{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%appyter init\n",
    "import os, sys; sys.path.insert(0, os.path.realpath('..'))\n",
    "from appyter import magic\n",
    "magic.init(lambda _=globals: _())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Imports\n",
    "## Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "## Machine Learning\n",
    "import sklearn as sk\n",
    "from sklearn import (\n",
    "    calibration,\n",
    "    decomposition,\n",
    "    ensemble,\n",
    "    feature_selection,\n",
    "    linear_model,\n",
    "    manifold,\n",
    "    metrics,\n",
    "    model_selection,\n",
    "    multioutput,\n",
    "    pipeline,\n",
    "    preprocessing,\n",
    "    svm,\n",
    "    tree,\n",
    ")\n",
    "## Plotting\n",
    "from matplotlib import pyplot as plt\n",
    "## Drugmonizome API\n",
    "from drugmonizome import Drugmonizome\n",
    "# Utility\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from functools import reduce\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = 2020\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a target attribute of interest, we will use machine learning to predict drugs that are strongly correlated with that target. Using the Drugmonizome datasets (stored locally), we load the dataset containing the target attribute as well as a number of well-populated Omics datasets for more drugs and features and build a large sparse dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select Omics datasets are downloaded and joined on the drug producing a large association matrix. Only association is preserved in order to create a binary classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter hide\n",
    "{% do SectionField(\n",
    "    title='ATTRIBUTE DATASET SELECTION',\n",
    "    subtitle='Select the input datasets to use for learning and classification.\\n\\\n",
    "              (If no datasets are selected, default attributes will be used.)',\n",
    "    name='ATTRIBUTES',\n",
    ") %}\n",
    "\n",
    "{% set exprdatasets = MultiChoiceField(\n",
    "    name='exprdatasets',\n",
    "    label='L1000',\n",
    "    choices=[\n",
    "        'L1000FWD Downregulated GO Biological Processes',\n",
    "        'L1000FWD Downregulated GO Cellular Components',\n",
    "        'L1000FWD Downregulated GO Molecular Function',\n",
    "        'L1000FWD Downregulated KEGG Pathways',\n",
    "        'L1000FWD Downregulated Signatures',\n",
    "        'L1000FWD Predicted Side Effects',\n",
    "        'L1000FWD Upregulated GO Biological Process',\n",
    "        'L1000FWD Upregulated GO Cellular Components',\n",
    "        'L1000FWD Upregulated GO Molecular Function',\n",
    "        'L1000FWD Upregulated KEGG Pathways',\n",
    "        'L1000FWD Upregulated Signatures',\n",
    "    ],\n",
    "    default=[],\n",
    "    section='ATTRIBUTES'\n",
    ") %}\n",
    "\n",
    "{% set targetdatasets = MultiChoiceField(\n",
    "    name='targetdatasets',\n",
    "    label='Drug Targets and Associated Genes',\n",
    "    choices=[\n",
    "        'Downregulated CREEDS Signatures',\n",
    "        'Upregulated CREEDS Signatures',\n",
    "        'DrugCentral Targets',\n",
    "        'DrugRepurposingHub Drug Targets',\n",
    "        'Drugbank Small Molecule Carriers',\n",
    "        'Drugbank Small Molecule Enzymes',\n",
    "        'Drugbank Small Molecule Targets',\n",
    "        'Drugbank Small Molecule Transporters',\n",
    "        'Geneshot Associated Genes',\n",
    "        'Geneshot Predicted AutoRIF Genes',\n",
    "        'Geneshot Predicted Coexpression Genes',\n",
    "        'Geneshot Predicted Enrichr Genes',\n",
    "        'Geneshot Predicted GeneRIF Genes',\n",
    "        'Geneshot Predicted Tagger Genes',\n",
    "        'KinomeScan Kinases',\n",
    "        'PharmGKB Single Nucleotide Polymorphisms',\n",
    "        'STITCH Targets',\n",
    "    ],\n",
    "    default=[],\n",
    "    section='ATTRIBUTES'\n",
    ") %}\n",
    "\n",
    "{% set indicationdatasets = MultiChoiceField(\n",
    "    name='indicationdatasets',\n",
    "    label='Indications, Modes of Action, and Side Effects',\n",
    "    choices=[\n",
    "        'ATC Codes Drugsetlibrary',\n",
    "        'DrugRepurposingHub Mechanisms of Action',\n",
    "        'PharmGKB OFFSIDES Side Effects',\n",
    "        'SIDER Indications',\n",
    "        'SIDER Side Effects',\n",
    "    ],\n",
    "    default=[],\n",
    "    section='ATTRIBUTES'\n",
    ") %}\n",
    "\n",
    "{% set structuraldatasets = MultiChoiceField(\n",
    "    name='structuraldatasets',\n",
    "    label='Structural Features',\n",
    "    choices=[\n",
    "        'RDKIT MACCS Chemical Fingerprints'\n",
    "    ],\n",
    "    default=[],\n",
    "    section='ATTRIBUTES'\n",
    ") %}\n",
    "\n",
    "{% set attribute_datasets = exprdatasets.value +\n",
    "                             targetdatasets.value +\n",
    "                             indicationdatasets.value +\n",
    "                             structuraldatasets.value %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%%appyter hide\n",
    "{% do SectionField(\n",
    "    title='TARGET DATASET SELECTION',\n",
    "    subtitle='Upload a list of drugs to be used as positive predictions for binary classification. \\\n",
    "              Drugs should be in a text file separated by newlines.\\n\\\n",
    "              (If no file is selected, a default list of hits from COVID-19 drug screens will be used.)',\n",
    "    name='TARGET',\n",
    ") %}\n",
    "\n",
    "{% set drugformat = ChoiceField(\n",
    "    name='drugformat',\n",
    "    label='Input Format',\n",
    "    default='Drug Name',\n",
    "    choices=[\n",
    "        'Drug Name',\n",
    "        'InChI Key'\n",
    "    ],\n",
    "    section='TARGET'\n",
    ") %}\n",
    "\n",
    "{% set drughitlist = FileField(\n",
    "    name='drughitlist',\n",
    "    label='Upload List of Drug Hits',\n",
    "    default='all_hits.txt',\n",
    "    section='TARGET'\n",
    ") %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "{% if attribute_datasets == [] %}\n",
    "# No attribute datasets selected, so use default datasets\n",
    "attribute_datasets = ['L1000FWD Downregulated Signatures',\n",
    "                      'L1000FWD Upregulated Signatures',\n",
    "                      'RDKIT MACCS Chemical Fingerprints']\n",
    "{% else %}\n",
    "# Use the selected attribute datasets\n",
    "attribute_datasets = {{ attribute_datasets }}\n",
    "{% endif %}\n",
    "\n",
    "df_attributes = list(Drugmonizome.download_df(\n",
    "    [dataset\n",
    "     for dataset in attribute_datasets]\n",
    "))\n",
    "\n",
    "# Assemble all attribute datasets\n",
    "if len(df_attributes) > 1:\n",
    "    # Obtain merged dataframe with omics and target data\n",
    "    df = reduce(\n",
    "        lambda a, b: pd.merge( # Merge two dataframes item by item\n",
    "            a, # left\n",
    "            b, # right\n",
    "            # Items with the same left and right index are merged\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            how='outer', # Keep mis-matched index\n",
    "        ),\n",
    "        df_attributes,\n",
    "    )\n",
    "else:\n",
    "    df = df_attributes[0]\n",
    "\n",
    "df = df.fillna(0)\n",
    "X = df.applymap(lambda f: 1 if f!=0 else 0)\n",
    "print('Total Shape:', X.shape)\n",
    "display(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "{% if drughitlist.value == '' %}\n",
    "hits_filename = '../../all_hits.txt'\n",
    "{% else %}\n",
    "hits_filename = {{drughitlist}}\n",
    "{% endif %}\n",
    "\n",
    "with open(hits_filename, 'r') as hits_file:\n",
    "    drug_hits = set(drug.strip() for drug in hits_file.read().strip().split('\\n') \n",
    "                    if len(drug.strip()) > 0)\n",
    "\n",
    "{% if drugformat.value == 'Drug Name' %}\n",
    "drug_hits = Drugmonizome.get_InChI_keys(drug_hits)\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the target class, we build a list (1 if drug is associated, otherwise 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([drug in drug_hits for drug in X.index]).astype(np.int8)\n",
    "print('Known Targets: %d (%0.3f %%)' % (y.sum(), 100*y.sum()/len(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We produce a target array containing 1 if the drug is associated and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output data shapes\n",
    "print('Input shape:', X.shape)\n",
    "print('Target shape:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter hide\n",
    "{% do SectionField(\n",
    "    title='SETTINGS',\n",
    "    subtitle='From here you can select the various available Machine Learning algorithms, their unique settings, and the methods to use to evaluate the classifier.',\n",
    "    name='SETTINGS',\n",
    ") %}\n",
    "{% set dimensionality_reduction = ChoiceField(\n",
    "    name='dimensionality_reduction',\n",
    "    label='Dimensionality Reduction Algorithm',\n",
    "    description='A dimensionality reduction algorithm should be selected to improve the quality of the classifier.',\n",
    "    default='PCA',\n",
    "    choices={\n",
    "        'PCA': 'sk.decomposition.PCA(n_components=64)',\n",
    "        'TruncatedSVD': 'sk.decomposition.TruncatedSVD(n_components=64)',\n",
    "        'IncrementalPCA': 'sk.decomposition.IncrementalPCA(n_components=64)',\n",
    "        'ICA': 'sk.decomposition.FastICA(n_components=64)',\n",
    "        'SparsePCA': 'sk.decomposition.SparsePCA(n_components=64)',\n",
    "    },\n",
    "    section='SETTINGS'\n",
    ") %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "## Dimensionality Reduction\n",
    "\n",
    "We reduce the dimensionality of our omics feature space with {{ dimensionality_reduction.value }}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "clf_dimensionality_reduction = {{ dimensionality_reduction }}\n",
    "X_reduced = clf_dimensionality_reduction.fit_transform(X.values)\n",
    "{% if dimensionality_reduction == 'PCA' %}\n",
    "print('Explained variance:', np.sum(clf_dimensionality_reduction.explained_variance_))\n",
    "{% endif %}\n",
    "plt.title('Low dimension representation')\n",
    "plt.scatter(\n",
    "    X_reduced[:, 0],\n",
    "    X_reduced[:, 1],\n",
    "    c=y,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter hide\n",
    "{% set feature_selection = ChoiceField(\n",
    "    name='feature_selection',\n",
    "    label='Machine Learning Feature Selection',\n",
    "    default='None',\n",
    "    choices={\n",
    "        'None': 'None',\n",
    "        'SelectFromLinearSVC': 'sk.feature_selection.SelectFromModel(sk.svm.LinearSVC(loss=\"squared_hinge\", penalty=\"l1\", dual=False))',\n",
    "        'SelectFromExtraTrees': 'sk.feature_selection.SelectFromModel(sk.ensemble.ExtraTreesClassifier())',\n",
    "        'SelectKBest': 'sk.feature_selection.SelectKBest(\"f_classif\")',\n",
    "        'SelectKBestChi2': 'sk.feature_selection.SelectKBest(\"chi2\")',\n",
    "        'SelectKBestMultiInfo': 'sk.feature_selection.SelectKBest(\"mutual_info_classif\")',\n",
    "    },\n",
    "    section='SETTINGS'\n",
    ") %}\n",
    "{% set cv_algorithm = ChoiceField(\n",
    "    name='cv_algorithm',\n",
    "    label='Cross Validation Algorithm',\n",
    "    default='StratifiedKFold',\n",
    "    value='KFold',\n",
    "    choices={\n",
    "        'KFold': 'sk.model_selection.KFold',\n",
    "        'GroupKFold': 'sk.model_selection.GroupKFold',\n",
    "        'RepeatedKFold': 'sk.model_selection.RepeatedKFold',\n",
    "        'StratifiedKFold': 'sk.model_selection.StratifiedKFold',\n",
    "        'RepeatedStratifiedKFold': 'sk.model_selection.RepeatedStratifiedKFold',\n",
    "    },\n",
    "    section='SETTINGS',\n",
    ") %}\n",
    "{% set algorithm = ChoiceField(\n",
    "    name='algorithm',\n",
    "    label='Machine Learning Algorithm',\n",
    "    default='RandomForestClassifier',\n",
    "    description='A machine learning algorithm should be selected to construct the predictive model.',\n",
    "    choices={\n",
    "        'GradientBoostingClassifier': 'sk.ensemble.GradientBoostingClassifier()',\n",
    "        'RandomForestClassifier': 'sk.ensemble.RandomForestClassifier()',\n",
    "        'AdaBoostClassifier': 'sk.ensemble.AdaBoostClassifier()',\n",
    "        'ExtraTreesClassifier': 'sk.ensemble.ExtraTreesClassifier()',\n",
    "        'DecisionTreeClassifier': 'sk.tree.DecisionTreeClassifier()',\n",
    "        'KNeighborsClassifier': 'sk.neighbors.KNeighborsClassifier()',\n",
    "        'RadiusNeighborsClassifier': 'sk.neighbors.RadiusNeighborsClassifier()',\n",
    "        'MLPClassifier': 'sk.neural_network.MLPClassifier()',\n",
    "        'OneClassSVM': 'sk.svm.OneClassSVM()',\n",
    "    },\n",
    "    section='SETTINGS'\n",
    ") %}\n",
    "{% set calibrated = BoolField(\n",
    "    name='calibrated',\n",
    "    label='Calibrate algorithm predictions',\n",
    "    description='Calibrate the prediction probabilities eliminating model-imparted bias.',\n",
    "    default=True,\n",
    "    section='SETTINGS',\n",
    ") %}\n",
    "{% set hyper_param_search = ChoiceField(\n",
    "    name='hyper_param_search',\n",
    "    label='Hyper Parameter Search Type',\n",
    "    default='None',\n",
    "    description='Hyper parameter searching is used to automatically select the best parameters (using the primary metric as the criteria).',\n",
    "    choices={\n",
    "        'None': 'None',\n",
    "        'RandomizedSearchCV': 'sk.model_selection.RandomizedSearchCV',\n",
    "        'GridSearchCV': 'sk.model_selection.GridSearchCV',\n",
    "    },\n",
    "    section='SETTINGS'\n",
    ") %}\n",
    "{% set cross_validation_n_folds = IntField(\n",
    "    name='cross_validation_n_folds',\n",
    "    label='Cross-Validated Folds',\n",
    "    description='Cross validation is employed as a strategy to train the model on data that the model has not seen before, more folds will ensure that the model is generalizing well.',\n",
    "    default=3,\n",
    "    min=2,\n",
    "    max=10,\n",
    "    section='SETTINGS'\n",
    ") %}\n",
    "{% set primary_metric = ChoiceField(\n",
    "    name='primary_metric',\n",
    "    label='Primary Evaluation Metric',\n",
    "    default='roc_auc',\n",
    "    description='The primary evaluation metric is used for deciding how we assess the performance of our model.',\n",
    "    choices=[\n",
    "        'accuracy',\n",
    "        'adjusted_mutual_info_score',\n",
    "        'adjusted_rand_score',\n",
    "        'average_precision',\n",
    "        'balanced_accuracy',\n",
    "        'completeness_score',\n",
    "        'explained_variance',\n",
    "        'f1',\n",
    "        'f1_macro',\n",
    "        'f1_micro',\n",
    "        'f1_weighted',\n",
    "        'fowlkes_mallows_score',\n",
    "        'homogeneity_score',\n",
    "        'jaccard',\n",
    "        'jaccard_macro',\n",
    "        'jaccard_micro',\n",
    "        'jaccard_weighted',\n",
    "        'max_error',\n",
    "        'mutual_info_score',\n",
    "        'neg_brier_score',\n",
    "        'neg_log_loss',\n",
    "        'neg_mean_absolute_error',\n",
    "        'neg_mean_squared_error',\n",
    "        'neg_mean_squared_log_error',\n",
    "        'neg_median_absolute_error',\n",
    "        'neg_root_mean_squared_error',\n",
    "        'normalized_mutual_info_score',\n",
    "        'precision',\n",
    "        'precision_macro',\n",
    "        'precision_micro',\n",
    "        'precision_weighted',\n",
    "        'r2',\n",
    "        'recall',\n",
    "        'recall_macro',\n",
    "        'recall_micro',\n",
    "        'recall_weighted',\n",
    "        'roc_auc',\n",
    "        'roc_auc_ovo',\n",
    "        'roc_auc_ovo_weighted',\n",
    "        'roc_auc_ovr',\n",
    "        'roc_auc_ovr_weighted',\n",
    "        'v_measure_score'\n",
    "    ],\n",
    "    section='SETTINGS'\n",
    ") %}\n",
    "{% set evaluation_metrics = MultiChoiceField(\n",
    "    name='evaluation_metrics',\n",
    "    label='Evaluation Metrics',\n",
    "    default=[],\n",
    "    description='Additional evaluation metrics can be specified, these metrics will also be reported for all models trained.',\n",
    "    value=['recall', 'f1'],\n",
    "    choices=[\n",
    "        'accuracy',\n",
    "        'adjusted_mutual_info_score',\n",
    "        'adjusted_rand_score',\n",
    "        'average_precision',\n",
    "        'balanced_accuracy',\n",
    "        'completeness_score',\n",
    "        'explained_variance',\n",
    "        'f1',\n",
    "        'f1_macro',\n",
    "        'f1_micro',\n",
    "        'f1_weighted',\n",
    "        'fowlkes_mallows_score',\n",
    "        'homogeneity_score',\n",
    "        'jaccard',\n",
    "        'jaccard_macro',\n",
    "        'jaccard_micro',\n",
    "        'jaccard_weighted',\n",
    "        'max_error',\n",
    "        'mutual_info_score',\n",
    "        'neg_brier_score',\n",
    "        'neg_log_loss',\n",
    "        'neg_mean_absolute_error',\n",
    "        'neg_mean_squared_error',\n",
    "        'neg_mean_squared_log_error',\n",
    "        'neg_median_absolute_error',\n",
    "        'neg_root_mean_squared_error',\n",
    "        'normalized_mutual_info_score',\n",
    "        'precision',\n",
    "        'precision_macro',\n",
    "        'precision_micro',\n",
    "        'precision_weighted',\n",
    "        'r2',\n",
    "        'recall',\n",
    "        'recall_macro',\n",
    "        'recall_micro',\n",
    "        'recall_weighted',\n",
    "        'roc_auc',\n",
    "        'roc_auc_ovo',\n",
    "        'roc_auc_ovo_weighted',\n",
    "        'roc_auc_ovr',\n",
    "        'roc_auc_ovr_weighted',\n",
    "        'v_measure_score'\n",
    "    ],\n",
    "    section='SETTINGS',\n",
    ") %}\n",
    "{% set all_metrics = [primary_metric.value] + evaluation_metrics.value %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "## Machine Learning\n",
    "\n",
    "We apply a {% if hyper_param_search.value != 'None' %}{{ hyper_param_search.value }} search for the hyper parameters\n",
    "of a {% endif %}sklearn pipeline with a dimensionality reduction step of {{ dimensionality_reduction.value }}\n",
    "{% if feature_selection.value != 'None' %}and a feature selection step of {{ feature_selection.value }}\n",
    "{% endif %} and a{% if calibrated %} calibrated{%endif %} {{ algorithm.value }} classifier\n",
    "using {{ cross_validation_n_folds.value }}-fold repeated\n",
    "stratified cross-validation, optimizing {{ primary_metric.value }}\n",
    "{% if evaluation_metrics.value %} and computing {{ ', '.join(evaluation_metrics.value) }}{% endif %}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "{% if algorithm.value == 'GradientBoostingClassifier' %}\n",
    "## Early stopping function\n",
    "def early_stopping(n_rounds, tol=0.001):\n",
    "    def early_stopping_func(i, self, local):\n",
    "        rounds = getattr(self, '__rounds', 0)\n",
    "        last = getattr(self, '__last', None)\n",
    "        current = self.train_score_[i]\n",
    "        if last and current and abs(current - last) < tol:\n",
    "            rounds += 1\n",
    "            if rounds > n_rounds:\n",
    "                return True\n",
    "        else:\n",
    "            rounds = 0\n",
    "        setattr(self, '__last', current)\n",
    "        setattr(self, '__rounds', rounds)\n",
    "        return False\n",
    "    return early_stopping_func\n",
    "{% endif %}\n",
    "\n",
    "{#\n",
    "param_grid = {\n",
    "    'reduce_dim__n_components': randint(2, 1024),\n",
    "{% if algorithm.value == 'GradientBoostingClassifier' %}\n",
    "    'clf__loss': ['deviance', 'exponential'],\n",
    "    'clf__learning_rate': randfloat(0.001, 1.),\n",
    "    'clf__subsample': randfloat(0.01, 1.),\n",
    "{% elif algorithm.value == 'RandomForestClassifier' %}\n",
    "    'clf__oob_score': [True],\n",
    "    'clf__criterion': ['gini', 'entropy'],\n",
    "{% endif %}\n",
    "    'clf__n_estimators': randint(10, 200),\n",
    "    'clf__max_depth': randint(20, 50),\n",
    "    'clf__max_features': ['sqrt', 'log2', None],\n",
    "    'clf__min_impurity_decrease': randfloat(0., 0.2),\n",
    "    'clf__min_weight_fraction_leaf': randfloat(0., 0.5),\n",
    "}\n",
    "\n",
    "fit_params = {\n",
    "{% if algorithm.value == 'GradientBoostingClassifier' %}\n",
    "    'clf__monitor': early_stopping(5),\n",
    "{% endif %}\n",
    "}\n",
    "#}\n",
    "    \n",
    "cv = {{ cv_algorithm }}(\n",
    "    n_splits={{ cross_validation_n_folds }},\n",
    "    shuffle=True,\n",
    "    random_state=rng,\n",
    ")\n",
    "\n",
    "model =\n",
    "{%- if hyper_param_search.value != 'None' %} {{ hyper_param_search }}({% endif -%}\n",
    "    {%- if calibrated %} sk.calibration.CalibratedClassifierCV({% endif -%}\n",
    "        sk.pipeline.Pipeline([\n",
    "            ('reduce_dim', {{ dimensionality_reduction }}),\n",
    "            {%- if feature_selection.value != 'None' %}('feature_selection', {{ feature_selection }}),{% endif %}\n",
    "            ('clf', {{ algorithm }}),\n",
    "        ]),\n",
    "    cv=cv,\n",
    "{% if calibrated %}){% endif -%}{%- if hyper_param_search.value != 'None' %}){% endif %}\n",
    "\n",
    "# Scoring parameters\n",
    "primary_metric = '{{ primary_metric }}'\n",
    "evaluation_metrics = {{ evaluation_metrics }}\n",
    "scoring_params = {k: metrics.get_scorer(k)\n",
    "                  for k in [primary_metric, *evaluation_metrics]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_eval\n",
    "{% if hyper_param_search.value == 'None' %}\n",
    "df_results = pd.DataFrame()\n",
    "for fold, (train, test) in enumerate(cv.split(X.values, y)):\n",
    "    model.fit(X.values[train], y[train])\n",
    "    {% for metric in all_metrics %}\n",
    "    df_results.loc[fold, '{{ metric }}'] = scoring_params['{{ metric }}'](model, X.values[test], y[test])\n",
    "    {% endfor %}\n",
    "display(df_results.agg(['mean', 'std']))\n",
    "{% else %}\n",
    "model.fit(X, y)\n",
    "df_results = model.cv_results_\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This visualization shows illustrates the cross-validated performance of the model. Low fold variance and high AUC is desired in a well-generalized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "{% if 'roc_auc' in all_metrics %}\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "for fold, (train, test) in enumerate(cv.split(X.values, y)):\n",
    "    model.fit(X.values[train], y[train])\n",
    "    y_proba = model.predict_proba(X.values[test]) # Probability prediction will be True\n",
    "    fpr, tpr, _ = sk.metrics.roc_curve(y[test], y_proba[:, 1])\n",
    "    tprs.append(sp.interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = sk.metrics.auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    ax.plot(fpr, tpr, alpha=0.4, label='ROC Fold %d (AUC=%0.3f)' % (fold, roc_auc))\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = sk.metrics.auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "ax.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2)\n",
    "\n",
    "ax.plot([0,1],[0,1],'--', label='Luck')\n",
    "ax.legend()\n",
    "\n",
    "z = (mean_auc - 0.5)/std_auc\n",
    "cl = sp.stats.norm.cdf(z) * 100\n",
    "ci = sp.stats.norm.interval(0.95, loc=mean_auc, scale=std_auc)\n",
    "print('Confidence interval (95%)', ci)\n",
    "print(\"We are %0.3f %% confident the model's results are not just chance.\" % (cl))\n",
    "if cl > 95:\n",
    "    print('This is statistically significant. These results can be trusted.')\n",
    "else:\n",
    "    print('This is not statistically significant. These results should not be trusted.')\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will take a long time as we are evaluating n_iter different models n_splits different times each computing all the metrics on `product(X.shape)` data points--not to mention the size of each model dictated by the range of parameters specified in the params dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y, model.predict(X.values))\n",
    "display(cm)\n",
    "print('\\n',\n",
    "    'True labels predicted to be true:', cm[0,0], '\\n',\n",
    "    'True labels predicted to be false:', cm[0,1], '\\n',\n",
    "    'False labels predicted to be true:', cm[1,0], '\\n',\n",
    "    'False labels predicted to be false:', cm[1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine drug predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain prediction results\n",
    "y_probas = model.predict_proba(X)[:, 1]\n",
    "results = pd.DataFrame(np.array([\n",
    "    Drugmonizome.get_drug_names(X.index),\n",
    "    y,\n",
    "    (y_probas > 0.5).astype('float64'),\n",
    "    y_probas,\n",
    "]).T, columns=[\n",
    "    'Name',\n",
    "    'Known',\n",
    "    'Predicted',\n",
    "    'Prediction Probability',\n",
    "], index=X.index).astype({'Known': 'float64', 'Predicted': 'float64', 'Prediction Probability': 'float64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank drug hits\n",
    "results[((results['Known'] == 1))].sort_values('Prediction Probability', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict additional drugs\n",
    "results[results['Known'] == 0].sort_values('Prediction Probability', ascending=False).head(25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drugmonizome-ml-appyter",
   "language": "python",
   "name": "drugmonizome-ml-appyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
