{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%appyter init\n",
    "import os, sys; sys.path.insert(0, os.path.realpath('..'))\n",
    "from appyter import magic\n",
    "magic.init(lambda _=globals: _())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Imports\n",
    "## Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "## Machine Learning\n",
    "import sklearn as sk\n",
    "from sklearn import (\n",
    "    calibration,\n",
    "    decomposition,\n",
    "    ensemble,\n",
    "    feature_selection,\n",
    "    linear_model,\n",
    "    manifold,\n",
    "    metrics,\n",
    "    model_selection,\n",
    "    multioutput,\n",
    "    pipeline,\n",
    "    preprocessing,\n",
    "    svm,\n",
    "    tree,\n",
    "    feature_extraction,\n",
    ")\n",
    "from split import StratifiedGroupKFold, RepeatedStratifiedGroupKFold\n",
    "import umap\n",
    "## Plotting\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "## Drugmonizome API\n",
    "from drugmonizome import Drugmonizome\n",
    "## SEP-L1000 data retrieval\n",
    "from sepl1000 import SEPL1000\n",
    "## L1000FWD queries\n",
    "import querysepl1000fwd\n",
    "## Match drug name inputs using PubChem API\n",
    "from DrugNameConverter import DrugNameConverter\n",
    "# Utility\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from functools import reduce\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = 2020\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Input Datasets and Target Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selected drug set libraries and omics datasets are downloaded and joined on the drug to produce a large association matrix. A machine learning model will be trained to predict the specified target labels from this association matrix. This is a binary classification task that can be used to predict drugs that are likely to be associated with the target class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter hide\n",
    "{% do SectionField(\n",
    "    title='Attribute Dataset Selection',\n",
    "    subtitle='Select the input datasets to use for learning and classification. \\\n",
    "              A model will be trained to predict the target labels from the selected attributes. \\\n",
    "              If no datasets are selected, default attributes will be used.',\n",
    "    name='ATTRIBUTES',\n",
    "    img='attributes.png',\n",
    ") %}\n",
    "\n",
    "{% set sepl1000datasets = MultiChoiceField(\n",
    "    name='sepl1000datasets',\n",
    "    label='SEP-L1000',\n",
    "    description='These input datasets were used previously for side effect prediction (https://maayanlab.net/SEP-L1000/).',\n",
    "    choices=[\n",
    "        'LINCS Gene Expression Signatures',\n",
    "        'GO Transformed Signatures (PAEA)',\n",
    "        'MLPCN Cell Morphological Profiling',\n",
    "        'MACCS Chemical Fingerprint',\n",
    "    ],\n",
    "    default=['LINCS Gene Expression Signatures', 'GO Transformed Signatures (PAEA)', 'MLPCN Cell Morphological Profiling', 'MACCS Chemical Fingerprint'],\n",
    "    section='ATTRIBUTES'\n",
    ") %}\n",
    "\n",
    "{% set exprdatasets = MultiChoiceField(\n",
    "    name='exprdatasets',\n",
    "    label='L1000FWD (drug sets)',\n",
    "    choices=[\n",
    "        'L1000FWD Downregulated GO Biological Processes',\n",
    "        'L1000FWD Downregulated GO Cellular Components',\n",
    "        'L1000FWD Downregulated GO Molecular Function',\n",
    "        'L1000FWD Downregulated KEGG Pathways',\n",
    "        'L1000FWD Downregulated Signatures',\n",
    "        'L1000FWD Predicted Side Effects',\n",
    "        'L1000FWD Upregulated GO Biological Process',\n",
    "        'L1000FWD Upregulated GO Cellular Components',\n",
    "        'L1000FWD Upregulated GO Molecular Function',\n",
    "        'L1000FWD Upregulated KEGG Pathways',\n",
    "        'L1000FWD Upregulated Signatures',\n",
    "    ],\n",
    "    default=[],\n",
    "    section='ATTRIBUTES'\n",
    ") %}\n",
    "\n",
    "{% set targetdatasets = MultiChoiceField(\n",
    "    name='targetdatasets',\n",
    "    label='Drug Targets and Associated Genes (drug sets)',\n",
    "    choices=[\n",
    "        'Downregulated CREEDS Signatures',\n",
    "        'Upregulated CREEDS Signatures',\n",
    "        'DrugCentral Targets',\n",
    "        'DrugRepurposingHub Drug Targets',\n",
    "        'Drugbank Small Molecule Carriers',\n",
    "        'Drugbank Small Molecule Enzymes',\n",
    "        'Drugbank Small Molecule Targets',\n",
    "        'Drugbank Small Molecule Transporters',\n",
    "        'Geneshot Associated Genes',\n",
    "        'Geneshot Predicted AutoRIF Genes',\n",
    "        'Geneshot Predicted Coexpression Genes',\n",
    "        'Geneshot Predicted Enrichr Genes',\n",
    "        'Geneshot Predicted GeneRIF Genes',\n",
    "        'Geneshot Predicted Tagger Genes',\n",
    "        'KinomeScan Kinases',\n",
    "        'PharmGKB Single Nucleotide Polymorphisms',\n",
    "        'STITCH Targets',\n",
    "    ],\n",
    "    default=[],\n",
    "    section='ATTRIBUTES'\n",
    ") %}\n",
    "\n",
    "{% set indicationdatasets = MultiChoiceField(\n",
    "    name='indicationdatasets',\n",
    "    label='Indications, Modes of Action, and Side Effects (drug sets)',\n",
    "    choices=[\n",
    "        'ATC Codes Drugsetlibrary',\n",
    "        'DrugRepurposingHub Mechanisms of Action',\n",
    "        'PharmGKB OFFSIDES Side Effects',\n",
    "        'SIDER Indications',\n",
    "        'SIDER Side Effects',\n",
    "    ],\n",
    "    default=[],\n",
    "    section='ATTRIBUTES'\n",
    ") %}\n",
    "\n",
    "{% set structuraldatasets = MultiChoiceField(\n",
    "    name='structuraldatasets',\n",
    "    label='Structural Features (drug sets)',\n",
    "    choices=[\n",
    "        'RDKIT MACCS Chemical Fingerprints'\n",
    "    ],\n",
    "    default=[],\n",
    "    section='ATTRIBUTES'\n",
    ") %}\n",
    "\n",
    "{% set keepmissing = BoolField(\n",
    "    name='keepmissing',\n",
    "    label='Keep drugs with missing data when joining datasets',\n",
    "    description='Keep drugs that appear in some datasets and not in others. \\\n",
    "                 Missing data is filled in with zeros. Otherwise, only drugs \\\n",
    "                 that are present in all datasets are preserved.',\n",
    "    default=False,\n",
    "    section='ATTRIBUTES',\n",
    ") %}\n",
    "\n",
    "{% set tfidf = BoolField(\n",
    "    name='tfidf',\n",
    "    label='Apply tfâ€“idf normalization to binary inputs',\n",
    "    description='For binary drug-attribute associations in the input matrix, \\\n",
    "                 apply tf-idf transformation to normalize data.',\n",
    "    default=True,\n",
    "    section='ATTRIBUTES',\n",
    ") %}\n",
    "\n",
    "{% set attribute_datasets = exprdatasets.value +\n",
    "                             targetdatasets.value +\n",
    "                             indicationdatasets.value +\n",
    "                             structuraldatasets.value %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "\n",
    "To construct the input matrix, we download drug set libraries and omics datasets and join them on the InChI Key.\n",
    "{% if keepmissing.value %} Drugs that appear in some datasets and not in others are retained, and missing data is filled in with zeros.\n",
    "{% else %} Only drugs that are present in all datasets are retained.\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%%appyter hide\n",
    "{% do SectionField(\n",
    "    title='Target Label Selection',\n",
    "    subtitle='Upload a list of drugs to be given positive class labels for binary classification. \\\n",
    "              Drugs should be in a text file, specified by either drug name or InChI Key and separated by newlines. \\\n",
    "              If no file is selected, a default list of hits from COVID-19 drug screens will be used.',\n",
    "    name='TARGET',\n",
    "    img='target.png',\n",
    ") %}\n",
    "\n",
    "{% set drugformat = ChoiceField(\n",
    "    name='drugformat',\n",
    "    label='Drug Identifier Format',\n",
    "    default='Drug Name',\n",
    "    choices=[\n",
    "        'Drug Name',\n",
    "        'InChI Key'\n",
    "    ],\n",
    "    section='TARGET'\n",
    ") %}\n",
    "\n",
    "{% set drughitlist = FileField(\n",
    "    name='drughitlist',\n",
    "    label='Upload List of Drug Hits',\n",
    "    default='COVID19ScreenHits.txt',\n",
    "    examples={\n",
    "        'COVID19ScreenHits.txt': 'https://appyters.maayanlab.cloud/storage/Drugmonizome_ML/COVID19ScreenHits.txt',\n",
    "    },\n",
    "    section='TARGET'\n",
    ") %}\n",
    "\n",
    "{% set includestereo = BoolField(\n",
    "    name='includestereo',\n",
    "    label='Include stereoisomers',\n",
    "    description='If true, drugs are matched to entries in the datasets by the first 14 characters of their InChI Keys, \\\n",
    "                 so stereoisomers of the drugs in the input list are also counted as hits. \\\n",
    "                 Note that different resources record different details for charge and stereochemistry, \\\n",
    "                 causing some drugs to have different full-length InChI Keys in different datasets. \\\n",
    "                 Selecting this option may allow such drugs to be better matched to entries in the datasets.',\n",
    "    default=True,\n",
    "    section='TARGET',\n",
    ") %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "# Use the selected SEP-L1000 datasets\n",
    "sepl1000datasets = {{ sepl1000datasets }}\n",
    "\n",
    "name_to_file = {\n",
    "    'LINCS Gene Expression Signatures': 'LINCS_Gene_Experssion_signatures_CD.csv.gz',\n",
    "    'GO Transformed Signatures (PAEA)': 'GO_transformed_signatures_PAEA.csv.gz',\n",
    "    'MLPCN Cell Morphological Profiling': 'MLPCN_morplological_profiles.csv.gz',\n",
    "    'MACCS Chemical Fingerprint': 'MACCS_bitmatrix.csv.gz',\n",
    "}\n",
    "\n",
    "df_sepl1000_list = list(SEPL1000.download_df(list(name_to_file[dataset] for dataset in sepl1000datasets),\n",
    "                                             index_col=0))\n",
    "dataset_sizes = list(zip(sepl1000datasets, [dataset.shape[1] for dataset in df_sepl1000_list]))\n",
    "\n",
    "# Assemble all SEP-L1000 datasets\n",
    "if len(df_sepl1000_list) > 1:\n",
    "    # Obtain merged dataframe with omics and target data\n",
    "    df_sepl1000 = reduce(\n",
    "        lambda a, b: pd.merge( # Merge two dataframes item by item\n",
    "            a, # left\n",
    "            b, # right\n",
    "            # Items with the same left and right index are merged\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            {% if keepmissing.value %}\n",
    "            how='outer', # Keep mis-matched indices\n",
    "            {% else %}\n",
    "            how='inner', # Keep only matched indices\n",
    "            {% endif %}\n",
    "        ),\n",
    "        df_sepl1000_list,\n",
    "    )\n",
    "else:\n",
    "    df_sepl1000 = df_sepl1000_list[0]\n",
    "\n",
    "# del(df_sepl1000_list)\n",
    "\n",
    "# Mean-fill infinite and missing values\n",
    "df_sepl1000 = df_sepl1000.replace([np.inf, -np.inf], np.nan)\n",
    "df_sepl1000 = df_sepl1000.fillna(np.mean(df_sepl1000))\n",
    "print('Total shape:', df_sepl1000.shape)\n",
    "display(df_sepl1000.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "{% if attribute_datasets == [] and sepl1000datasets == [] %}\n",
    "# No datasets selected, so use default datasets\n",
    "attribute_datasets = ['L1000FWD Downregulated Signatures',\n",
    "                      'L1000FWD Upregulated Signatures',\n",
    "                      'RDKIT MACCS Chemical Fingerprints']\n",
    "{% else %}\n",
    "# Use the selected attribute datasets\n",
    "attribute_datasets = {{ attribute_datasets }}\n",
    "{% endif %}\n",
    "\n",
    "{% if attribute_datasets == [] and sepl1000datasets != [] %}\n",
    "X = df_sepl1000\n",
    "{% else %}\n",
    "df_attributes = list(Drugmonizome.download_df(\n",
    "    [dataset\n",
    "     for dataset in attribute_datasets]\n",
    "))\n",
    "dataset_sizes += list(zip(sepl1000datasets, [dataset.shape[1] for dataset in df_sepl1000_list]))\n",
    "\n",
    "# Assemble all attribute datasets\n",
    "if len(df_attributes) > 1:\n",
    "    # Obtain merged dataframe with omics and target data\n",
    "    df = reduce(\n",
    "        lambda a, b: pd.merge( # Merge two dataframes item by item\n",
    "            a, # left\n",
    "            b, # right\n",
    "            # Items with the same left and right index are merged\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            {% if keepmissing.value %}\n",
    "            how='outer', # Keep mis-matched indices\n",
    "            {% else %}\n",
    "            how='inner', # Keep only matched indices\n",
    "            {% endif %}\n",
    "        ),\n",
    "        df_attributes,\n",
    "    )\n",
    "else:\n",
    "    df = df_attributes[0]\n",
    "\n",
    "df = df.fillna(0)\n",
    "X = df.applymap(lambda f: 1 if f!=0 else 0)\n",
    "{% if tfidf.value %}\n",
    "# Apply tf-idf normalization\n",
    "transformer = feature_extraction.text.TfidfTransformer()\n",
    "X_tfidf = transformer.fit_transform(X)\n",
    "X = pd.DataFrame.sparse.from_spmatrix(X_tfidf, columns=X.columns, index=X.index)\n",
    "X = pd.merge(df_sepl1000, X, left_index=True, right_index=True)\n",
    "{% endif %}\n",
    "{% endif %}\n",
    "\n",
    "print('Total shape:', X.shape)\n",
    "display(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "\n",
    "The target labels are produced from the uploaded list of hits: 1 if the drug is specified as a hit, 0 otherwise.\n",
    "{% if drugformat.value == 'Drug Name' %} Drug names are matched to InChI Keys from the Drugmonizome metadata.\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "{% if drughitlist.value == '' %}\n",
    "# Using default list of hits from COVID-19 in vitro drug screens\n",
    "hits_filename = '../../COVID19ScreenHits.txt'\n",
    "{% else %}\n",
    "# Using user-specified list of positive drug hits\n",
    "hits_filename = {{drughitlist}}\n",
    "{% endif %}\n",
    "\n",
    "with open(hits_filename, 'r') as hits_file:\n",
    "    drug_hits = set(drug.strip() for drug in hits_file.read().strip().split('\\n') \n",
    "                    if len(drug.strip()) > 0)\n",
    "\n",
    "{% if drugformat.value == 'Drug Name' %}\n",
    "# Query PubChem API to map drug names to InChI Keys\n",
    "drug_hits_inchi = DrugNameConverter.batch_to_inchi_keys(drug_hits)\n",
    "drug_hits = set(key for drug in drug_hits_inchi\n",
    "                    for key in drug_hits_inchi[drug])\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We produce a target array containing 1 if the drug is specified as a hit and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "{% if includestereo.value %}\n",
    "# Match first 14 characters of InChI Keys (hash of InChI connectivity information)\n",
    "drug_hits_inchi_main_layer = set(key[:14] for key in drug_hits)\n",
    "y = np.array([drug[:14] in drug_hits_inchi_main_layer for drug in X.index]).astype(np.int8)\n",
    "{% else %}\n",
    "y = np.array([drug in drug_hits for drug in X.index]).astype(np.int8)\n",
    "{% endif %}\n",
    "print('Number of hits matched in input: %d (%0.3f %%)' % (y.sum(), 100*y.sum()/len(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output data shapes\n",
    "print('Input shape:', X.shape)\n",
    "print('Target shape:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter hide\n",
    "{% do SectionField(\n",
    "    title='Machine Learning Pipeline',\n",
    "    subtitle='Select from available machine learning algorithms, their unique settings, and methods to use to evaluate the classifier.',\n",
    "    name='SETTINGS',\n",
    "    img='settings.png',\n",
    ") %}\n",
    "\n",
    "{% set visualization_reduction = ChoiceField(\n",
    "    name='visualization_reduction',\n",
    "    label='Data Visualization Method',\n",
    "    description='A dimensionality reduction algorithm should be selected for data visualization.',\n",
    "    default='UMAP',\n",
    "    choices={\n",
    "        'UMAP': 'umap.UMAP()',\n",
    "        'NMF': 'sk.decomposition.NMF(n_components=2)',\n",
    "        'PCA': 'sk.decomposition.PCA(n_components=2)',\n",
    "        'TruncatedSVD': 'sk.decomposition.TruncatedSVD(n_components=2)',\n",
    "        'IncrementalPCA': 'sk.decomposition.IncrementalPCA(n_components=2)',\n",
    "        'ICA': 'sk.decomposition.FastICA(n_components=2)',\n",
    "        'SparsePCA': 'sk.decomposition.SparsePCA(n_components=2)',\n",
    "    },\n",
    "    section='SETTINGS'\n",
    ") %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "\n",
    "We reduce the dimensionality of our omics feature space for visualization with {{ visualization_reduction.raw_value }}\n",
    "([visualization.svg](./visualization.svg))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "clf_dimensionality_reduction = {{ visualization_reduction }}\n",
    "X_reduced = clf_dimensionality_reduction.fit_transform(X.values)\n",
    "{% if visualization_reduction.raw_value == 'PCA' %}\n",
    "print('Explained variance:', np.sum(clf_dimensionality_reduction.explained_variance_))\n",
    "{% endif %}\n",
    "plt.title('{{ visualization_reduction.raw_value }}')\n",
    "plt.scatter(\n",
    "    X_reduced[y==0, 0],\n",
    "    X_reduced[y==0, 1],\n",
    "    alpha=min(0.8, 500/np.sum(y==0)),\n",
    "    s=10\n",
    ")\n",
    "plt.scatter(\n",
    "    X_reduced[y==1, 0],\n",
    "    X_reduced[y==1, 1],\n",
    "    alpha=min(0.8, 500/np.sum(y==1)),\n",
    "    s=10\n",
    ")\n",
    "plt.savefig('visualization.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter hide\n",
    "{% set dimensionality_reduction = ChoiceField(\n",
    "    name='dimensionality_reduction',\n",
    "    label='Dimensionality Reduction Algorithm',\n",
    "    description='A dimensionality reduction algorithm should be selected to improve the quality of the classifier.',\n",
    "    default='None',\n",
    "    choices={\n",
    "        'None': 'None',\n",
    "        'PCA': 'sk.decomposition.PCA(n_components=64)',\n",
    "        'TruncatedSVD': 'sk.decomposition.TruncatedSVD(n_components=64)',\n",
    "        'IncrementalPCA': 'sk.decomposition.IncrementalPCA(n_components=64)',\n",
    "        'ICA': 'sk.decomposition.FastICA(n_components=64)',\n",
    "        'SparsePCA': 'sk.decomposition.SparsePCA(n_components=64)',\n",
    "    },\n",
    "    section='SETTINGS'\n",
    ") %}\n",
    "{% set feature_selection = ChoiceField(\n",
    "    name='feature_selection',\n",
    "    label='Machine Learning Feature Selection',\n",
    "    default='RecursiveSelectionFromExtraTrees',\n",
    "    choices={\n",
    "        'None': 'None',\n",
    "        'SelectFromLinearSVC': 'sk.feature_selection.SelectFromModel(sk.svm.LinearSVC(loss=\"squared_hinge\", penalty=\"l1\", dual=False, class_weight=\"balanced\"))',\n",
    "        'SelectFromExtraTrees': 'sk.feature_selection.SelectFromModel(sk.ensemble.ExtraTreesClassifier(class_weight=\"balanced\"))',\n",
    "        'RecursiveSelectionFromExtraTrees': 'sk.feature_selection.RFE(sk.ensemble.ExtraTreesClassifier(class_weight=\"balanced\"), n_features_to_select=64, step=1000)',\n",
    "        'SelectKBest': 'sk.feature_selection.SelectKBest(\"f_classif\")',\n",
    "        'SelectKBestChi2': 'sk.feature_selection.SelectKBest(\"chi2\")',\n",
    "        'SelectKBestMultiInfo': 'sk.feature_selection.SelectKBest(\"mutual_info_classif\")',\n",
    "    },\n",
    "    section='SETTINGS'\n",
    ") %}\n",
    "{% set cv_algorithm = ChoiceField(\n",
    "    name='cv_algorithm',\n",
    "    label='Cross Validation Algorithm',\n",
    "    default='StratifiedGroupKFold',\n",
    "    value='KFold',\n",
    "    choices={\n",
    "        'KFold': 'sk.model_selection.KFold',\n",
    "        'GroupKFold': 'sk.model_selection.GroupKFold',\n",
    "        'RepeatedKFold': 'sk.model_selection.RepeatedKFold',\n",
    "        'StratifiedKFold': 'sk.model_selection.StratifiedKFold',\n",
    "        'StratifiedGroupKFold': 'StratifiedGroupKFold',\n",
    "        'RepeatedStratifiedKFold': 'sk.model_selection.RepeatedStratifiedKFold',\n",
    "        'RepeatedStratifiedGroupKFold': 'RepeatedStratifiedGroupKFold'\n",
    "    },\n",
    "    section='SETTINGS',\n",
    ") %}\n",
    "{% set algorithm = ChoiceField(\n",
    "    name='algorithm',\n",
    "    label='Machine Learning Algorithm',\n",
    "    default='ExtraTreesClassifier',\n",
    "    description='A machine learning algorithm should be selected to construct the predictive model.',\n",
    "    choices={\n",
    "        'GradientBoostingClassifier': 'sk.ensemble.GradientBoostingClassifier()',\n",
    "        'RandomForestClassifier': 'sk.ensemble.RandomForestClassifier(class_weight=\"balanced\")',\n",
    "        'AdaBoostClassifier': 'sk.ensemble.AdaBoostClassifier()',\n",
    "        'ExtraTreesClassifier': 'sk.ensemble.ExtraTreesClassifier(class_weight=\"balanced\")',\n",
    "        'DecisionTreeClassifier': 'sk.tree.DecisionTreeClassifier(class_weight=\"balanced\")',\n",
    "        'KNeighborsClassifier': 'sk.neighbors.KNeighborsClassifier()',\n",
    "        'RadiusNeighborsClassifier': 'sk.neighbors.RadiusNeighborsClassifier()',\n",
    "        'MLPClassifier': 'sk.neural_network.MLPClassifier()',\n",
    "        'OneClassSVM': 'sk.svm.OneClassSVM()',\n",
    "    },\n",
    "    section='SETTINGS'\n",
    ") %}\n",
    "{% set calibrated = BoolField(\n",
    "    name='calibrated',\n",
    "    label='Calibrate algorithm predictions',\n",
    "    description='Calibrate the prediction probabilities eliminating model-imparted bias.',\n",
    "    default=True,\n",
    "    section='SETTINGS',\n",
    ") %}\n",
    "{% set hyper_param_search = ChoiceField(\n",
    "    name='hyper_param_search',\n",
    "    label='Hyper Parameter Search Type',\n",
    "    default='None',\n",
    "    description='Hyper parameter searching is used to automatically select the best parameters (using the primary metric as the criteria).',\n",
    "    choices={\n",
    "        'None': 'None',\n",
    "        'RandomizedSearchCV': 'sk.model_selection.RandomizedSearchCV',\n",
    "        'GridSearchCV': 'sk.model_selection.GridSearchCV',\n",
    "    },\n",
    "    section='SETTINGS'\n",
    ") %}\n",
    "{% set cross_validation_n_folds = IntField(\n",
    "    name='cross_validation_n_folds',\n",
    "    label='Cross-Validated Folds',\n",
    "    description='Cross validation is employed as a strategy to train the model on data that the model has not seen before, more folds will ensure that the model is generalizing well.',\n",
    "    default=3,\n",
    "    min=2,\n",
    "    max=10,\n",
    "    section='SETTINGS'\n",
    ") %}\n",
    "{% set primary_metric = ChoiceField(\n",
    "    name='primary_metric',\n",
    "    label='Primary Evaluation Metric',\n",
    "    default='roc_auc',\n",
    "    description='The primary evaluation metric is used for deciding how we assess the performance of our model.',\n",
    "    choices=[\n",
    "        'accuracy',\n",
    "        'adjusted_mutual_info_score',\n",
    "        'adjusted_rand_score',\n",
    "        'average_precision',\n",
    "        'balanced_accuracy',\n",
    "        'completeness_score',\n",
    "        'explained_variance',\n",
    "        'f1',\n",
    "        'f1_macro',\n",
    "        'f1_micro',\n",
    "        'f1_weighted',\n",
    "        'fowlkes_mallows_score',\n",
    "        'homogeneity_score',\n",
    "        'jaccard',\n",
    "        'jaccard_macro',\n",
    "        'jaccard_micro',\n",
    "        'jaccard_weighted',\n",
    "        'max_error',\n",
    "        'mutual_info_score',\n",
    "        'neg_brier_score',\n",
    "        'neg_log_loss',\n",
    "        'neg_mean_absolute_error',\n",
    "        'neg_mean_squared_error',\n",
    "        'neg_mean_squared_log_error',\n",
    "        'neg_median_absolute_error',\n",
    "        'neg_root_mean_squared_error',\n",
    "        'normalized_mutual_info_score',\n",
    "        'precision',\n",
    "        'precision_macro',\n",
    "        'precision_micro',\n",
    "        'precision_weighted',\n",
    "        'r2',\n",
    "        'recall',\n",
    "        'recall_macro',\n",
    "        'recall_micro',\n",
    "        'recall_weighted',\n",
    "        'roc_auc',\n",
    "        'roc_auc_ovo',\n",
    "        'roc_auc_ovo_weighted',\n",
    "        'roc_auc_ovr',\n",
    "        'roc_auc_ovr_weighted',\n",
    "        'v_measure_score'\n",
    "    ],\n",
    "    section='SETTINGS'\n",
    ") %}\n",
    "{% set evaluation_metrics = MultiChoiceField(\n",
    "    name='evaluation_metrics',\n",
    "    label='Evaluation Metrics',\n",
    "    default=[],\n",
    "    description='Additional evaluation metrics can be specified, these metrics will also be reported for all models trained.',\n",
    "    value=[],\n",
    "    choices=[\n",
    "        'accuracy',\n",
    "        'adjusted_mutual_info_score',\n",
    "        'adjusted_rand_score',\n",
    "        'average_precision',\n",
    "        'balanced_accuracy',\n",
    "        'completeness_score',\n",
    "        'explained_variance',\n",
    "        'f1',\n",
    "        'f1_macro',\n",
    "        'f1_micro',\n",
    "        'f1_weighted',\n",
    "        'fowlkes_mallows_score',\n",
    "        'homogeneity_score',\n",
    "        'jaccard',\n",
    "        'jaccard_macro',\n",
    "        'jaccard_micro',\n",
    "        'jaccard_weighted',\n",
    "        'max_error',\n",
    "        'mutual_info_score',\n",
    "        'neg_brier_score',\n",
    "        'neg_log_loss',\n",
    "        'neg_mean_absolute_error',\n",
    "        'neg_mean_squared_error',\n",
    "        'neg_mean_squared_log_error',\n",
    "        'neg_median_absolute_error',\n",
    "        'neg_root_mean_squared_error',\n",
    "        'normalized_mutual_info_score',\n",
    "        'precision',\n",
    "        'precision_macro',\n",
    "        'precision_micro',\n",
    "        'precision_weighted',\n",
    "        'r2',\n",
    "        'recall',\n",
    "        'recall_macro',\n",
    "        'recall_micro',\n",
    "        'recall_weighted',\n",
    "        'roc_auc',\n",
    "        'roc_auc_ovo',\n",
    "        'roc_auc_ovo_weighted',\n",
    "        'roc_auc_ovr',\n",
    "        'roc_auc_ovr_weighted',\n",
    "        'v_measure_score'\n",
    "    ],\n",
    "    section='SETTINGS',\n",
    ") %}\n",
    "{% set all_metrics = [primary_metric.value] + evaluation_metrics.value %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "\n",
    "We apply a {% if hyper_param_search.value != 'None' %}{{ hyper_param_search.raw_value }} search for the hyper parameters\n",
    "of a {% endif %}sklearn pipeline with a dimensionality reduction step of {{ dimensionality_reduction.raw_value }}\n",
    "{% if feature_selection.value != 'None' %}and a feature selection step of {{ feature_selection.raw_value }}\n",
    "{% endif %} and a{% if calibrated.value %} calibrated{%endif %} {{ algorithm.raw_value }} classifier\n",
    "using {{ cross_validation_n_folds.value }}-fold {{ cv_algorithm.raw_value }} cross-validation,\n",
    "optimizing {{ primary_metric.value }}{% if evaluation_metrics.value %} and computing {{ ', '.join(evaluation_metrics.value) }}{% endif %}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will take a long time as we are evaluating n_iter different models n_splits different times each computing all the metrics on `product(X.shape)` data points--not to mention the size of each model dictated by the range of parameters specified in the params dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "{% if algorithm.value == 'GradientBoostingClassifier' %}\n",
    "## Early stopping function\n",
    "def early_stopping(n_rounds, tol=0.001):\n",
    "    def early_stopping_func(i, self, local):\n",
    "        rounds = getattr(self, '__rounds', 0)\n",
    "        last = getattr(self, '__last', None)\n",
    "        current = self.train_score_[i]\n",
    "        if last and current and abs(current - last) < tol:\n",
    "            rounds += 1\n",
    "            if rounds > n_rounds:\n",
    "                return True\n",
    "        else:\n",
    "            rounds = 0\n",
    "        setattr(self, '__last', current)\n",
    "        setattr(self, '__rounds', rounds)\n",
    "        return False\n",
    "    return early_stopping_func\n",
    "{% endif %}\n",
    "\n",
    "{#\n",
    "param_grid = {\n",
    "    'reduce_dim__n_components': randint(2, 1024),\n",
    "{% if algorithm.value == 'GradientBoostingClassifier' %}\n",
    "    'clf__loss': ['deviance', 'exponential'],\n",
    "    'clf__learning_rate': randfloat(0.001, 1.),\n",
    "    'clf__subsample': randfloat(0.01, 1.),\n",
    "{% elif algorithm.value == 'RandomForestClassifier' %}\n",
    "    'clf__oob_score': [True],\n",
    "    'clf__criterion': ['gini', 'entropy'],\n",
    "{% endif %}\n",
    "    'clf__n_estimators': randint(10, 200),\n",
    "    'clf__max_depth': randint(20, 50),\n",
    "    'clf__max_features': ['sqrt', 'log2', None],\n",
    "    'clf__min_impurity_decrease': randfloat(0., 0.2),\n",
    "    'clf__min_weight_fraction_leaf': randfloat(0., 0.5),\n",
    "}\n",
    "\n",
    "fit_params = {\n",
    "{% if algorithm.value == 'GradientBoostingClassifier' %}\n",
    "    'clf__monitor': early_stopping(5),\n",
    "{% endif %}\n",
    "}\n",
    "#}\n",
    "    \n",
    "cv = {{ cv_algorithm }}(\n",
    "    n_splits={{ cross_validation_n_folds }},\n",
    "    shuffle=True,\n",
    "    random_state=rng,\n",
    ")\n",
    "\n",
    "{% if cv_algorithm.value in ['GroupKFold', 'StratifiedGroupKFold'] %}\n",
    "groups=[key[:14] for key in X.index]    # Group compounds by atom connectivity\n",
    "{% endif %}\n",
    "\n",
    "model =\n",
    "{%- if hyper_param_search.value != 'None' %} {{ hyper_param_search }}({% endif -%}\n",
    "    {%- if calibrated.value %} sk.calibration.CalibratedClassifierCV({% endif -%}\n",
    "        sk.pipeline.Pipeline([\n",
    "            {%- if dimensionality_reduction.value != 'None' %}('reduce_dim', {{ dimensionality_reduction }}),{% endif %}\n",
    "            {%- if feature_selection.value != 'None' %}('feature_selection', {{ feature_selection }}),{% endif %}\n",
    "            ('clf', {{ algorithm }}),\n",
    "        ]),\n",
    "    {% if cv_algorithm.value in ['GroupKFold', 'StratifiedGroupKFold'] %}\n",
    "    cv={{ cross_validation_n_folds }},\n",
    "    {% else %}\n",
    "    cv=cv,\n",
    "    {% endif %}\n",
    "{% if calibrated.value %}){% endif -%}{%- if hyper_param_search.value != 'None' %}){% endif %}\n",
    "\n",
    "# Scoring parameters\n",
    "primary_metric = '{{ primary_metric }}'\n",
    "evaluation_metrics = {{ evaluation_metrics }}\n",
    "scoring_params = {k: metrics.get_scorer(k)\n",
    "                  for k in [primary_metric, *evaluation_metrics]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "{% if hyper_param_search.value == 'None' %}\n",
    "\n",
    "df_results = pd.DataFrame()\n",
    "\n",
    "# Store performance on each split for computing ROC and PRC curves\n",
    "fprs = []\n",
    "tprs = []\n",
    "precs = []\n",
    "recs = []\n",
    "\n",
    "# Store cross-validation test predictions and folds\n",
    "y_proba_cv = np.empty(len(y))\n",
    "y_proba_cv[:] = np.nan\n",
    "folds_cv = np.empty(len(y)).astype(int)\n",
    "\n",
    "{% if cv_algorithm.value in ['GroupKFold', 'StratifiedGroupKFold'] %}\n",
    "groups=[key[:14] for key in X.index]    # Group compounds by atom connectivity\n",
    "for fold, (train, test) in enumerate(cv.split(X.values, y, groups=groups)):\n",
    "{% else %}\n",
    "for fold, (train, test) in enumerate(cv.split(X.values, y)):\n",
    "{% endif %}\n",
    "    model.fit(X.values[train], y[train])\n",
    "    {% for metric in all_metrics %}\n",
    "    df_results.loc[fold, '{{ metric }}'] = scoring_params['{{ metric }}'](model, X.values[test], y[test])\n",
    "    {% endfor %}\n",
    "    y_proba = model.predict_proba(X.values[test]) # Probability prediction will be True\n",
    "    y_proba_cv[test] = y_proba[:, 1]\n",
    "    folds_cv[test] = fold\n",
    "    model_fpr, model_tpr, _ = metrics.roc_curve(y[test], y_proba[:, 1])\n",
    "    model_prec, model_rec, _ = metrics.precision_recall_curve(y[test], y_proba[:, 1])\n",
    "    fprs.append(model_fpr)\n",
    "    tprs.append(model_tpr)\n",
    "    precs.append(model_prec)\n",
    "    recs.append(model_rec)\n",
    "\n",
    "assert not(any(np.isnan(y_proba_cv))), 'All probabilities should have been calculated'\n",
    "\n",
    "display(df_results.agg(['mean', 'std']))\n",
    "{% else %}\n",
    "model.fit(X.values, y)\n",
    "df_results = model.cv_results_\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This visualization shows the cross-validated performance of the model. Low fold variance and high AUC is desired in a well-generalized model.\n",
    "* ROC curve: [roc.svg](./roc.svg)\n",
    "* Precision-recall curve: [prc.svg](./prc.svg)\n",
    "* Confusion matrix: [confusion_matrix.svg](./confusion_matrix.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "tprs_interp = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "for fold, (fpr, tpr) in enumerate(zip(fprs, tprs)):\n",
    "    tpr_interp = np.interp(mean_fpr, fpr, tpr)\n",
    "    tpr_interp[0] = 0.\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    tprs_interp.append(tpr_interp)\n",
    "    aucs.append(roc_auc)\n",
    "    ax.plot(fpr, tpr, alpha=0.4, label='ROC Fold %d (AUC=%0.3f)' % (fold, roc_auc))\n",
    "\n",
    "mean_tpr = np.mean(tprs_interp, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = sk.metrics.auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "ax.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs_interp, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2)\n",
    "\n",
    "ax.plot([0,1],[0,1],'--', label='Random')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.legend()\n",
    "plt.savefig('roc.svg')\n",
    "plt.show()\n",
    "\n",
    "z = (mean_auc - 0.5)/std_auc\n",
    "cl = sp.stats.norm.cdf(z) * 100\n",
    "ci = sp.stats.norm.interval(0.95, loc=mean_auc, scale=std_auc)\n",
    "print('Confidence interval (95%)', ci)\n",
    "print(\"We are %0.3f %% confident the model's results are not just chance.\" % (cl))\n",
    "if cl > 95:\n",
    "    print('This is statistically significant. These results can be trusted.')\n",
    "else:\n",
    "    print('This is not statistically significant. These results should not be trusted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "precs_interp = []\n",
    "prc_aucs = []\n",
    "mean_rec = np.linspace(0, 1, 100)\n",
    "\n",
    "for fold, (rec, prec) in enumerate(zip(recs, precs)):\n",
    "    prec_interp = np.interp(mean_rec, rec[::-1], prec[::-1])\n",
    "    prc_auc = metrics.auc(rec, prec)\n",
    "    precs_interp.append(prec_interp)\n",
    "    prc_aucs.append(prc_auc)\n",
    "    ax.plot(rec, prec, alpha=0.4, label='PRC Fold %d (AUC=%0.3f)' % (fold, prc_auc))\n",
    "\n",
    "mean_prec = np.mean(precs_interp, axis=0)\n",
    "mean_auc = sk.metrics.auc(mean_rec, mean_prec)\n",
    "std_auc = np.std(prc_aucs)\n",
    "ax.plot(mean_rec, mean_prec, color='b',\n",
    "         label=r'Mean PRC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_prec = np.std(precs_interp, axis=0)\n",
    "precs_upper = np.minimum(mean_prec + std_prec, 1)\n",
    "precs_lower = np.maximum(mean_prec - std_prec, 0)\n",
    "plt.fill_between(mean_rec, precs_lower, precs_upper, color='grey', alpha=.2)\n",
    "\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.legend()\n",
    "plt.savefig('prc.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Confusion Matrix (Cross-Validation)')\n",
    "sns.heatmap(\n",
    "    metrics.confusion_matrix(y, y_proba_cv > 0.5),\n",
    "    annot=True,\n",
    "    cmap=plt.cm.Blues,\n",
    "    fmt='g'\n",
    ")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.savefig('confusion_matrix.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine drug predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the binary classification model, we can rank the drug hits by their predicted score. The model can also be used to identify additional drugs that are likely to share properties with the hits. The results table is available at [drug_cv_predictions.csv](./drug_cv_predictions.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "# Obtain prediction results\n",
    "y_probas = y_proba_cv\n",
    "results = pd.DataFrame(np.array([\n",
    "    querysepl1000fwd.get_drug_names(X.index),\n",
    "    Drugmonizome.get_drug_names(X.index),\n",
    "    folds_cv,\n",
    "    y,\n",
    "    (y_probas > 0.5).astype('float64'),\n",
    "    y_probas,\n",
    "]).T, columns=[\n",
    "    'Name (L1000FWD)',\n",
    "    'Name (Drugmonizome)',\n",
    "    'Cross-validation fold',\n",
    "    'Known',\n",
    "    'Predicted',\n",
    "    'Prediction Probability',\n",
    "], index=X.index).astype({'Known': 'float64',\n",
    "                          'Predicted': 'float64',\n",
    "                          'Prediction Probability': 'float64'})\n",
    "\n",
    "results.to_csv('drug_cv_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Rank drug hits\n",
    "results[((results['Known'] == 1))].sort_values('Prediction Probability', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Predict additional drugs\n",
    "results[results['Known'] == 0].sort_values('Prediction Probability', ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine feature importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relative contribution of each input feature to the final model predictions can be estimated for a variety of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "\n",
    "{% if feature_selection.raw_value == 'RecursiveSelectionFromExtraTrees' %}\n",
    "When recursive feature selection is performed, the features are ranked by the stage at which they were removed.\n",
    "Selected (i.e. estimated best) features are have importance 1. The ranks are averaged across cross-validation\n",
    "splits to produce an average importance score. The full feature importance table is available at\n",
    "[feature_importance.csv](./feature_importance.csv).\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "{% if feature_selection.raw_value == 'RecursiveSelectionFromExtraTrees' %}\n",
    "df_feat_imp = pd.DataFrame({'Feature': X.columns,\n",
    "                            'Dataset': reduce(lambda a,b: a+b, ([dataset]*size for dataset, size in dataset_sizes)),\n",
    "                            'Importance': np.mean([calibrated_clf.base_estimator['feature_selection'].ranking_\n",
    "                                                   for calibrated_clf in model.calibrated_classifiers_],\n",
    "                                                  axis=0)})\n",
    "df_feat_imp = df_feat_imp.set_index('Feature').sort_values('Importance')\n",
    "display(df_feat_imp.head(25))\n",
    "df_feat_imp.to_csv('feature_importance.csv')\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "\n",
    "{% if feature_selection.raw_value == 'RecursiveSelectionFromExtraTrees' %}\n",
    "Plot the distribution of importance scores for features in each dataset ([feature_importance.svg](./feature_importance.svg)).\n",
    "Features with lower scores were retained for more rounds during recursive feature selection\n",
    "and have greater relative importance.\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "{% if feature_selection.raw_value == 'RecursiveSelectionFromExtraTrees' %}\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "for dataset in set(df_feat_imp.Dataset):\n",
    "    importance_scores = df_feat_imp.loc[df_feat_imp.Dataset == dataset].Importance.values\n",
    "    axs[0].plot(importance_scores, label=dataset)\n",
    "axs[0].set_xlabel('Ranked features (absolute count)')\n",
    "axs[0].set_ylabel('Average importance\\n(lower score is more important)')\n",
    "axs[0].legend()\n",
    "axs[0].set_title('Distribution of feature scores')\n",
    "for dataset in set(df_feat_imp.Dataset):\n",
    "    importance_scores = df_feat_imp.loc[df_feat_imp.Dataset == dataset].Importance.values\n",
    "    axs[1].plot(np.linspace(0, 1, len(importance_scores)), importance_scores, label=dataset)\n",
    "axs[1].set_xlabel('Ranked features (relative count)')\n",
    "axs[1].set_ylabel('Average importance\\n(lower score is more important)')\n",
    "axs[1].legend()\n",
    "axs[1].set_title('Distribution of feature scores')\n",
    "plt.savefig('feature_importance.svg')\n",
    "plt.show()\n",
    "{% endif %}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdkit-dml-env",
   "language": "python",
   "name": "rdkit-dml-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
