{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%appyter init\n",
    "import os, sys; sys.path.insert(0, os.path.realpath('..'))\n",
    "from appyter import magic\n",
    "magic.init(lambda _=globals: _())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Imports\n",
    "## Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "## Machine Learning\n",
    "import sklearn as sk\n",
    "from sklearn import (\n",
    "    calibration,\n",
    "    decomposition,\n",
    "    ensemble,\n",
    "    feature_selection,\n",
    "    linear_model,\n",
    "    manifold,\n",
    "    metrics,\n",
    "    model_selection,\n",
    "    multioutput,\n",
    "    pipeline,\n",
    "    preprocessing,\n",
    "    svm,\n",
    "    tree,\n",
    "    feature_extraction,\n",
    ")\n",
    "from split import StratifiedGroupKFold, RepeatedStratifiedGroupKFold\n",
    "import umap\n",
    "## Plotting\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "## Drugmonizome API\n",
    "# from drugmonizome import Drugmonizome\n",
    "## SEP-L1000 data retrieval\n",
    "from sepl1000 import SEPL1000\n",
    "## L1000FWD queries\n",
    "import querysepl1000fwd\n",
    "## Match drug name inputs using PubChem API\n",
    "# from DrugNameConverter import DrugNameConverter\n",
    "# Utility\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from functools import reduce\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = 2020\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Input Datasets and Target Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selected drug set libraries and omics datasets are downloaded and joined on the drug to produce a large association matrix. A machine learning model will be trained to predict the specified target labels from this association matrix. This is a binary classification task that can be used to predict drugs that are likely to be associated with the target class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter hide\n",
    "{% do SectionField(\n",
    "    title='Attribute Dataset Selection',\n",
    "    subtitle='Select the input datasets to use for learning and classification. \\\n",
    "              A model will be trained to predict the target labels from the selected attributes. \\\n",
    "              If no datasets are selected, default attributes will be used.',\n",
    "    name='ATTRIBUTES',\n",
    "    img='attributes.png',\n",
    ") %}\n",
    "\n",
    "{% set sepl1000datasets = MultiChoiceField(\n",
    "    name='sepl1000datasets',\n",
    "    label='SEP-L1000',\n",
    "    description='These input datasets were used previously for side effect prediction (https://maayanlab.net/SEP-L1000/).',\n",
    "    choices=[\n",
    "        'LINCS Gene Expression Signatures',\n",
    "        'GO Transformed Signatures (PAEA)',\n",
    "        'MLPCN Cell Morphological Profiling',\n",
    "        'MACCS Chemical Fingerprint',\n",
    "    ],\n",
    "    default=['LINCS Gene Expression Signatures', 'GO Transformed Signatures (PAEA)'],\n",
    "    section='ATTRIBUTES'\n",
    ") %}\n",
    "\n",
    "{% set exprdatasets = MultiChoiceField(\n",
    "    name='exprdatasets',\n",
    "    label='L1000FWD (drug sets)',\n",
    "    choices=[\n",
    "        'L1000FWD Downregulated GO Biological Processes',\n",
    "        'L1000FWD Downregulated GO Cellular Components',\n",
    "        'L1000FWD Downregulated GO Molecular Function',\n",
    "        'L1000FWD Downregulated KEGG Pathways',\n",
    "        'L1000FWD Downregulated Signatures',\n",
    "        'L1000FWD Predicted Side Effects',\n",
    "        'L1000FWD Upregulated GO Biological Process',\n",
    "        'L1000FWD Upregulated GO Cellular Components',\n",
    "        'L1000FWD Upregulated GO Molecular Function',\n",
    "        'L1000FWD Upregulated KEGG Pathways',\n",
    "        'L1000FWD Upregulated Signatures',\n",
    "    ],\n",
    "    default=[],\n",
    "    section='ATTRIBUTES'\n",
    ") %}\n",
    "\n",
    "{% set targetdatasets = MultiChoiceField(\n",
    "    name='targetdatasets',\n",
    "    label='Drug Targets and Associated Genes (drug sets)',\n",
    "    choices=[\n",
    "        'Downregulated CREEDS Signatures',\n",
    "        'Upregulated CREEDS Signatures',\n",
    "        'DrugCentral Targets',\n",
    "        'DrugRepurposingHub Drug Targets',\n",
    "        'Drugbank Small Molecule Carriers',\n",
    "        'Drugbank Small Molecule Enzymes',\n",
    "        'Drugbank Small Molecule Targets',\n",
    "        'Drugbank Small Molecule Transporters',\n",
    "        'Geneshot Associated Genes',\n",
    "        'Geneshot Predicted AutoRIF Genes',\n",
    "        'Geneshot Predicted Coexpression Genes',\n",
    "        'Geneshot Predicted Enrichr Genes',\n",
    "        'Geneshot Predicted GeneRIF Genes',\n",
    "        'Geneshot Predicted Tagger Genes',\n",
    "        'KinomeScan Kinases',\n",
    "        'PharmGKB Single Nucleotide Polymorphisms',\n",
    "        'STITCH Targets',\n",
    "    ],\n",
    "    default=[],\n",
    "    section='ATTRIBUTES'\n",
    ") %}\n",
    "\n",
    "{% set indicationdatasets = MultiChoiceField(\n",
    "    name='indicationdatasets',\n",
    "    label='Indications, Modes of Action, and Side Effects (drug sets)',\n",
    "    choices=[\n",
    "        'ATC Codes Drugsetlibrary',\n",
    "        'DrugRepurposingHub Mechanisms of Action',\n",
    "        'PharmGKB OFFSIDES Side Effects',\n",
    "        'SIDER Indications',\n",
    "        'SIDER Side Effects',\n",
    "    ],\n",
    "    default=[],\n",
    "    section='ATTRIBUTES'\n",
    ") %}\n",
    "\n",
    "{% set structuraldatasets = MultiChoiceField(\n",
    "    name='structuraldatasets',\n",
    "    label='Structural Features (drug sets)',\n",
    "    choices=[\n",
    "        'RDKIT MACCS Chemical Fingerprints'\n",
    "    ],\n",
    "    default=[],\n",
    "    section='ATTRIBUTES'\n",
    ") %}\n",
    "\n",
    "{% set keepmissing = BoolField(\n",
    "    name='keepmissing',\n",
    "    label='Keep drugs with missing data when joining datasets',\n",
    "    description='Keep drugs that appear in some datasets and not in others. \\\n",
    "                 Missing data is filled in with zeros. Otherwise, only drugs \\\n",
    "                 that are present in all datasets are preserved.',\n",
    "    default=False,\n",
    "    section='ATTRIBUTES',\n",
    ") %}\n",
    "\n",
    "{% set tfidf = BoolField(\n",
    "    name='tfidf',\n",
    "    label='Apply tfâ€“idf normalization to binary inputs',\n",
    "    description='For binary drug-attribute associations in the input matrix, \\\n",
    "                 apply tf-idf transformation to normalize data.',\n",
    "    default=True,\n",
    "    section='ATTRIBUTES',\n",
    ") %}\n",
    "\n",
    "{% set attribute_datasets = exprdatasets.value +\n",
    "                             targetdatasets.value +\n",
    "                             indicationdatasets.value +\n",
    "                             structuraldatasets.value %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "\n",
    "To construct the input matrix, we download drug set libraries and omics datasets and join them on the InChI Key.\n",
    "{% if keepmissing.value %} Drugs that appear in some datasets and not in others are retained, and missing data is filled in with zeros.\n",
    "{% else %} Only drugs that are present in all datasets are retained.\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%%appyter hide\n",
    "{% do SectionField(\n",
    "    title='Target Label Selection',\n",
    "    subtitle='Upload a list of drugs to be given positive class labels for binary classification. \\\n",
    "              Drugs should be in a text file, specified by either drug name or InChI Key and separated by newlines. \\\n",
    "              If no file is selected, a default list of hits from COVID-19 drug screens will be used.',\n",
    "    name='TARGET',\n",
    "    img='target.png',\n",
    ") %}\n",
    "\n",
    "{% set drugformat = ChoiceField(\n",
    "    name='drugformat',\n",
    "    label='Drug Identifier Format',\n",
    "    default='InChI Key',\n",
    "    choices=[\n",
    "        'Drug Name',\n",
    "        'InChI Key'\n",
    "    ],\n",
    "    section='TARGET'\n",
    ") %}\n",
    "\n",
    "{% set drughitlist = FileField(\n",
    "    name='drughitlist',\n",
    "    label='Upload List of Drug Hits',\n",
    "    default='COVID19ScreenHitsInChIKeys.txt',\n",
    "    examples={\n",
    "        'COVID19ScreenHits.txt': 'https://appyters.maayanlab.cloud/storage/Drugmonizome_ML/COVID19ScreenHits.txt',\n",
    "        'COVID19ScreenHitsInChIKeys.txt': 'https://appyters.maayanlab.cloud/storage/Drugmonizome_ML/COVID19ScreenHitsInChIKeys.txt',\n",
    "    },\n",
    "    section='TARGET'\n",
    ") %}\n",
    "\n",
    "{% set includestereo = BoolField(\n",
    "    name='includestereo',\n",
    "    label='Include stereoisomers',\n",
    "    description='If true, drugs are matched to entries in the datasets by the first 14 characters of their InChI Keys, \\\n",
    "                 so stereoisomers of the drugs in the input list are also counted as hits. \\\n",
    "                 Note that different resources record different details for charge and stereochemistry, \\\n",
    "                 causing some drugs to have different full-length InChI Keys in different datasets. \\\n",
    "                 Selecting this option may allow such drugs to be better matched to entries in the datasets.',\n",
    "    default=True,\n",
    "    section='TARGET',\n",
    ") %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "# Use the selected SEP-L1000 datasets\n",
    "sepl1000datasets = {{ sepl1000datasets }}\n",
    "\n",
    "name_to_file = {\n",
    "    'LINCS Gene Expression Signatures': 'LINCS_Gene_Experssion_signatures_CD.csv.gz',\n",
    "    'GO Transformed Signatures (PAEA)': 'GO_transformed_signatures_PAEA.csv.gz',\n",
    "    'MLPCN Cell Morphological Profiling': 'MLPCN_morplological_profiles.csv.gz',\n",
    "    'MACCS Chemical Fingerprint': 'MACCS_bitmatrix.csv.gz',\n",
    "}\n",
    "\n",
    "df_sepl1000_list = list(SEPL1000.download_df(list(name_to_file[dataset] for dataset in sepl1000datasets),\n",
    "                                             index_col=0))\n",
    "dataset_sizes = list(zip(sepl1000datasets, [dataset.shape[1] for dataset in df_sepl1000_list]))\n",
    "\n",
    "# Assemble all SEP-L1000 datasets\n",
    "if len(df_sepl1000_list) > 1:\n",
    "    # Obtain merged dataframe with omics and target data\n",
    "    df_sepl1000 = reduce(\n",
    "        lambda a, b: pd.merge( # Merge two dataframes item by item\n",
    "            a, # left\n",
    "            b, # right\n",
    "            # Items with the same left and right index are merged\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            {% if keepmissing.value %}\n",
    "            how='outer', # Keep mis-matched indices\n",
    "            {% else %}\n",
    "            how='inner', # Keep only matched indices\n",
    "            {% endif %}\n",
    "        ),\n",
    "        df_sepl1000_list,\n",
    "    )\n",
    "else:\n",
    "    df_sepl1000 = df_sepl1000_list[0]\n",
    "\n",
    "# del(df_sepl1000_list)\n",
    "\n",
    "# Mean-fill infinite and missing values\n",
    "df_sepl1000 = df_sepl1000.replace([np.inf, -np.inf], np.nan)\n",
    "df_sepl1000 = df_sepl1000.fillna(np.mean(df_sepl1000))\n",
    "print('Total shape:', df_sepl1000.shape)\n",
    "display(df_sepl1000.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "{% if attribute_datasets == [] and sepl1000datasets == [] %}\n",
    "# No datasets selected, so use default datasets\n",
    "attribute_datasets = ['L1000FWD Downregulated Signatures',\n",
    "                      'L1000FWD Upregulated Signatures',\n",
    "                      'RDKIT MACCS Chemical Fingerprints']\n",
    "{% else %}\n",
    "# Use the selected attribute datasets\n",
    "attribute_datasets = {{ attribute_datasets }}\n",
    "{% endif %}\n",
    "\n",
    "{% if attribute_datasets == [] and sepl1000datasets != [] %}\n",
    "X = df_sepl1000\n",
    "{% else %}\n",
    "df_attributes = list(Drugmonizome.download_df(\n",
    "    [dataset\n",
    "     for dataset in attribute_datasets]\n",
    "))\n",
    "dataset_sizes += list(zip(sepl1000datasets, [dataset.shape[1] for dataset in df_sepl1000_list]))\n",
    "\n",
    "# Assemble all attribute datasets\n",
    "if len(df_attributes) > 1:\n",
    "    # Obtain merged dataframe with omics and target data\n",
    "    df = reduce(\n",
    "        lambda a, b: pd.merge( # Merge two dataframes item by item\n",
    "            a, # left\n",
    "            b, # right\n",
    "            # Items with the same left and right index are merged\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            {% if keepmissing.value %}\n",
    "            how='outer', # Keep mis-matched indices\n",
    "            {% else %}\n",
    "            how='inner', # Keep only matched indices\n",
    "            {% endif %}\n",
    "        ),\n",
    "        df_attributes,\n",
    "    )\n",
    "else:\n",
    "    df = df_attributes[0]\n",
    "\n",
    "df = df.fillna(0)\n",
    "X = df.applymap(lambda f: 1 if f!=0 else 0)\n",
    "{% if tfidf.value %}\n",
    "# Apply tf-idf normalization\n",
    "transformer = feature_extraction.text.TfidfTransformer()\n",
    "X_tfidf = transformer.fit_transform(X)\n",
    "X = pd.DataFrame.sparse.from_spmatrix(X_tfidf, columns=X.columns, index=X.index)\n",
    "X = pd.merge(df_sepl1000, X, left_index=True, right_index=True)\n",
    "{% endif %}\n",
    "{% endif %}\n",
    "\n",
    "print('Total shape:', X.shape)\n",
    "display(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "\n",
    "The target labels are produced from the uploaded list of hits: 1 if the drug is specified as a hit, 0 otherwise.\n",
    "{% if drugformat.value == 'Drug Name' %} Drug names are matched to InChI Keys from the Drugmonizome metadata.\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "{% if drughitlist.value == '' %}\n",
    "# Using default list of hits from COVID-19 in vitro drug screens\n",
    "hits_filename = '../../COVID19ScreenHits.txt'\n",
    "{% else %}\n",
    "# Using user-specified list of positive drug hits\n",
    "hits_filename = {{drughitlist}}\n",
    "{% endif %}\n",
    "\n",
    "{% if drugformat.value == 'InChI Key' %}\n",
    "# Read InChI Keys from file\n",
    "with open(hits_filename, 'r') as hits_file:\n",
    "    drug_hits = set(drug.strip().upper() for drug in hits_file.read().strip().split('\\n') \n",
    "                    if len(drug.strip()) > 0)\n",
    "\n",
    "{% elif drugformat.value == 'Drug Name' %}\n",
    "# Helper functions\n",
    "def merge(A, B, f):\n",
    "    \"\"\"\n",
    "    Merges two dictionaries, where items from shared keys are merged using a custom function.\n",
    "    \"\"\"\n",
    "    merged = {k: A.get(k, B.get(k)) for k in A.keys() ^ B.keys()}\n",
    "    merged.update({k: f(A[k], B[k]) for k in A.keys() & B.keys()})\n",
    "    return merged\n",
    "def save_items(out_file, items):\n",
    "    \"\"\"\n",
    "    Saves list of items as rows in a file.\n",
    "    \"\"\"\n",
    "    with open(out_file, 'w') as f:\n",
    "        for i in range(len(items)):\n",
    "            if i < len(items) - 1:\n",
    "                f.write(items[i] + '\\n')\n",
    "            else:\n",
    "                f.write(items[i])\n",
    "\n",
    "def save_gmt(out_file, keys_to_sets, sep='\\t'):\n",
    "    \"\"\"\n",
    "    Saves dict with key-set pairs as gmt file format.\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "    for key in sorted(keys_to_sets):\n",
    "        lines.append(key + sep*2 + sep.join(sorted(keys_to_sets[key])))\n",
    "    save_items(out_file, lines)\n",
    "\n",
    "# Read drug names from file\n",
    "with open(hits_filename, 'r') as hits_file:\n",
    "    drug_hits = set(drug.strip().lower() for drug in hits_file.read().strip().split('\\n') \n",
    "                    if len(drug.strip()) > 0)\n",
    "\n",
    "# Query PubChem API to map drug names to InChI Keys\n",
    "print('Querying PubChem API...')\n",
    "drug_hits_inchi_pubchem = DrugNameConverter.batch_to_inchi_keys(drug_hits)\n",
    "# Query Drugmonizome API to map drug names to InChI Keys\n",
    "print('Querying Drugmonizome API...')\n",
    "drug_hits_inchi_drugmonizome = Drugmonizome.map_names_to_inchi_keys(drug_hits)\n",
    "# Query L1000FWD API to map drug names to InChI Keys\n",
    "print('Querying L1000FWD API...')\n",
    "drug_hits_inchi_l1000fwd = querysepl1000fwd.map_names_to_inchi_keys(drug_hits)\n",
    "\n",
    "# Combine InChI Keys from all resources\n",
    "drug_hits_inchi = merge(drug_hits_inchi_pubchem, drug_hits_inchi_drugmonizome, lambda s1, s2: s1 | s2)\n",
    "drug_hits_inchi = merge(drug_hits_inchi, drug_hits_inchi_l1000fwd, lambda s1, s2: s1 | s2)\n",
    "save_gmt('hits_drug_name_to_inchi_keys.gmt', drug_hits_inchi)\n",
    "# Unmatched drug names\n",
    "unmatched_drugs = set(drug for drug in drug_hits\n",
    "                      if drug not in drug_hits_inchi or len(drug_hits_inchi[drug]) == 0)\n",
    "print(f'Drugs without InChI Keys ({ len(unmatched_drugs) }/{ len(drug_hits) }):', unmatched_drugs)\n",
    "\n",
    "# Set of InChI Keys for user-specified hits\n",
    "drug_hits = set(key for drug in drug_hits_inchi\n",
    "                    for key in drug_hits_inchi[drug])\n",
    "save_items('hits_inchi_keys.txt', sorted(drug_hits))\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "\n",
    "{% if drugformat.value == 'Drug Name' %}\n",
    "For the user-inputted drug names:\n",
    "* Mapping of drug name to InChI Key: [hits_drug_name_to_inchi_keys.gmt](./hits_drug_name_to_inchi_keys.gmt)\n",
    "* List of InChI Keys: [hits_inchi_keys.txt](./hits_inchi_keys.txt)\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We produce a target array containing 1 if the drug is specified as a hit and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "{% if includestereo.value %}\n",
    "# Match first 14 characters of InChI Keys (hash of InChI connectivity information)\n",
    "drug_hits_inchi_main_layer = set(key[:14] for key in drug_hits)\n",
    "y = np.array([drug[:14] in drug_hits_inchi_main_layer for drug in X.index]).astype(np.int8)\n",
    "{% else %}\n",
    "# Match full InChI Keys\n",
    "y = np.array([drug in drug_hits for drug in X.index]).astype(np.int8)\n",
    "{% endif %}\n",
    "print('Number of hits matched in input: %d (%0.3f %%)' % (y.sum(), 100*y.sum()/len(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output data shapes\n",
    "print('Input shape:', X.shape)\n",
    "print('Target shape:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter hide\n",
    "{% do SectionField(\n",
    "    title='Machine Learning Pipeline',\n",
    "    subtitle='Select from available machine learning algorithms, their unique settings, and methods to use to evaluate the classifier.',\n",
    "    name='SETTINGS',\n",
    "    img='settings.png',\n",
    ") %}\n",
    "\n",
    "{% set visualization_reduction = ChoiceField(\n",
    "    name='visualization_reduction',\n",
    "    label='Data Visualization Method',\n",
    "    description='A dimensionality reduction algorithm should be selected for data visualization.',\n",
    "    default='UMAP',\n",
    "    choices={\n",
    "        'UMAP': 'umap.UMAP(random_state=rng)',\n",
    "        'NMF': 'sk.decomposition.NMF(n_components=2)',\n",
    "        'PCA': 'sk.decomposition.PCA(n_components=2)',\n",
    "        'TruncatedSVD': 'sk.decomposition.TruncatedSVD(n_components=2)',\n",
    "        'IncrementalPCA': 'sk.decomposition.IncrementalPCA(n_components=2)',\n",
    "        'ICA': 'sk.decomposition.FastICA(n_components=2)',\n",
    "        'SparsePCA': 'sk.decomposition.SparsePCA(n_components=2)',\n",
    "    },\n",
    "    section='SETTINGS'\n",
    ") %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "\n",
    "We reduce the dimensionality of our omics feature space for visualization with {{ visualization_reduction.raw_value }}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "clf_dimensionality_reduction = {{ visualization_reduction }}\n",
    "X_reduced = clf_dimensionality_reduction.fit_transform(X.values)\n",
    "{% if visualization_reduction.raw_value == 'PCA' %}\n",
    "print('Explained variance:', np.sum(clf_dimensionality_reduction.explained_variance_))\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced_df = pd.DataFrame(X_reduced, columns=['Component 1', 'Component 2'])\n",
    "X_reduced_df['Drug Name'] = querysepl1000fwd.get_drug_names(X.index)\n",
    "X_reduced_df['InChI Key'] = X.index\n",
    "X_reduced_df['Label'] = y\n",
    "X_reduced_df['marker symbol'] = ['x' if label else 'circle' for label in X_reduced_df['Label']]\n",
    "X_reduced_df['text'] = ['<br>'.join(['Drug Name: ' + str(name),\n",
    "                                     'InChI Key: ' + str(inchi),\n",
    "                                     'Label: ' + str(label)])\n",
    "                        for name, inchi, label in zip(X_reduced_df['Drug Name'],\n",
    "                                                      X_reduced_df['InChI Key'],\n",
    "                                                      X_reduced_df['Label'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "fig = go.Figure()\n",
    "for label in set(X_reduced_df['Label']):\n",
    "    X_plot = X_reduced_df[X_reduced_df['Label'] == label].sort_values('Label')\n",
    "    fig.add_trace(go.Scatter(mode='markers',\n",
    "                             x=X_plot['Component 1'], y=X_plot['Component 2'],\n",
    "                             text=X_plot['text'],\n",
    "                             name=label,\n",
    "                             marker=dict(\n",
    "                                 color=['#0d0887', '#f0f921'][label%2],\n",
    "                                 size=8,\n",
    "                                 symbol=X_plot['marker symbol'],\n",
    "                                 line_width=1,\n",
    "                                 line_color='white'\n",
    "                             )))\n",
    "fig.update_layout(height=600, width=800,\n",
    "                  xaxis_title='Component 1',\n",
    "                  yaxis_title='Component 2',\n",
    "                  title_text='Known Labels ({{ visualization_reduction.raw_value }})',\n",
    "                  legend_title_text='Target Label',\n",
    "                  template='simple_white')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter hide\n",
    "{% set dimensionality_reduction = ChoiceField(\n",
    "    name='dimensionality_reduction',\n",
    "    label='Dimensionality Reduction Algorithm',\n",
    "    description='A dimensionality reduction algorithm should be selected to improve the quality of the classifier.',\n",
    "    default='None',\n",
    "    choices={\n",
    "        'None': 'None',\n",
    "        'PCA': 'sk.decomposition.PCA(n_components=64)',\n",
    "        'TruncatedSVD': 'sk.decomposition.TruncatedSVD(n_components=64)',\n",
    "        'IncrementalPCA': 'sk.decomposition.IncrementalPCA(n_components=64)',\n",
    "        'ICA': 'sk.decomposition.FastICA(n_components=64)',\n",
    "        'SparsePCA': 'sk.decomposition.SparsePCA(n_components=64)',\n",
    "    },\n",
    "    section='SETTINGS'\n",
    ") %}\n",
    "{% set feature_selection = ChoiceField(\n",
    "    name='feature_selection',\n",
    "    label='Machine Learning Feature Selection',\n",
    "    default='None',\n",
    "    choices={\n",
    "        'None': 'None',\n",
    "        'SelectFromLinearSVC': 'sk.feature_selection.SelectFromModel(sk.svm.LinearSVC(loss=\"squared_hinge\", penalty=\"l1\", dual=False, class_weight=\"balanced\"))',\n",
    "        'SelectFromExtraTrees': 'sk.feature_selection.SelectFromModel(sk.ensemble.ExtraTreesClassifier(class_weight=\"balanced\"))',\n",
    "        'RecursiveSelectionFromExtraTrees': 'sk.feature_selection.RFE(sk.ensemble.ExtraTreesClassifier(class_weight=\"balanced\"), n_features_to_select=256, step=0.1)',\n",
    "        'SelectKBest': 'sk.feature_selection.SelectKBest(\"f_classif\")',\n",
    "        'SelectKBestChi2': 'sk.feature_selection.SelectKBest(\"chi2\")',\n",
    "        'SelectKBestMultiInfo': 'sk.feature_selection.SelectKBest(\"mutual_info_classif\")',\n",
    "    },\n",
    "    section='SETTINGS'\n",
    ") %}\n",
    "{% set cv_algorithm = ChoiceField(\n",
    "    name='cv_algorithm',\n",
    "    label='Cross Validation Algorithm',\n",
    "    default='RepeatedStratifiedGroupKFold',\n",
    "    choices={\n",
    "        'KFold': 'sk.model_selection.KFold',\n",
    "        'GroupKFold': 'sk.model_selection.GroupKFold',\n",
    "        'RepeatedKFold': 'sk.model_selection.RepeatedKFold',\n",
    "        'StratifiedKFold': 'sk.model_selection.StratifiedKFold',\n",
    "        'StratifiedGroupKFold': 'StratifiedGroupKFold',\n",
    "        'RepeatedStratifiedKFold': 'sk.model_selection.RepeatedStratifiedKFold',\n",
    "        'RepeatedStratifiedGroupKFold': 'RepeatedStratifiedGroupKFold'\n",
    "    },\n",
    "    section='SETTINGS',\n",
    ") %}\n",
    "{% set algorithm = ChoiceField(\n",
    "    name='algorithm',\n",
    "    label='Machine Learning Algorithm',\n",
    "    default='RandomForestClassifier',\n",
    "    description='A machine learning algorithm should be selected to construct the predictive model.',\n",
    "    choices={\n",
    "        'GradientBoostingClassifier': 'sk.ensemble.GradientBoostingClassifier()',\n",
    "        'RandomForestClassifier': 'sk.ensemble.RandomForestClassifier(class_weight=\"balanced\", n_jobs=-1)',\n",
    "        'AdaBoostClassifier': 'sk.ensemble.AdaBoostClassifier()',\n",
    "        'ExtraTreesClassifier': 'sk.ensemble.ExtraTreesClassifier(class_weight=\"balanced\", n_jobs=-1)',\n",
    "        'DecisionTreeClassifier': 'sk.tree.DecisionTreeClassifier(class_weight=\"balanced\")',\n",
    "        'KNeighborsClassifier': 'sk.neighbors.KNeighborsClassifier()',\n",
    "        'RadiusNeighborsClassifier': 'sk.neighbors.RadiusNeighborsClassifier()',\n",
    "        'MLPClassifier': 'sk.neural_network.MLPClassifier()',\n",
    "        'OneClassSVM': 'sk.svm.OneClassSVM()',\n",
    "    },\n",
    "    section='SETTINGS'\n",
    ") %}\n",
    "{% set calibrated = BoolField(\n",
    "    name='calibrated',\n",
    "    label='Calibrate algorithm predictions',\n",
    "    description='Calibrate the prediction probabilities eliminating model-imparted bias.',\n",
    "    default=True,\n",
    "    section='SETTINGS',\n",
    ") %}\n",
    "{% set hyper_param_search = ChoiceField(\n",
    "    name='hyper_param_search',\n",
    "    label='Hyper Parameter Search Type',\n",
    "    default='None',\n",
    "    description='Hyper parameter searching is used to automatically select the best parameters (using the primary metric as the criteria).',\n",
    "    choices={\n",
    "        'None': 'None',\n",
    "        'RandomizedSearchCV': 'sk.model_selection.RandomizedSearchCV',\n",
    "        'GridSearchCV': 'sk.model_selection.GridSearchCV',\n",
    "    },\n",
    "    section='SETTINGS'\n",
    ") %}\n",
    "{% set cross_validation_n_folds = IntField(\n",
    "    name='cross_validation_n_folds',\n",
    "    label='Cross-Validated Folds',\n",
    "    description='Cross validation is employed as a strategy to train the model on data that the model has not seen before, more folds will ensure that the model is generalizing well.',\n",
    "    default=5,\n",
    "    min=2,\n",
    "    max=10,\n",
    "    section='SETTINGS'\n",
    ") %}\n",
    "{% set primary_metric = ChoiceField(\n",
    "    name='primary_metric',\n",
    "    label='Primary Evaluation Metric',\n",
    "    default='roc_auc',\n",
    "    description='The primary evaluation metric is used for deciding how we assess the performance of our model.',\n",
    "    choices=[\n",
    "        'accuracy',\n",
    "        'adjusted_mutual_info_score',\n",
    "        'adjusted_rand_score',\n",
    "        'average_precision',\n",
    "        'balanced_accuracy',\n",
    "        'completeness_score',\n",
    "        'explained_variance',\n",
    "        'f1',\n",
    "        'f1_macro',\n",
    "        'f1_micro',\n",
    "        'f1_weighted',\n",
    "        'fowlkes_mallows_score',\n",
    "        'homogeneity_score',\n",
    "        'jaccard',\n",
    "        'jaccard_macro',\n",
    "        'jaccard_micro',\n",
    "        'jaccard_weighted',\n",
    "        'max_error',\n",
    "        'mutual_info_score',\n",
    "        'neg_brier_score',\n",
    "        'neg_log_loss',\n",
    "        'neg_mean_absolute_error',\n",
    "        'neg_mean_squared_error',\n",
    "        'neg_mean_squared_log_error',\n",
    "        'neg_median_absolute_error',\n",
    "        'neg_root_mean_squared_error',\n",
    "        'normalized_mutual_info_score',\n",
    "        'precision',\n",
    "        'precision_macro',\n",
    "        'precision_micro',\n",
    "        'precision_weighted',\n",
    "        'r2',\n",
    "        'recall',\n",
    "        'recall_macro',\n",
    "        'recall_micro',\n",
    "        'recall_weighted',\n",
    "        'roc_auc',\n",
    "        'roc_auc_ovo',\n",
    "        'roc_auc_ovo_weighted',\n",
    "        'roc_auc_ovr',\n",
    "        'roc_auc_ovr_weighted',\n",
    "        'v_measure_score'\n",
    "    ],\n",
    "    section='SETTINGS'\n",
    ") %}\n",
    "{% set evaluation_metrics = MultiChoiceField(\n",
    "    name='evaluation_metrics',\n",
    "    label='Evaluation Metrics',\n",
    "    default=[],\n",
    "    description='Additional evaluation metrics can be specified, these metrics will also be reported for all models trained.',\n",
    "    value=[],\n",
    "    choices=[\n",
    "        'accuracy',\n",
    "        'adjusted_mutual_info_score',\n",
    "        'adjusted_rand_score',\n",
    "        'average_precision',\n",
    "        'balanced_accuracy',\n",
    "        'completeness_score',\n",
    "        'explained_variance',\n",
    "        'f1',\n",
    "        'f1_macro',\n",
    "        'f1_micro',\n",
    "        'f1_weighted',\n",
    "        'fowlkes_mallows_score',\n",
    "        'homogeneity_score',\n",
    "        'jaccard',\n",
    "        'jaccard_macro',\n",
    "        'jaccard_micro',\n",
    "        'jaccard_weighted',\n",
    "        'max_error',\n",
    "        'mutual_info_score',\n",
    "        'neg_brier_score',\n",
    "        'neg_log_loss',\n",
    "        'neg_mean_absolute_error',\n",
    "        'neg_mean_squared_error',\n",
    "        'neg_mean_squared_log_error',\n",
    "        'neg_median_absolute_error',\n",
    "        'neg_root_mean_squared_error',\n",
    "        'normalized_mutual_info_score',\n",
    "        'precision',\n",
    "        'precision_macro',\n",
    "        'precision_micro',\n",
    "        'precision_weighted',\n",
    "        'r2',\n",
    "        'recall',\n",
    "        'recall_macro',\n",
    "        'recall_micro',\n",
    "        'recall_weighted',\n",
    "        'roc_auc',\n",
    "        'roc_auc_ovo',\n",
    "        'roc_auc_ovo_weighted',\n",
    "        'roc_auc_ovr',\n",
    "        'roc_auc_ovr_weighted',\n",
    "        'v_measure_score'\n",
    "    ],\n",
    "    section='SETTINGS',\n",
    ") %}\n",
    "{% set all_metrics = [primary_metric.value] + evaluation_metrics.value %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "\n",
    "We apply a {% if hyper_param_search.value != 'None' %}{{ hyper_param_search.raw_value }} search for the hyper parameters\n",
    "of a {% endif %}sklearn pipeline with a dimensionality reduction step of {{ dimensionality_reduction.raw_value }}\n",
    "{% if feature_selection.value != 'None' %}and a feature selection step of {{ feature_selection.raw_value }}\n",
    "{% endif %} and a{% if calibrated.value %} calibrated{%endif %} {{ algorithm.raw_value }} classifier\n",
    "using {{ cross_validation_n_folds.value }}-fold {{ cv_algorithm.raw_value }} cross-validation,\n",
    "optimizing {{ primary_metric.value }}{% if evaluation_metrics.value %} and computing {{ ', '.join(evaluation_metrics.value) }}{% endif %}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will take a long time as we are evaluating n_iter different models n_splits different times each computing all the metrics on `product(X.shape)` data points--not to mention the size of each model dictated by the range of parameters specified in the params dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "{% if algorithm.value == 'GradientBoostingClassifier' %}\n",
    "## Early stopping function\n",
    "def early_stopping(n_rounds, tol=0.001):\n",
    "    def early_stopping_func(i, self, local):\n",
    "        rounds = getattr(self, '__rounds', 0)\n",
    "        last = getattr(self, '__last', None)\n",
    "        current = self.train_score_[i]\n",
    "        if last and current and abs(current - last) < tol:\n",
    "            rounds += 1\n",
    "            if rounds > n_rounds:\n",
    "                return True\n",
    "        else:\n",
    "            rounds = 0\n",
    "        setattr(self, '__last', current)\n",
    "        setattr(self, '__rounds', rounds)\n",
    "        return False\n",
    "    return early_stopping_func\n",
    "{% endif %}\n",
    "\n",
    "{#\n",
    "param_grid = {\n",
    "    'reduce_dim__n_components': randint(2, 1024),\n",
    "{% if algorithm.value == 'GradientBoostingClassifier' %}\n",
    "    'clf__loss': ['deviance', 'exponential'],\n",
    "    'clf__learning_rate': randfloat(0.001, 1.),\n",
    "    'clf__subsample': randfloat(0.01, 1.),\n",
    "{% elif algorithm.value == 'RandomForestClassifier' %}\n",
    "    'clf__oob_score': [True],\n",
    "    'clf__criterion': ['gini', 'entropy'],\n",
    "{% endif %}\n",
    "    'clf__n_estimators': randint(10, 200),\n",
    "    'clf__max_depth': randint(20, 50),\n",
    "    'clf__max_features': ['sqrt', 'log2', None],\n",
    "    'clf__min_impurity_decrease': randfloat(0., 0.2),\n",
    "    'clf__min_weight_fraction_leaf': randfloat(0., 0.5),\n",
    "}\n",
    "\n",
    "fit_params = {\n",
    "{% if algorithm.value == 'GradientBoostingClassifier' %}\n",
    "    'clf__monitor': early_stopping(5),\n",
    "{% endif %}\n",
    "}\n",
    "#}\n",
    "\n",
    "{% if cv_algorithm.raw_value in ['RepeatedStratifiedKFold', 'RepeatedStratifiedGroupKFold'] %}\n",
    "n_repeats=5\n",
    "{% endif %}\n",
    "cv = {{ cv_algorithm }}(\n",
    "    n_splits={{ cross_validation_n_folds }},\n",
    "    {% if cv_algorithm.raw_value in ['RepeatedStratifiedKFold', 'RepeatedStratifiedGroupKFold'] %}\n",
    "    n_repeats=n_repeats,\n",
    "    {% else %}\n",
    "    shuffle=True,\n",
    "    {% endif %}\n",
    "    random_state=rng,\n",
    ")\n",
    "\n",
    "{% if cv_algorithm.raw_value in ['GroupKFold', 'StratifiedGroupKFold', 'RepeatedStratifiedGroupKFold'] %}\n",
    "groups=[key[:14] for key in X.index]    # Group compounds by atom connectivity\n",
    "{% endif %}\n",
    "\n",
    "# Scoring parameters\n",
    "primary_metric = '{{ primary_metric }}'\n",
    "evaluation_metrics = {{ evaluation_metrics }}\n",
    "scoring_params = {k: metrics.get_scorer(k)\n",
    "                  for k in [primary_metric, *evaluation_metrics]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "{% if hyper_param_search.value == 'None' %}\n",
    "\n",
    "df_results = pd.DataFrame()\n",
    "\n",
    "# Store performance on each split for computing ROC and PRC curves\n",
    "fprs = []\n",
    "tprs = []\n",
    "precs = []\n",
    "recs = []\n",
    "\n",
    "# Store cross-validation test predictions and folds\n",
    "y_proba_cv = [[] for _ in range(len(y))]\n",
    "folds_cv = [[] for _ in range(len(y))]\n",
    "\n",
    "# Store models\n",
    "models = []\n",
    "\n",
    "{% if cv_algorithm.raw_value in ['GroupKFold', 'StratifiedGroupKFold', 'RepeatedStratifiedGroupKFold'] %}\n",
    "groups=[key[:14] for key in X.index]    # Group compounds by atom connectivity\n",
    "for fold, (train, test) in tqdm(enumerate(cv.split(X.values, y, groups=groups))):\n",
    "{% else %}\n",
    "for fold, (train, test) in tqdm(enumerate(cv.split(X.values, y))):\n",
    "{% endif %}\n",
    "    model =\n",
    "    {%- if hyper_param_search.value != 'None' %} {{ hyper_param_search }}({% endif -%}\n",
    "            sk.pipeline.Pipeline([\n",
    "                {%- if dimensionality_reduction.value != 'None' %}\n",
    "                ('reduce_dim', {{ dimensionality_reduction }}),\n",
    "                {% endif %}\n",
    "                {%- if feature_selection.value != 'None' %}\n",
    "                ('feature_selection', {{ feature_selection }}),\n",
    "                {% endif %}\n",
    "                ('clf', {{ algorithm }}),\n",
    "            ])\n",
    "    {%- if hyper_param_search.value != 'None' %}){% endif %}\n",
    "    model.fit(X.values[train], y[train])\n",
    "    \n",
    "    {% if calibrated.value %}\n",
    "    calibrator = sk.calibration.CalibratedClassifierCV(model, cv='prefit')\n",
    "    calibrator.fit(X.values[test], y[test])\n",
    "    model = calibrator\n",
    "    {% endif %}\n",
    "    \n",
    "    {% for metric in all_metrics %}\n",
    "    df_results.loc[fold, '{{ metric }}'] = scoring_params['{{ metric }}'](model, X.values[test], y[test])\n",
    "    {% endfor %}\n",
    "    \n",
    "    y_proba = model.predict_proba(X.values[test]) # Probability prediction will be True\n",
    "    for i in range(len(test)):\n",
    "        y_proba_cv[test[i]].append(y_proba[i, 1])\n",
    "        folds_cv[test[i]].append(fold % {{ cross_validation_n_folds }})\n",
    "    model_fpr, model_tpr, _ = metrics.roc_curve(y[test], y_proba[:, 1])\n",
    "    model_prec, model_rec, _ = metrics.precision_recall_curve(y[test], y_proba[:, 1])\n",
    "    fprs.append(model_fpr)\n",
    "    tprs.append(model_tpr)\n",
    "    precs.append(model_prec)\n",
    "    recs.append(model_rec)\n",
    "    models.append(model)\n",
    "\n",
    "assert not(any(len(probs) == 0 for probs in y_proba_cv)), 'All probabilities should have been calculated'\n",
    "\n",
    "display(df_results.agg(['mean', 'std']))\n",
    "{% else %}\n",
    "model.fit(X.values, y)\n",
    "df_results = model.cv_results_\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This visualization shows the cross-validated performance of the model. Low fold variance and high AUC is desired in a well-generalized model.\n",
    "* ROC curve: [roc.svg](./roc.svg)\n",
    "* Precision-recall curve: [prc.svg](./prc.svg)\n",
    "* Confusion matrix: [confusion_matrix.svg](./confusion_matrix.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "tprs_interp = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "for fold, (fpr, tpr) in enumerate(zip(fprs, tprs)):\n",
    "    tpr_interp = np.interp(mean_fpr, fpr, tpr)\n",
    "    tpr_interp[0] = 0.\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    tprs_interp.append(tpr_interp)\n",
    "    aucs.append(roc_auc)\n",
    "    {% if cv_algorithm.raw_value in ['RepeatedStratifiedKFold', 'RepeatedStratifiedGroupKFold'] %}\n",
    "    ax.plot(fpr, tpr, alpha=0.4)\n",
    "    {% else %}\n",
    "    ax.plot(fpr, tpr, alpha=0.4, label='ROC Fold %d (AUC=%0.3f)' % (fold, roc_auc))\n",
    "    {% endif %}\n",
    "\n",
    "mean_tpr = np.mean(tprs_interp, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = sk.metrics.auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "ax.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs_interp, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2)\n",
    "\n",
    "ax.plot([0,1],[0,1],'--', label='Random')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.legend()\n",
    "plt.savefig('roc.svg')\n",
    "plt.show()\n",
    "\n",
    "z = (mean_auc - 0.5)/std_auc\n",
    "cl = sp.stats.norm.cdf(z) * 100\n",
    "ci = sp.stats.norm.interval(0.95, loc=mean_auc, scale=std_auc)\n",
    "print('Confidence interval (95%)', ci)\n",
    "print(\"We are %0.3f %% confident the model's results are not just chance.\" % (cl))\n",
    "if cl > 95:\n",
    "    print('This is statistically significant. These results can be trusted.')\n",
    "else:\n",
    "    print('This is not statistically significant. These results should not be trusted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "precs_interp = []\n",
    "prc_aucs = []\n",
    "mean_rec = np.linspace(0, 1, 100)\n",
    "\n",
    "for fold, (rec, prec) in enumerate(zip(recs, precs)):\n",
    "    prec_interp = np.interp(mean_rec, rec[::-1], prec[::-1])\n",
    "    prc_auc = metrics.auc(rec, prec)\n",
    "    precs_interp.append(prec_interp)\n",
    "    prc_aucs.append(prc_auc)\n",
    "    {% if cv_algorithm.raw_value in ['RepeatedStratifiedKFold', 'RepeatedStratifiedGroupKFold'] %}\n",
    "    ax.plot(rec, prec, alpha=0.4)\n",
    "    {% else %}\n",
    "    ax.plot(rec, prec, alpha=0.4, label='PRC Fold %d (AUC=%0.3f)' % (fold, prc_auc))\n",
    "    {% endif %}\n",
    "    \n",
    "mean_prec = np.mean(precs_interp, axis=0)\n",
    "mean_auc = sk.metrics.auc(mean_rec, mean_prec)\n",
    "std_auc = np.std(prc_aucs)\n",
    "ax.plot(mean_rec, mean_prec, color='b',\n",
    "         label=r'Mean PRC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_prec = np.std(precs_interp, axis=0)\n",
    "precs_upper = np.minimum(mean_prec + std_prec, 1)\n",
    "precs_lower = np.maximum(mean_prec - std_prec, 0)\n",
    "plt.fill_between(mean_rec, precs_lower, precs_upper, color='grey', alpha=.2)\n",
    "\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.legend()\n",
    "plt.savefig('prc.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.title('Confusion Matrix (Cross-Validation)')\n",
    "sns.heatmap(\n",
    "    metrics.confusion_matrix(y, np.array([np.mean(probs) for probs in y_proba_cv]) > 0.5),\n",
    "    annot=True,\n",
    "    cmap=plt.cm.Blues,\n",
    "    fmt='g'\n",
    ")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.savefig('confusion_matrix.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine drug predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the binary classification model, we can rank the drug hits by their predicted score. The model can also be used to identify additional drugs that are likely to share properties with the hits. The results table is available at [drug_cv_predictions.csv](./drug_cv_predictions.csv)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot distribution of predictions for positive and negative classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "# Calculate mean and deviation of predictions\n",
    "y_probas = np.array([np.mean(probs) for probs in y_proba_cv])\n",
    "{% if cv_algorithm.raw_value in ['RepeatedStratifiedKFold', 'RepeatedStratifiedGroupKFold'] %}\n",
    "y_probas_std = np.array([np.std(probs) for probs in y_proba_cv])\n",
    "# Find minimum non-zero standard deviation to avoid dividing by zero when computing t-statistic\n",
    "min_y_probas_std = max(np.min(y_probas_std[y_probas_std != 0]), 1e-10)\n",
    "t_stats = (y_probas - np.mean(y_probas)) / (np.maximum(y_probas_std, min_y_probas_std)/np.sqrt(n_repeats))\n",
    "# Calculate p-value using one-sample t-test\n",
    "p_vals_t = 1-sp.stats.t(n_repeats-1).cdf(t_stats)\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "{% if cv_algorithm.raw_value in ['RepeatedStratifiedKFold', 'RepeatedStratifiedGroupKFold'] %}\n",
    "y_probas_means_5 = []\n",
    "y_probas_values = np.array(y_proba_cv).flatten()\n",
    "\n",
    "np.random.seed(rng)\n",
    "for i in tqdm(range(100000)):\n",
    "    y_probas_means_5.append(np.mean(np.random.choice(y_probas_values, n_repeats)))\n",
    "    \n",
    "y_probas_means_5 = np.array(sorted(y_probas_means_5))\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "{% if cv_algorithm.raw_value in ['RepeatedStratifiedKFold', 'RepeatedStratifiedGroupKFold'] %}\n",
    "y_probas_ts_5 = []\n",
    "mean_y_probas = np.mean(y_probas)\n",
    "y_probas_values = np.array(y_proba_cv).flatten()\n",
    "\n",
    "np.random.seed(rng)\n",
    "for i in tqdm(range(100000)):\n",
    "    sample = np.random.choice(y_probas_values, n_repeats)\n",
    "    y_probas_ts_5.append((np.mean(sample) - mean_y_probas) / (np.maximum(np.std(sample), min_y_probas_std)/np.sqrt(n_repeats)))\n",
    "    \n",
    "y_probas_ts_5 = np.array(sorted(y_probas_ts_5))\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "{% if cv_algorithm.raw_value in ['RepeatedStratifiedKFold', 'RepeatedStratifiedGroupKFold'] %}\n",
    "max_mean = np.max(y_probas_means_5)\n",
    "p_vals = np.array(list(tqdm((1 - np.argwhere(y_probas_means_5 >= min(pred, max_mean))[0][0] / len(y_probas_means_5)\n",
    "                             for pred in y_probas), total=len(y_probas))))\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "{% if cv_algorithm.raw_value in ['RepeatedStratifiedKFold', 'RepeatedStratifiedGroupKFold'] %}\n",
    "max_t = np.max(y_probas_ts_5)\n",
    "p_vals_t_sim = np.array(list(tqdm((1 - np.argwhere(y_probas_ts_5 >= min(t, max_t))[0][0] / len(y_probas_ts_5)\n",
    "                                   for t in t_stats), total=len(t_stats))))\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "sns.kdeplot(y_probas[y == 0], shade=True, gridsize=2000, clip=[np.min(y_probas), np.percentile(y_probas, 99.9)], bw=0.01, label='Not known NSAID')\n",
    "sns.kdeplot(y_probas[y == 1], shade=True, gridsize=2000, clip=[np.min(y_probas), np.percentile(y_probas, 99.9)], bw=0.002, label='Known NSAID')\n",
    "{% if cv_algorithm.raw_value in ['RepeatedStratifiedKFold', 'RepeatedStratifiedGroupKFold'] %}\n",
    "sns.kdeplot(y_probas_means_5, shade=True, gridsize=2000, clip=[np.min(y_probas), np.percentile(y_probas, 99.9)], bw=0.01, label='Null distribution\\n(simulated)')\n",
    "{% endif %}\n",
    "plt.xlabel('Mean Predicted Probability')\n",
    "plt.xlim([np.min(y_probas), np.percentile(y_probas, 99)])\n",
    "plt.legend()\n",
    "plt.savefig('mean-prediction-distribution-kde.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "{% if cv_algorithm.raw_value in ['RepeatedStratifiedKFold', 'RepeatedStratifiedGroupKFold'] %}\n",
    "sns.kdeplot(t_stats[y == 0], shade=True, gridsize=1000, clip=(-20, 20), bw=0.1, label='Not known NSAID')\n",
    "sns.kdeplot(t_stats[y == 1], shade=True, gridsize=1000, clip=(-20, 20), bw=0.05, label='Known NSAID')\n",
    "sns.kdeplot(y_probas_ts_5, shade=True, gridsize=1000, clip=(-20, 20), bw=0.1, label='Null distribution\\n(simulated)')\n",
    "plt.xlabel('t-statistic')\n",
    "plt.xlim([-20,20])\n",
    "plt.legend()\n",
    "plt.savefig('t-statistic-distribution-kde.svg')\n",
    "plt.show()\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlay predictions on visualization of input space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "# Add attributes for plotting to Dataframe\n",
    "X_reduced_df['Predicted Probability'] = y_probas\n",
    "X_reduced_df['log10(pred)'] = np.log10(y_probas + 1e-10)\n",
    "X_reduced_df['p-value'] = p_vals_t_sim\n",
    "X_reduced_df['log10(p-value)'] = np.log10(X_reduced_df['p-value'])\n",
    "X_reduced_df['Predicted Probability'] = y_probas\n",
    "X_reduced_df['Standard Deviation'] = y_probas_std\n",
    "X_reduced_df['Cross-validation fold'] = folds_cv\n",
    "X_reduced_df['marker size'] = 2*np.minimum(2-np.log10(X_reduced_df['p-value']), 5)\n",
    "X_reduced_df['text'] = ['<br>'.join(['Drug Name: ' + str(name),\n",
    "                                     'InChI Key: ' + str(inchi),\n",
    "                                     'Predicted Probability: {:.1e}'.format(p),\n",
    "                                     'Standard Deviation: {:.1e}'.format(s),\n",
    "                                     'p-value: {:.1e}'.format(p_val),\n",
    "                                     'Label: ' + str(label),\n",
    "                                     'Cross-validation fold: ' + str(fold)])\n",
    "                  for name, inchi, p, s, p_val, label, fold in zip(X_reduced_df['Drug Name'],\n",
    "                                                         X_reduced_df['InChI Key'],\n",
    "                                                         X_reduced_df['Predicted Probability'],\n",
    "                                                         X_reduced_df['Standard Deviation'],\n",
    "                                                         X_reduced_df['p-value'],\n",
    "                                                         X_reduced_df['Label'],\n",
    "                                                         X_reduced_df['Cross-validation fold'])]\n",
    "X_reduced_df.to_csv('X_reduced_df.csv')\n",
    "\n",
    "# Helper function for formatting Plotly colorbar\n",
    "def colorbar_param(values_log10, **kwargs):\n",
    "    min_val = np.floor(np.min(values_log10))\n",
    "    max_val = np.ceil(np.max(values_log10))\n",
    "    \n",
    "    ticks1 = 10**np.arange(min_val, max_val+1)\n",
    "    ticks2 = 3*10**np.arange(min_val, max_val)\n",
    "    \n",
    "    ticktext = sorted(np.concatenate([ticks1, ticks2]))\n",
    "    tickvals = list(np.log10(ticktext))\n",
    "    ticktext = ['{:.0e}'.format(text) for text in ticktext]\n",
    "    \n",
    "    return dict(ticktext=ticktext, tickvals=tickvals, **kwargs)\n",
    "\n",
    "fig = go.Figure()\n",
    "for label in sorted(set(X_reduced_df['Label'])):\n",
    "    X_plot = X_reduced_df[X_reduced_df['Label'] == label].sort_values(['Predicted Probability'])\n",
    "    fig.add_trace(go.Scatter(mode='markers',\n",
    "                               x=X_plot['Component 1'], y=X_plot['Component 2'],\n",
    "                               text=X_plot['text'],\n",
    "                               name=label,\n",
    "                               marker=dict(\n",
    "                                   color=X_plot['log10(pred)'],\n",
    "                                   cmin=np.percentile(X_reduced_df['log10(pred)'], 50),\n",
    "                                   cmax=np.max(X_reduced_df['log10(pred)']),\n",
    "                                   size=X_plot['marker size'],\n",
    "                                   colorbar=colorbar_param(X_plot['log10(pred)'], title='Predicted Probability'),\n",
    "                                   symbol=X_plot['marker symbol'],\n",
    "                                   line_width=1,\n",
    "                                   colorscale='plasma'\n",
    "                               )))\n",
    "fig.update_layout(height=600, width=800,\n",
    "                  xaxis_title='Component 1',\n",
    "                  yaxis_title='Component 2',\n",
    "                  title_text='Predicted Probabilities ({{ visualization_reduction.raw_value }})',\n",
    "                  legend_title_text='Target Label',\n",
    "                  legend=dict(\n",
    "                      yanchor=\"top\",\n",
    "                      y=0.98,\n",
    "                      xanchor=\"left\",\n",
    "                      x=0.02\n",
    "                  ),\n",
    "                  template='simple_white')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tables of top-predicted compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "# Obtain prediction results\n",
    "results = pd.DataFrame(np.array([\n",
    "    querysepl1000fwd.get_drug_names(X.index),\n",
    "#     Drugmonizome.get_drug_names(X.index),\n",
    "    folds_cv,\n",
    "    y,\n",
    "    y_probas,\n",
    "    {% if cv_algorithm.raw_value in ['RepeatedStratifiedKFold', 'RepeatedStratifiedGroupKFold'] %}\n",
    "    y_probas_std,\n",
    "    t_stats,\n",
    "    p_vals,\n",
    "    p_vals_t,\n",
    "    p_vals_t_sim,\n",
    "    {% endif %}\n",
    "]).T, columns=[\n",
    "    'Name (L1000FWD)',\n",
    "#     'Name (Drugmonizome)',\n",
    "    'Cross-validation fold',\n",
    "    'Known',\n",
    "    'Prediction Probability',\n",
    "    {% if cv_algorithm.raw_value in ['RepeatedStratifiedKFold', 'RepeatedStratifiedGroupKFold'] %}\n",
    "    'Prediction Probability Std. Dev.',\n",
    "    't statistic',\n",
    "    'p value (simulated mean distribution)',\n",
    "    'p value (one sample t test)',\n",
    "    'p value (simulated t distribution)',\n",
    "    {% endif %}\n",
    "], index=X.index).astype({'Known': 'bool',\n",
    "                          'Prediction Probability': 'float64',\n",
    "                          {% if cv_algorithm.raw_value in ['RepeatedStratifiedKFold', 'RepeatedStratifiedGroupKFold'] %}\n",
    "                          'Prediction Probability Std. Dev.': 'float64',\n",
    "                          't statistic': 'float64',\n",
    "                          'p value (simulated mean distribution)': 'float64',\n",
    "                          'p value (one sample t test)': 'float64',\n",
    "                          'p value (simulated t distribution)': 'float64',{% endif %}})\n",
    "\n",
    "results.to_csv('drug_cv_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank drug hits\n",
    "results[((results['Known'] == 1))].sort_values('Prediction Probability', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predict additional drugs\n",
    "results[results['Known'] == 0].sort_values('Prediction Probability', ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine feature importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relative contribution of each input feature to the final model predictions can be estimated for recursive feature selection and for a variety of tree-based models. Note that this analysis is not available if a dimensionality reduction algorithm is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "\n",
    "{% if feature_selection.raw_value == 'RecursiveSelectionFromExtraTrees' and dimensionality_reduction.raw_value == 'None' %}\n",
    "When recursive feature selection is performed, the features are ranked by the stage at which they were removed.\n",
    "Selected (i.e. estimated best) features are have importance 1. The ranks are averaged across cross-validation\n",
    "splits to produce an average importance score. The full feature importance table is available at\n",
    "[feature_importance.csv](./feature_importance.csv).\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "{% if feature_selection.raw_value == 'RecursiveSelectionFromExtraTrees' and dimensionality_reduction.raw_value == 'None' %}\n",
    "all_rankings = []\n",
    "{% endif %}\n",
    "{% if algorithm.raw_value in ['GradientBoostingClassifier', 'RandomForestClassifier', 'AdaBoostClassifier', 'ExtraTreesClassifier', 'DecisionTreeClassifier'] %}\n",
    "all_feature_importances = []\n",
    "{% endif %}\n",
    "for model in models:\n",
    "    {% if calibrated.value %}\n",
    "    for calibrated_clf in model.calibrated_classifiers_:\n",
    "        pipeline = calibrated_clf.base_estimator\n",
    "    {% else %}\n",
    "        pipeline = model\n",
    "    {% endif %}\n",
    "        \n",
    "        {% if feature_selection.raw_value == 'RecursiveSelectionFromExtraTrees' %}\n",
    "        ranking = pipeline['feature_selection'].ranking_\n",
    "        all_rankings.append(ranking)\n",
    "        {% endif %}\n",
    "        \n",
    "        {% if algorithm.raw_value in ['GradientBoostingClassifier', 'RandomForestClassifier', 'AdaBoostClassifier', 'ExtraTreesClassifier', 'DecisionTreeClassifier'] %}\n",
    "        {% if feature_selection.raw_value != 'None' %}\n",
    "        feature_importances = np.zeros(pipeline['feature_selection'].get_support().shape)\n",
    "        feature_importances[pipeline['feature_selection'].get_support()] = pipeline['clf'].feature_importances_\n",
    "        {% else %}\n",
    "        feature_importances = pipeline['clf'].feature_importances_\n",
    "        {% endif %}\n",
    "        all_feature_importances.append(feature_importances)\n",
    "        {% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "{% if dimensionality_reduction.raw_value == 'None' %}\n",
    "df_feat_imp = pd.DataFrame({'Feature': X.columns,\n",
    "                            'Dataset': reduce(lambda a,b: a+b, ([dataset]*size for dataset, size in dataset_sizes)),\n",
    "                            {% if feature_selection.raw_value == 'RecursiveSelectionFromExtraTrees' %}\n",
    "                            'Ranking Mean': np.mean(all_rankings, axis=0),\n",
    "                            'Ranking Std. Dev.': np.std(all_rankings, axis=0),\n",
    "                            {% endif %}\n",
    "                            'Importance Mean': np.mean(all_feature_importances, axis=0),\n",
    "                            'Importance Std. Dev.': np.std(all_feature_importances, axis=0)})\n",
    "df_feat_imp = df_feat_imp.set_index('Feature').sort_values('Importance Mean', ascending=False)\n",
    "display(df_feat_imp.head(25))\n",
    "df_feat_imp.to_csv('feature_importance.csv')\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "\n",
    "{% if feature_selection.raw_value == 'RecursiveSelectionFromExtraTrees' and dimensionality_reduction.raw_value == 'None' %}\n",
    "Plot the distribution of importance scores for features in each dataset ([feature_importance.svg](./feature_importance.svg)).\n",
    "Features with lower scores were retained for more rounds during recursive feature selection\n",
    "and have greater relative importance.\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "{% if feature_selection.raw_value == 'RecursiveSelectionFromExtraTrees' and dimensionality_reduction.raw_value == 'None' %}\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "df_feat_imp = df_feat_imp.sort_values('Ranking Mean')\n",
    "for dataset in set(df_feat_imp.Dataset):\n",
    "    importance_scores = df_feat_imp.loc[df_feat_imp.Dataset == dataset]['Ranking Mean'].values\n",
    "    importance_scores_std = df_feat_imp.loc[df_feat_imp.Dataset == dataset]['Ranking Std. Dev.'].values\n",
    "    lower = importance_scores - importance_scores_std\n",
    "    upper = importance_scores + importance_scores_std\n",
    "    axs[0].plot(importance_scores, label=dataset)\n",
    "    axs[0].fill_between(np.arange(len(importance_scores)), lower, upper, alpha=.2)\n",
    "    axs[1].plot(np.linspace(0, 1, len(importance_scores)), importance_scores, label=dataset)\n",
    "    axs[1].fill_between(np.linspace(0, 1, len(importance_scores)), lower, upper, alpha=.2)\n",
    "for i in [0, 1]:\n",
    "    axs[i].legend()\n",
    "    axs[i].set_title('Distribution of feature ranking from recursive feature elimination')\n",
    "    axs[i].set_ylabel('Average feature ranking\\n(lower ranking is more important)')\n",
    "axs[0].set_xlabel('Ranked features (absolute count)')\n",
    "axs[1].set_xlabel('Ranked features (relative count)')\n",
    "axs[0].set_xlim([0,512])\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance_rfe.svg')\n",
    "plt.show()\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "{% if algorithm.raw_value in ['GradientBoostingClassifier', 'RandomForestClassifier', 'AdaBoostClassifier', 'ExtraTreesClassifier', 'DecisionTreeClassifier']  and dimensionality_reduction.raw_value == 'None' %}\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
    "df_feat_imp = df_feat_imp.sort_values('Importance Mean', ascending=False)\n",
    "for dataset in set(df_feat_imp.Dataset):\n",
    "    importance_scores = df_feat_imp.loc[df_feat_imp.Dataset == dataset]['Importance Mean'].values\n",
    "    importance_scores_std = df_feat_imp.loc[df_feat_imp.Dataset == dataset]['Importance Std. Dev.'].values\n",
    "    lower = importance_scores - importance_scores_std\n",
    "    upper = importance_scores + importance_scores_std\n",
    "    axs[0][0].plot(importance_scores, label=dataset)\n",
    "    axs[0][0].fill_between(np.arange(len(importance_scores)), lower, upper, alpha=.2)\n",
    "    axs[0][1].plot(np.linspace(0, 1, len(importance_scores)), importance_scores, label=dataset)\n",
    "    axs[0][1].fill_between(np.linspace(0, 1, len(importance_scores)), lower, upper, alpha=.2)\n",
    "    \n",
    "    importance_scores = np.cumsum(df_feat_imp.loc[df_feat_imp.Dataset == dataset]['Importance Mean'].values)\n",
    "    axs[1][0].plot(importance_scores, label=dataset)\n",
    "    axs[1][1].plot(np.linspace(0, 1, len(importance_scores)), importance_scores, label=dataset)\n",
    "for i in [0, 1]:\n",
    "    axs[0][i].legend()\n",
    "    axs[0][i].set_title('Distribution of feature scores from model')\n",
    "    axs[1][i].set_title('Cumulative distribution of feature scores from model')\n",
    "    axs[i][0].set_xlabel('Ranked features (absolute count)')\n",
    "    axs[i][1].set_xlabel('Ranked features (relative count)')\n",
    "    axs[0][i].set_ylabel('Average feature importance\\n(higher score is more important)')\n",
    "    axs[1][i].set_ylabel('Cumulative sum of feature importance')\n",
    "    axs[i][0].set_xlim([0,512])\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.svg')\n",
    "plt.show()\n",
    "{% endif %}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdkit-dml-env",
   "language": "python",
   "name": "rdkit-dml-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "279.8px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
