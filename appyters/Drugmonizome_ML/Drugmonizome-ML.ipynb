{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%appyter init\n",
    "import os, sys; sys.path.insert(0, os.path.realpath('..'))\n",
    "from appyter import magic\n",
    "magic.init(lambda _=globals: _())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Imports\n",
    "## Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "## Machine Learning\n",
    "import sklearn as sk\n",
    "from sklearn import (\n",
    "    calibration,\n",
    "    decomposition,\n",
    "    ensemble,\n",
    "    feature_selection,\n",
    "    linear_model,\n",
    "    manifold,\n",
    "    metrics,\n",
    "    model_selection,\n",
    "    multioutput,\n",
    "    pipeline,\n",
    "    preprocessing,\n",
    "    svm,\n",
    "    tree,\n",
    "    feature_extraction,\n",
    ")\n",
    "import umap\n",
    "## Plotting\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "## Drugmonizome API\n",
    "from drugmonizome import Drugmonizome\n",
    "# Utility\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from functools import reduce\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = 2020\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Input Datasets and Target Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selected drug set libraries and omics datasets are downloaded and joined on the drug to produce a large association matrix. A machine learning model will be trained to predict the specified target labels from this association matrix. This is a binary classification task that can be used to predict drugs that are likely to be associated with the target class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter hide\n",
    "{% do SectionField(\n",
    "    title='Attribute Dataset Selection',\n",
    "    subtitle='Select the input datasets to use for learning and classification. \\\n",
    "              A model will be trained to predict the target labels from the selected attributes. \\\n",
    "              If no datasets are selected, default attributes will be used.',\n",
    "    name='ATTRIBUTES',\n",
    "    img='attributes.png',\n",
    ") %}\n",
    "\n",
    "{% set exprdatasets = MultiChoiceField(\n",
    "    name='exprdatasets',\n",
    "    label='L1000',\n",
    "    choices=[\n",
    "        'L1000FWD Downregulated GO Biological Processes',\n",
    "        'L1000FWD Downregulated GO Cellular Components',\n",
    "        'L1000FWD Downregulated GO Molecular Function',\n",
    "        'L1000FWD Downregulated KEGG Pathways',\n",
    "        'L1000FWD Downregulated Signatures',\n",
    "        'L1000FWD Predicted Side Effects',\n",
    "        'L1000FWD Upregulated GO Biological Process',\n",
    "        'L1000FWD Upregulated GO Cellular Components',\n",
    "        'L1000FWD Upregulated GO Molecular Function',\n",
    "        'L1000FWD Upregulated KEGG Pathways',\n",
    "        'L1000FWD Upregulated Signatures',\n",
    "    ],\n",
    "    default=[],\n",
    "    section='ATTRIBUTES'\n",
    ") %}\n",
    "\n",
    "{% set targetdatasets = MultiChoiceField(\n",
    "    name='targetdatasets',\n",
    "    label='Drug Targets and Associated Genes',\n",
    "    choices=[\n",
    "        'Downregulated CREEDS Signatures',\n",
    "        'Upregulated CREEDS Signatures',\n",
    "        'DrugCentral Targets',\n",
    "        'DrugRepurposingHub Drug Targets',\n",
    "        'Drugbank Small Molecule Carriers',\n",
    "        'Drugbank Small Molecule Enzymes',\n",
    "        'Drugbank Small Molecule Targets',\n",
    "        'Drugbank Small Molecule Transporters',\n",
    "        'Geneshot Associated Genes',\n",
    "        'Geneshot Predicted AutoRIF Genes',\n",
    "        'Geneshot Predicted Coexpression Genes',\n",
    "        'Geneshot Predicted Enrichr Genes',\n",
    "        'Geneshot Predicted GeneRIF Genes',\n",
    "        'Geneshot Predicted Tagger Genes',\n",
    "        'KinomeScan Kinases',\n",
    "        'PharmGKB Single Nucleotide Polymorphisms',\n",
    "        'STITCH Targets',\n",
    "    ],\n",
    "    default=[],\n",
    "    section='ATTRIBUTES'\n",
    ") %}\n",
    "\n",
    "{% set indicationdatasets = MultiChoiceField(\n",
    "    name='indicationdatasets',\n",
    "    label='Indications, Modes of Action, and Side Effects',\n",
    "    choices=[\n",
    "        'ATC Codes Drugsetlibrary',\n",
    "        'DrugRepurposingHub Mechanisms of Action',\n",
    "        'PharmGKB OFFSIDES Side Effects',\n",
    "        'SIDER Indications',\n",
    "        'SIDER Side Effects',\n",
    "    ],\n",
    "    default=[],\n",
    "    section='ATTRIBUTES'\n",
    ") %}\n",
    "\n",
    "{% set structuraldatasets = MultiChoiceField(\n",
    "    name='structuraldatasets',\n",
    "    label='Structural Features',\n",
    "    choices=[\n",
    "        'RDKIT MACCS Chemical Fingerprints'\n",
    "    ],\n",
    "    default=[],\n",
    "    section='ATTRIBUTES'\n",
    ") %}\n",
    "\n",
    "{% set keepmissing = BoolField(\n",
    "    name='keepmissing',\n",
    "    label='Keep drugs with missing data when joining datasets',\n",
    "    description='Keep drugs that appear in some datasets and not in others. \\\n",
    "                 Missing data is filled in with zeros. Otherwise, only drugs \\\n",
    "                 that are present in all datasets are preserved.',\n",
    "    default=False,\n",
    "    section='ATTRIBUTES',\n",
    ") %}\n",
    "\n",
    "{% set tfidf = BoolField(\n",
    "    name='tfidf',\n",
    "    label='Apply tfâ€“idf normalization to binary inputs',\n",
    "    description='For binary drug-attribute associations in the input matrix, \\\n",
    "                 apply tf-idf transformation to normalize data.',\n",
    "    default=True,\n",
    "    section='ATTRIBUTES',\n",
    ") %}\n",
    "\n",
    "{% set attribute_datasets = exprdatasets.value +\n",
    "                             targetdatasets.value +\n",
    "                             indicationdatasets.value +\n",
    "                             structuraldatasets.value %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "\n",
    "To construct the input matrix, we download drug set libraries and omics datasets and join them on the drug ID.\n",
    "{% if keepmissing.value %}\n",
    "Drugs that appear in some datasets and not in others are preserved, and missing data is filled in with zeros.\n",
    "{% else %}\n",
    "Only drugs that are present in all datasets are preserved.\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%%appyter hide\n",
    "{% do SectionField(\n",
    "    title='Target Label Selection',\n",
    "    subtitle='Upload a list of drugs to be given positive class labels for binary classification. \\\n",
    "              Drugs should be in a text file, specified by either drug name or InChI Key and separated by newlines. \\\n",
    "              If no file is selected, a default list of hits from COVID-19 drug screens will be used.',\n",
    "    name='TARGET',\n",
    "    img='target.png',\n",
    ") %}\n",
    "\n",
    "{% set drugformat = ChoiceField(\n",
    "    name='drugformat',\n",
    "    label='Drug Identifier Format',\n",
    "    default='Drug Name',\n",
    "    choices=[\n",
    "        'Drug Name',\n",
    "        'InChI Key'\n",
    "    ],\n",
    "    section='TARGET'\n",
    ") %}\n",
    "\n",
    "{% set drughitlist = FileField(\n",
    "    name='drughitlist',\n",
    "    label='Upload List of Drug Hits',\n",
    "    default='all_hits.txt',\n",
    "    section='TARGET'\n",
    ") %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "{% if attribute_datasets == [] %}\n",
    "# No attribute datasets selected, so use default datasets\n",
    "attribute_datasets = ['L1000FWD Downregulated Signatures',\n",
    "                      'L1000FWD Upregulated Signatures',\n",
    "                      'RDKIT MACCS Chemical Fingerprints']\n",
    "{% else %}\n",
    "# Use the selected attribute datasets\n",
    "attribute_datasets = {{ attribute_datasets }}\n",
    "{% endif %}\n",
    "\n",
    "df_attributes = list(Drugmonizome.download_df(\n",
    "    [dataset\n",
    "     for dataset in attribute_datasets]\n",
    "))\n",
    "\n",
    "# Assemble all attribute datasets\n",
    "if len(df_attributes) > 1:\n",
    "    # Obtain merged dataframe with omics and target data\n",
    "    df = reduce(\n",
    "        lambda a, b: pd.merge( # Merge two dataframes item by item\n",
    "            a, # left\n",
    "            b, # right\n",
    "            # Items with the same left and right index are merged\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            {% if keepmissing.value %}\n",
    "            how='outer', # Keep mis-matched indices\n",
    "            {% else %}\n",
    "            how='inner', # Keep only matched indices\n",
    "            {% endif %}\n",
    "        ),\n",
    "        df_attributes,\n",
    "    )\n",
    "else:\n",
    "    df = df_attributes[0]\n",
    "\n",
    "df = df.fillna(0)\n",
    "X = df.applymap(lambda f: 1 if f!=0 else 0)\n",
    "{% if tfidf.value %}\n",
    "# Apply tf-idf normalization\n",
    "transformer = feature_extraction.text.TfidfTransformer()\n",
    "X_tfidf = transformer.fit_transform(X)\n",
    "X = pd.DataFrame.sparse.from_spmatrix(X_tfidf, columns=X.columns, index=X.index)\n",
    "{% endif %}\n",
    "print('Total shape:', X.shape)\n",
    "display(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "\n",
    "The target labels are produced from the uploaded list of hits: 1 if the drug is specified as a hit, 0 otherwise.\n",
    "    {% if drugformat.value == 'Drug Name' %}\n",
    "    Drug names are matched to InChI Keys from the Drugmonizome metadata.\n",
    "    {% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "{% if drughitlist.value == '' %}\n",
    "# Using default list of hits from COVID-19 in vitro drug screens\n",
    "hits_filename = '../../all_hits.txt'\n",
    "{% else %}\n",
    "# Using user-specified list of positive drug hits\n",
    "hits_filename = {{drughitlist}}\n",
    "{% endif %}\n",
    "\n",
    "with open(hits_filename, 'r') as hits_file:\n",
    "    drug_hits = set(drug.strip() for drug in hits_file.read().strip().split('\\n') \n",
    "                    if len(drug.strip()) > 0)\n",
    "\n",
    "{% if drugformat.value == 'Drug Name' %}\n",
    "drug_hits = Drugmonizome.get_InChI_keys(drug_hits)\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We produce a target array containing 1 if the drug is specified as a hit and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([drug in drug_hits for drug in X.index]).astype(np.int8)\n",
    "print('Number of hits matched in input: %d (%0.3f %%)' % (y.sum(), 100*y.sum()/len(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output data shapes\n",
    "print('Input shape:', X.shape)\n",
    "print('Target shape:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter hide\n",
    "{% do SectionField(\n",
    "    title='Machine Learning Pipeline',\n",
    "    subtitle='Select from available machine learning algorithms, their unique settings, and methods to use to evaluate the classifier.',\n",
    "    name='SETTINGS',\n",
    "    img='settings.png',\n",
    ") %}\n",
    "\n",
    "{% set visualization_reduction = ChoiceField(\n",
    "    name='visualization_reduction',\n",
    "    label='Data Visualization Method',\n",
    "    description='A dimensionality reduction algorithm should be selected for data visualization.',\n",
    "    default='UMAP',\n",
    "    choices={\n",
    "        'UMAP': 'umap.UMAP()',\n",
    "        'NMF': 'sk.decomposition.NMF(n_components=2)',\n",
    "        'PCA': 'sk.decomposition.PCA(n_components=2)',\n",
    "        'TruncatedSVD': 'sk.decomposition.TruncatedSVD(n_components=2)',\n",
    "        'IncrementalPCA': 'sk.decomposition.IncrementalPCA(n_components=2)',\n",
    "        'ICA': 'sk.decomposition.FastICA(n_components=2)',\n",
    "        'SparsePCA': 'sk.decomposition.SparsePCA(n_components=2)',\n",
    "    },\n",
    "    section='SETTINGS'\n",
    ") %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "\n",
    "We reduce the dimensionality of our omics feature space for visualization with {{ visualization_reduction.raw_value }}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "clf_dimensionality_reduction = {{ visualization_reduction }}\n",
    "X_reduced = clf_dimensionality_reduction.fit_transform(X.values)\n",
    "{% if visualization_reduction.raw_value == 'PCA' %}\n",
    "print('Explained variance:', np.sum(clf_dimensionality_reduction.explained_variance_))\n",
    "{% endif %}\n",
    "plt.title('Low dimension representation')\n",
    "plt.scatter(\n",
    "    X_reduced[:, 0],\n",
    "    X_reduced[:, 1],\n",
    "    c=y,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter hide\n",
    "{% set dimensionality_reduction = ChoiceField(\n",
    "    name='dimensionality_reduction',\n",
    "    label='Dimensionality Reduction Algorithm',\n",
    "    description='A dimensionality reduction algorithm should be selected to improve the quality of the classifier.',\n",
    "    default='PCA',\n",
    "    choices={\n",
    "        'PCA': 'sk.decomposition.PCA(n_components=64)',\n",
    "        'TruncatedSVD': 'sk.decomposition.TruncatedSVD(n_components=64)',\n",
    "        'IncrementalPCA': 'sk.decomposition.IncrementalPCA(n_components=64)',\n",
    "        'ICA': 'sk.decomposition.FastICA(n_components=64)',\n",
    "        'SparsePCA': 'sk.decomposition.SparsePCA(n_components=64)',\n",
    "    },\n",
    "    section='SETTINGS'\n",
    ") %}\n",
    "{% set feature_selection = ChoiceField(\n",
    "    name='feature_selection',\n",
    "    label='Machine Learning Feature Selection',\n",
    "    default='None',\n",
    "    choices={\n",
    "        'None': 'None',\n",
    "        'SelectFromLinearSVC': 'sk.feature_selection.SelectFromModel(sk.svm.LinearSVC(loss=\"squared_hinge\", penalty=\"l1\", dual=False))',\n",
    "        'SelectFromExtraTrees': 'sk.feature_selection.SelectFromModel(sk.ensemble.ExtraTreesClassifier())',\n",
    "        'SelectKBest': 'sk.feature_selection.SelectKBest(\"f_classif\")',\n",
    "        'SelectKBestChi2': 'sk.feature_selection.SelectKBest(\"chi2\")',\n",
    "        'SelectKBestMultiInfo': 'sk.feature_selection.SelectKBest(\"mutual_info_classif\")',\n",
    "    },\n",
    "    section='SETTINGS'\n",
    ") %}\n",
    "{% set cv_algorithm = ChoiceField(\n",
    "    name='cv_algorithm',\n",
    "    label='Cross Validation Algorithm',\n",
    "    default='StratifiedKFold',\n",
    "    value='KFold',\n",
    "    choices={\n",
    "        'KFold': 'sk.model_selection.KFold',\n",
    "        'GroupKFold': 'sk.model_selection.GroupKFold',\n",
    "        'RepeatedKFold': 'sk.model_selection.RepeatedKFold',\n",
    "        'StratifiedKFold': 'sk.model_selection.StratifiedKFold',\n",
    "        'RepeatedStratifiedKFold': 'sk.model_selection.RepeatedStratifiedKFold',\n",
    "    },\n",
    "    section='SETTINGS',\n",
    ") %}\n",
    "{% set algorithm = ChoiceField(\n",
    "    name='algorithm',\n",
    "    label='Machine Learning Algorithm',\n",
    "    default='RandomForestClassifier',\n",
    "    description='A machine learning algorithm should be selected to construct the predictive model.',\n",
    "    choices={\n",
    "        'GradientBoostingClassifier': 'sk.ensemble.GradientBoostingClassifier()',\n",
    "        'RandomForestClassifier': 'sk.ensemble.RandomForestClassifier()',\n",
    "        'AdaBoostClassifier': 'sk.ensemble.AdaBoostClassifier()',\n",
    "        'ExtraTreesClassifier': 'sk.ensemble.ExtraTreesClassifier()',\n",
    "        'DecisionTreeClassifier': 'sk.tree.DecisionTreeClassifier()',\n",
    "        'KNeighborsClassifier': 'sk.neighbors.KNeighborsClassifier()',\n",
    "        'RadiusNeighborsClassifier': 'sk.neighbors.RadiusNeighborsClassifier()',\n",
    "        'MLPClassifier': 'sk.neural_network.MLPClassifier()',\n",
    "        'OneClassSVM': 'sk.svm.OneClassSVM()',\n",
    "    },\n",
    "    section='SETTINGS'\n",
    ") %}\n",
    "{% set calibrated = BoolField(\n",
    "    name='calibrated',\n",
    "    label='Calibrate algorithm predictions',\n",
    "    description='Calibrate the prediction probabilities eliminating model-imparted bias.',\n",
    "    default=True,\n",
    "    section='SETTINGS',\n",
    ") %}\n",
    "{% set hyper_param_search = ChoiceField(\n",
    "    name='hyper_param_search',\n",
    "    label='Hyper Parameter Search Type',\n",
    "    default='None',\n",
    "    description='Hyper parameter searching is used to automatically select the best parameters (using the primary metric as the criteria).',\n",
    "    choices={\n",
    "        'None': 'None',\n",
    "        'RandomizedSearchCV': 'sk.model_selection.RandomizedSearchCV',\n",
    "        'GridSearchCV': 'sk.model_selection.GridSearchCV',\n",
    "    },\n",
    "    section='SETTINGS'\n",
    ") %}\n",
    "{% set cross_validation_n_folds = IntField(\n",
    "    name='cross_validation_n_folds',\n",
    "    label='Cross-Validated Folds',\n",
    "    description='Cross validation is employed as a strategy to train the model on data that the model has not seen before, more folds will ensure that the model is generalizing well.',\n",
    "    default=3,\n",
    "    min=2,\n",
    "    max=10,\n",
    "    section='SETTINGS'\n",
    ") %}\n",
    "{% set primary_metric = ChoiceField(\n",
    "    name='primary_metric',\n",
    "    label='Primary Evaluation Metric',\n",
    "    default='roc_auc',\n",
    "    description='The primary evaluation metric is used for deciding how we assess the performance of our model.',\n",
    "    choices=[\n",
    "        'accuracy',\n",
    "        'adjusted_mutual_info_score',\n",
    "        'adjusted_rand_score',\n",
    "        'average_precision',\n",
    "        'balanced_accuracy',\n",
    "        'completeness_score',\n",
    "        'explained_variance',\n",
    "        'f1',\n",
    "        'f1_macro',\n",
    "        'f1_micro',\n",
    "        'f1_weighted',\n",
    "        'fowlkes_mallows_score',\n",
    "        'homogeneity_score',\n",
    "        'jaccard',\n",
    "        'jaccard_macro',\n",
    "        'jaccard_micro',\n",
    "        'jaccard_weighted',\n",
    "        'max_error',\n",
    "        'mutual_info_score',\n",
    "        'neg_brier_score',\n",
    "        'neg_log_loss',\n",
    "        'neg_mean_absolute_error',\n",
    "        'neg_mean_squared_error',\n",
    "        'neg_mean_squared_log_error',\n",
    "        'neg_median_absolute_error',\n",
    "        'neg_root_mean_squared_error',\n",
    "        'normalized_mutual_info_score',\n",
    "        'precision',\n",
    "        'precision_macro',\n",
    "        'precision_micro',\n",
    "        'precision_weighted',\n",
    "        'r2',\n",
    "        'recall',\n",
    "        'recall_macro',\n",
    "        'recall_micro',\n",
    "        'recall_weighted',\n",
    "        'roc_auc',\n",
    "        'roc_auc_ovo',\n",
    "        'roc_auc_ovo_weighted',\n",
    "        'roc_auc_ovr',\n",
    "        'roc_auc_ovr_weighted',\n",
    "        'v_measure_score'\n",
    "    ],\n",
    "    section='SETTINGS'\n",
    ") %}\n",
    "{% set evaluation_metrics = MultiChoiceField(\n",
    "    name='evaluation_metrics',\n",
    "    label='Evaluation Metrics',\n",
    "    default=[],\n",
    "    description='Additional evaluation metrics can be specified, these metrics will also be reported for all models trained.',\n",
    "    value=[],\n",
    "    choices=[\n",
    "        'accuracy',\n",
    "        'adjusted_mutual_info_score',\n",
    "        'adjusted_rand_score',\n",
    "        'average_precision',\n",
    "        'balanced_accuracy',\n",
    "        'completeness_score',\n",
    "        'explained_variance',\n",
    "        'f1',\n",
    "        'f1_macro',\n",
    "        'f1_micro',\n",
    "        'f1_weighted',\n",
    "        'fowlkes_mallows_score',\n",
    "        'homogeneity_score',\n",
    "        'jaccard',\n",
    "        'jaccard_macro',\n",
    "        'jaccard_micro',\n",
    "        'jaccard_weighted',\n",
    "        'max_error',\n",
    "        'mutual_info_score',\n",
    "        'neg_brier_score',\n",
    "        'neg_log_loss',\n",
    "        'neg_mean_absolute_error',\n",
    "        'neg_mean_squared_error',\n",
    "        'neg_mean_squared_log_error',\n",
    "        'neg_median_absolute_error',\n",
    "        'neg_root_mean_squared_error',\n",
    "        'normalized_mutual_info_score',\n",
    "        'precision',\n",
    "        'precision_macro',\n",
    "        'precision_micro',\n",
    "        'precision_weighted',\n",
    "        'r2',\n",
    "        'recall',\n",
    "        'recall_macro',\n",
    "        'recall_micro',\n",
    "        'recall_weighted',\n",
    "        'roc_auc',\n",
    "        'roc_auc_ovo',\n",
    "        'roc_auc_ovo_weighted',\n",
    "        'roc_auc_ovr',\n",
    "        'roc_auc_ovr_weighted',\n",
    "        'v_measure_score'\n",
    "    ],\n",
    "    section='SETTINGS',\n",
    ") %}\n",
    "{% set all_metrics = [primary_metric.value] + evaluation_metrics.value %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "\n",
    "We apply a {% if hyper_param_search.value != 'None' %}{{ hyper_param_search.raw_value }} search for the hyper parameters\n",
    "of a {% endif %}sklearn pipeline with a dimensionality reduction step of {{ dimensionality_reduction.raw_value }}\n",
    "{% if feature_selection.value != 'None' %}and a feature selection step of {{ feature_selection.raw_value }}\n",
    "{% endif %} and a{% if calibrated.value %} calibrated{%endif %} {{ algorithm.raw_value }} classifier\n",
    "using {{ cross_validation_n_folds.value }}-fold {{ cv_algorithm.raw_value }} cross-validation,\n",
    "optimizing {{ primary_metric.value }}{% if evaluation_metrics.value %} and computing {{ ', '.join(evaluation_metrics.value) }}{% endif %}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will take a long time as we are evaluating n_iter different models n_splits different times each computing all the metrics on `product(X.shape)` data points--not to mention the size of each model dictated by the range of parameters specified in the params dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "{% if algorithm.value == 'GradientBoostingClassifier' %}\n",
    "## Early stopping function\n",
    "def early_stopping(n_rounds, tol=0.001):\n",
    "    def early_stopping_func(i, self, local):\n",
    "        rounds = getattr(self, '__rounds', 0)\n",
    "        last = getattr(self, '__last', None)\n",
    "        current = self.train_score_[i]\n",
    "        if last and current and abs(current - last) < tol:\n",
    "            rounds += 1\n",
    "            if rounds > n_rounds:\n",
    "                return True\n",
    "        else:\n",
    "            rounds = 0\n",
    "        setattr(self, '__last', current)\n",
    "        setattr(self, '__rounds', rounds)\n",
    "        return False\n",
    "    return early_stopping_func\n",
    "{% endif %}\n",
    "\n",
    "{#\n",
    "param_grid = {\n",
    "    'reduce_dim__n_components': randint(2, 1024),\n",
    "{% if algorithm.value == 'GradientBoostingClassifier' %}\n",
    "    'clf__loss': ['deviance', 'exponential'],\n",
    "    'clf__learning_rate': randfloat(0.001, 1.),\n",
    "    'clf__subsample': randfloat(0.01, 1.),\n",
    "{% elif algorithm.value == 'RandomForestClassifier' %}\n",
    "    'clf__oob_score': [True],\n",
    "    'clf__criterion': ['gini', 'entropy'],\n",
    "{% endif %}\n",
    "    'clf__n_estimators': randint(10, 200),\n",
    "    'clf__max_depth': randint(20, 50),\n",
    "    'clf__max_features': ['sqrt', 'log2', None],\n",
    "    'clf__min_impurity_decrease': randfloat(0., 0.2),\n",
    "    'clf__min_weight_fraction_leaf': randfloat(0., 0.5),\n",
    "}\n",
    "\n",
    "fit_params = {\n",
    "{% if algorithm.value == 'GradientBoostingClassifier' %}\n",
    "    'clf__monitor': early_stopping(5),\n",
    "{% endif %}\n",
    "}\n",
    "#}\n",
    "    \n",
    "cv = {{ cv_algorithm }}(\n",
    "    n_splits={{ cross_validation_n_folds }},\n",
    "    shuffle=True,\n",
    "    random_state=rng,\n",
    ")\n",
    "\n",
    "model =\n",
    "{%- if hyper_param_search.value != 'None' %} {{ hyper_param_search }}({% endif -%}\n",
    "    {%- if calibrated.value %} sk.calibration.CalibratedClassifierCV({% endif -%}\n",
    "        sk.pipeline.Pipeline([\n",
    "            ('reduce_dim', {{ dimensionality_reduction }}),\n",
    "            {%- if feature_selection.value != 'None' %}('feature_selection', {{ feature_selection }}),{% endif %}\n",
    "            ('clf', {{ algorithm }}),\n",
    "        ]),\n",
    "    cv=cv,\n",
    "{% if calibrated.value %}){% endif -%}{%- if hyper_param_search.value != 'None' %}){% endif %}\n",
    "\n",
    "# Scoring parameters\n",
    "primary_metric = '{{ primary_metric }}'\n",
    "evaluation_metrics = {{ evaluation_metrics }}\n",
    "scoring_params = {k: metrics.get_scorer(k)\n",
    "                  for k in [primary_metric, *evaluation_metrics]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "{% if hyper_param_search.value == 'None' %}\n",
    "\n",
    "df_results = pd.DataFrame()\n",
    "\n",
    "# Store performance on each split for computing ROC and PRC curves\n",
    "fprs = []\n",
    "tprs = []\n",
    "precs = []\n",
    "recs = []\n",
    "\n",
    "# Store cross-validation test predictions\n",
    "y_proba_cv = np.empty(len(y))\n",
    "y_proba_cv[:] = np.nan\n",
    "\n",
    "for fold, (train, test) in enumerate(cv.split(X.values, y)):\n",
    "    model.fit(X.values[train], y[train])\n",
    "    {% for metric in all_metrics %}\n",
    "    df_results.loc[fold, '{{ metric }}'] = scoring_params['{{ metric }}'](model, X.values[test], y[test])\n",
    "    {% endfor %}\n",
    "    y_proba = model.predict_proba(X.values[test]) # Probability prediction will be True\n",
    "    y_proba_cv[test] = y_proba[:, 1]\n",
    "    model_fpr, model_tpr, _ = metrics.roc_curve(y[test], y_proba[:, 1])\n",
    "    model_prec, model_rec, _ = metrics.precision_recall_curve(y[test], y_proba[:, 1])\n",
    "    fprs.append(model_fpr)\n",
    "    tprs.append(model_tpr)\n",
    "    precs.append(model_prec)\n",
    "    recs.append(model_rec)\n",
    "\n",
    "assert not(any(np.isnan(y_proba_cv))), 'All probabilities should have been calculated'\n",
    "\n",
    "display(df_results.agg(['mean', 'std']))\n",
    "{% else %}\n",
    "model.fit(X.values, y)\n",
    "df_results = model.cv_results_\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This visualization shows the cross-validated performance of the model. Low fold variance and high AUC is desired in a well-generalized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "tprs_interp = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "for fold, (fpr, tpr) in enumerate(zip(fprs, tprs)):\n",
    "    tpr_interp = np.interp(mean_fpr, fpr, tpr)\n",
    "    tpr_interp[0] = 0.\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    tprs_interp.append(tpr_interp)\n",
    "    aucs.append(roc_auc)\n",
    "    ax.plot(fpr, tpr, alpha=0.4, label='ROC Fold %d (AUC=%0.3f)' % (fold, roc_auc))\n",
    "\n",
    "mean_tpr = np.mean(tprs_interp, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = sk.metrics.auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "ax.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs_interp, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2)\n",
    "\n",
    "ax.plot([0,1],[0,1],'--', label='Random')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.legend()\n",
    "\n",
    "z = (mean_auc - 0.5)/std_auc\n",
    "cl = sp.stats.norm.cdf(z) * 100\n",
    "ci = sp.stats.norm.interval(0.95, loc=mean_auc, scale=std_auc)\n",
    "print('Confidence interval (95%)', ci)\n",
    "print(\"We are %0.3f %% confident the model's results are not just chance.\" % (cl))\n",
    "if cl > 95:\n",
    "    print('This is statistically significant. These results can be trusted.')\n",
    "else:\n",
    "    print('This is not statistically significant. These results should not be trusted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "precs_interp = []\n",
    "prc_aucs = []\n",
    "mean_rec = np.linspace(0, 1, 100)\n",
    "\n",
    "for fold, (rec, prec) in enumerate(zip(recs, precs)):\n",
    "    prec_interp = np.interp(mean_rec, rec[::-1], prec[::-1])\n",
    "    prc_auc = metrics.auc(rec, prec)\n",
    "    precs_interp.append(prec_interp)\n",
    "    prc_aucs.append(prc_auc)\n",
    "    ax.plot(rec, prec, alpha=0.4, label='PRC Fold %d (AUC=%0.3f)' % (fold, prc_auc))\n",
    "\n",
    "mean_prec = np.mean(precs_interp, axis=0)\n",
    "mean_auc = sk.metrics.auc(mean_rec, mean_prec)\n",
    "std_auc = np.std(prc_aucs)\n",
    "ax.plot(mean_rec, mean_prec, color='b',\n",
    "         label=r'Mean PRC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_prec = np.std(precs_interp, axis=0)\n",
    "precs_upper = np.minimum(mean_prec + std_prec, 1)\n",
    "precs_lower = np.maximum(mean_prec - std_prec, 0)\n",
    "plt.fill_between(mean_rec, precs_lower, precs_upper, color='grey', alpha=.2)\n",
    "\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.legend()\n",
    "\n",
    "z = (mean_auc - 0.5)/std_auc\n",
    "cl = sp.stats.norm.cdf(z) * 100\n",
    "ci = sp.stats.norm.interval(0.95, loc=mean_auc, scale=std_auc)\n",
    "print('Confidence interval (95%)', ci)\n",
    "print(\"We are %0.3f %% confident the model's results are not just chance.\" % (cl))\n",
    "if cl > 95:\n",
    "    print('This is statistically significant. These results can be trusted.')\n",
    "else:\n",
    "    print('This is not statistically significant. These results should not be trusted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Confusion Matrix (Cross-Validation)')\n",
    "sns.heatmap(\n",
    "    metrics.confusion_matrix(y, y_proba_cv > 0.5),\n",
    "    annot=True,\n",
    "    cmap=plt.cm.Blues,\n",
    "    fmt='g'\n",
    ")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine drug predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the binary classification model, we can rank the drug hits by their predicted score. The model can also be used to identify additional drugs that are likely to share properties with the hits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain prediction results\n",
    "y_probas = y_proba_cv\n",
    "results = pd.DataFrame(np.array([\n",
    "    Drugmonizome.get_drug_names(X.index),\n",
    "    y,\n",
    "    (y_probas > 0.5).astype('float64'),\n",
    "    y_probas,\n",
    "]).T, columns=[\n",
    "    'Name',\n",
    "    'Known',\n",
    "    'Predicted',\n",
    "    'Prediction Probability',\n",
    "], index=X.index).astype({'Known': 'float64', 'Predicted': 'float64', 'Prediction Probability': 'float64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Rank drug hits\n",
    "results[((results['Known'] == 1))].sort_values('Prediction Probability', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict additional drugs\n",
    "results[results['Known'] == 0].sort_values('Prediction Probability', ascending=False).head(25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drugmonizome-ml-appyter",
   "language": "python",
   "name": "drugmonizome-ml-appyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
