{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%appyter init\n",
    "from appyter import magic\n",
    "magic.init(lambda _=globals: _())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Cell Enrichment\n",
    "\n",
    "We prepare single cell data, computing clusters, differential expression, and enrichment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import scipy.sparse as sp_sparse\n",
    "import seaborn as sns\n",
    "from matplotlib_venn import venn2\n",
    "from geode import chdir\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from IPython.display import display\n",
    "from umap import UMAP\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import silhouette_score\n",
    "from maayanlab_bioinformatics.api import enrichr_link_from_genes, enrichr_get_top_results\n",
    "from maayanlab_bioinformatics.normalization import log2_normalize, zscore_normalize, quantile_normalize, filter_by_expr\n",
    "from maayanlab_bioinformatics.dge import characteristic_direction, up_down_from_characteristic_direction\n",
    "from maayanlab_bioinformatics.utils import merge, fetch_save_read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter hide_code_exec\n",
    "\n",
    "{% do SectionField(\n",
    "    name='INPUT',\n",
    "    label='Upload your single-cell data',\n",
    "    description='In various data formats, see file descriptions.',\n",
    ") %}\n",
    "\n",
    "{% set expression = FileField(\n",
    "    name='expression_matrix',\n",
    "    label='Expression matrix file',\n",
    "    description='[REQUIRED] Expression matrix file need to be a csv or txt file with genes by samples matrix. The values in the matrix can be read counts or normalized read counts such as CPM, RPKM, FPKM, TPM and etc',\n",
    "    default='biojupies_example_matrix.txt',\n",
    "    examples={'biojupies_example_matrix.txt': 'https://amp.pharm.mssm.edu/biojupies/app/static/data/biojupies_example_matrix.txt'},\n",
    "    section='INPUT',\n",
    ") %}\n",
    "\n",
    "{% set features = FileField(\n",
    "    name='features',\n",
    "    label='Features file',\n",
    "    description='[OPTIONAL] Features file need to be a csv or txt file with the transcripts on the rows and attributes on the columns, `symbol` is mandatory if provided and should contain a gene symbol.',\n",
    "    default='',\n",
    "    section='INPUT',\n",
    ") %}\n",
    "\n",
    "{% set barcodes = FileField(\n",
    "    name='barcodes',\n",
    "    label='Barcodes file',\n",
    "    description='[OPTIONAL] Barcodes file need to be a csv or txt file with the samples on the rows and attributes on the columns.',\n",
    "    default='biojupies_example_metadata.txt',\n",
    "    examples={'biojupies_example_metadata.txt': 'https://amp.pharm.mssm.edu/biojupies/app/static/data/biojupies_example_metadata.txt'},\n",
    "    section='INPUT',\n",
    ") %}\n",
    "\n",
    "{% do SectionField(\n",
    "    name='CONFIG',\n",
    "    label='Configuration',\n",
    "    description='Configure various parameters for the analysis',\n",
    ") %}\n",
    "\n",
    "{% set top_n_genes = IntField(\n",
    "    name='top_n_genes',\n",
    "    label='Number of Genes',\n",
    "    description='The number of \\'top\\' genes to use for differential expression',\n",
    "    default=250,\n",
    "    min=100,\n",
    "    max=1000,\n",
    "    section='CONFIG',\n",
    ") %}\n",
    "\n",
    "{% set top_n_results = IntField(\n",
    "    name='top_n_results',\n",
    "    label='Number of Top Enrichment Results',\n",
    "    description='The number of \\'top\\' results to keep from enrichment analysis',\n",
    "    default=5,\n",
    "    min=1,\n",
    "    max=100,\n",
    "    section='CONFIG',\n",
    ") %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "# random state for reproducible output\n",
    "random_state = 42\n",
    "\n",
    "# the single cell data\n",
    "expression = {{ expression }}\n",
    "\n",
    "{% if features.value %}\n",
    "features = {{ features }}\n",
    "{% endif %}\n",
    "\n",
    "{% if barcodes.value %}\n",
    "barcodes = {{ barcodes }}\n",
    "{% endif %}\n",
    "\n",
    "# The number of 'top' genes to use for differential expression\n",
    "top_n_genes = {{ top_n_genes }}\n",
    "\n",
    "# The number of 'top' results to keep from enrichment analysis\n",
    "top_n_results = {{ top_n_results }}\n",
    "\n",
    "# TODO: add enrichr libraries as categories as fields\n",
    "useful_libs = OrderedDict([\n",
    "  ('cell_type', ['Human_Gene_Atlas', 'Mouse_Gene_Atlas', 'ARCHS4_Tissues']),\n",
    "  ('pathways', ['WikiPathways_2019_Mouse', 'WikiPathways_2019_Human']),\n",
    "  ('transcription', ['ARCHS4_TFs_Coexp', 'ENCODE_and_ChEA_Consensus_TFs_from_ChIP-X']),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "def load_dataframe(file):\n",
    "    ''' Load a file by downloading it or reading it if already downloaded.\n",
    "    '''\n",
    "    if not os.path.exists(file):\n",
    "        import urllib.request\n",
    "        urllib.request.urlretrieve(f\"{{ url_for(_session, filename='', public=True) }}/{file}\")\n",
    "\n",
    "    ext = os.path.splitext(file)[1]\n",
    "    if ext in {'.tsv', '.txt'}:\n",
    "        df = pd.read_csv(file, sep='\\t', index_col=0)\n",
    "    elif ext == '.csv':\n",
    "        df = pd.read_csv(file, index_col=0)\n",
    "    else:\n",
    "        raise Exception('Unrecognized file format', ext)\n",
    "\n",
    "    # Fix any type coersion on identifiers\n",
    "    df.index = df.index.astype(str)\n",
    "    df.columns = df.columns.astype(str)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "df_expression = load_dataframe(expression)\n",
    "display(df_expression.head())\n",
    "\n",
    "{% if features.value %}\n",
    "df_features = load_dataframe(features)\n",
    "display(df_expression.head())\n",
    "{% endif %}\n",
    "\n",
    "{% if barcodes.value %}\n",
    "df_barcodes = load_dataframe(barcodes)\n",
    "display(df_barcodes.head())\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "{% if barcodes.value %}\n",
    "venn2([\n",
    "    set(df_expression.columns),\n",
    "    set(df_barcodes.index),\n",
    "], [\n",
    "    'expression matrix (column)',\n",
    "    'barcodes (index)',\n",
    "])\n",
    "plt.show()\n",
    "assert set(df_expression.columns) & set(df_barcodes.index), \"There should be overlap or we won't have any barcodes!\"\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "{% if features.value %}\n",
    "venn2([\n",
    "    set(df_expression.index),\n",
    "    set(df_features.index),\n",
    "], [\n",
    "    'expression matrix (index)',\n",
    "    'features (index)',\n",
    "])\n",
    "plt.show()\n",
    "assert set(df_expression.index) & set(df_features.index), \"There should be overlap or we won't have any features!\"\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "{% if features.value %}\n",
    "## Map transcripts to Genes\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "{# TODO: allow organism to be configured #}\n",
    "{% if features.value %}\n",
    "# Get NCBI Gene information\n",
    "ncbi = pd.read_csv('ftp://ftp.ncbi.nih.gov/gene/DATA/GENE_INFO/Mammalia/Homo_sapiens.gene_info.gz', sep='\\t')\n",
    "# Ensure nulls are treated as such\n",
    "ncbi = ncbi.applymap(lambda v: float('nan') if type(v) == str and v == '-' else v)\n",
    "# Break up lists\n",
    "split_list = lambda v: v.split('|') if type(v) == str else []\n",
    "ncbi['dbXrefs'] = ncbi['dbXrefs'].apply(split_list)\n",
    "ncbi['Synonyms'] = ncbi['Synonyms'].apply(split_list)\n",
    "ncbi['LocusTag'] = ncbi['LocusTag'].apply(split_list)\n",
    "ncbi['Other_designations'] = ncbi['Other_designations'].apply(split_list)\n",
    "\n",
    "# Map existing entities to NCBI Genes\n",
    "ncbi_lookup = {\n",
    "  sym.upper(): row['Symbol'].upper()\n",
    "  for _, row in ncbi.iterrows()\n",
    "  for sym in [row['Symbol']] + row['Synonyms']\n",
    "}\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "{% if features.value %}\n",
    "# Select transcripts with highest variance corresponding to genes\n",
    "df_transcript_genes = merge(\n",
    "  df_expression.var(axis=1).to_frame('var'),\n",
    "  df_features[['symbol']].applymap(lambda s: str(ncbi_lookup.get(s.upper())))\n",
    ").groupby('symbol')['var'].idxmax().reset_index()\n",
    "df_transcript_genes.index = df_transcript_genes['var']\n",
    "df_transcript_genes = df_transcript_genes.drop('var', axis=1)\n",
    "df_transcript_genes\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain a gene expression matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "{% if features.value %}\n",
    "df_gene_expression = df_expression.loc[df_transcript_genes.index]\n",
    "df_gene_expression.index = df_transcript_genes['symbol']\n",
    "{% else %}\n",
    "df_gene_expression = df_expression\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Gene Expression Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review existing library size and distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_library_size = pd.DataFrame(\n",
    "    {\n",
    "        'n_reads': df_gene_expression[df_gene_expression > 0].count(),\n",
    "        'log_n_reads': np.log2(df_gene_expression[df_gene_expression > 0].count() + 1),\n",
    "        'n_expressed_genes': df_gene_expression.sum(),\n",
    "    }\n",
    ").sort_values('n_reads', ascending=False)\n",
    "\n",
    "display(df_library_size.head())\n",
    "sns.distplot(df_gene_expression.iloc[0, :]); plt.show()\n",
    "sns.distplot(df_gene_expression.iloc[:, 0]); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "{# TODO: make configurable #}\n",
    "\n",
    "df_gene_expression_norm = filter_by_expr(df_gene_expression)\n",
    "df_gene_expression_norm = log2_normalize(df_gene_expression_norm)\n",
    "df_gene_expression_norm = zscore_normalize(df_gene_expression_norm.T).T\n",
    "df_gene_expression_norm = quantile_normalize(df_gene_expression_norm)\n",
    "\n",
    "display(df_gene_expression_norm.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review normalized count distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "{# TODO: potentially evaluate kurtosis and warn about problems with normalization #}\n",
    "sns.distplot(df_gene_expression_norm.iloc[0, :]); plt.show()\n",
    "sns.distplot(df_gene_expression_norm.iloc[:, 0]); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction & Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "gene_expression_norm_pca = PCA(random_state=random_state)\n",
    "gene_expression_norm_pca.fit(df_gene_expression_norm.values.T)\n",
    "df_gene_expression_norm_pca = pd.DataFrame(\n",
    "    gene_expression_norm_pca.transform(df_gene_expression_norm.values.T),\n",
    "    index=df_gene_expression_norm.T.index\n",
    ")\n",
    "df_gene_expression_norm_pca.columns = [\n",
    "    f'PCA-{c} ({r:.3f})'\n",
    "    for c, r in zip(df_gene_expression_norm_pca.columns, gene_expression_norm_pca.explained_variance_ratio_)\n",
    "]\n",
    "display(df_gene_expression_norm_pca.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "  px.scatter(\n",
    "    merge(\n",
    "      df_gene_expression_norm_pca,\n",
    "      df_library_size,\n",
    "    ),\n",
    "    x=df_gene_expression_norm_pca.columns[0],\n",
    "    y=df_gene_expression_norm_pca.columns[1],\n",
    "    size='n_reads',\n",
    "    size_max=8,\n",
    "    hover_data=[df_gene_expression_norm.columns],\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "{# TODO: make configurable #}\n",
    "gene_expression_norm_umap = UMAP(\n",
    "  random_state=random_state,\n",
    "  n_components=2,\n",
    "  n_neighbors=30,\n",
    "  metric='cosine',\n",
    "  min_dist=0.3,\n",
    ")\n",
    "gene_expression_norm_umap.fit(df_gene_expression_norm_pca.iloc[:, :10].values)\n",
    "\n",
    "df_gene_expression_norm_umap = pd.DataFrame(\n",
    "  gene_expression_norm_umap.transform(df_gene_expression_norm_pca.iloc[:, :10].values),\n",
    "  columns=['UMAP-1', 'UMAP-2'],\n",
    "  index=df_gene_expression_norm_pca.index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "  px.scatter(\n",
    "    merge(\n",
    "      df_gene_expression_norm_umap,\n",
    "      df_library_size,\n",
    "    ),\n",
    "    x=df_gene_expression_norm_umap.columns[0],\n",
    "    y=df_gene_expression_norm_umap.columns[1],\n",
    "    size='n_reads',\n",
    "    size_max=8,\n",
    "    hover_data=[df_gene_expression_norm.columns],\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Silhouette Cluster Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_scores = {}\n",
    "for n in range(2, min(df_gene_expression_norm_umap.shape[0] - 1, 25)):\n",
    "    np.random.seed(0)\n",
    "    y_pred = KMeans(n_clusters=n, random_state=random_state).fit_predict(df_gene_expression_norm_umap.values)\n",
    "    silhouette_scores[n] = silhouette_score(df_gene_expression_norm_umap.values, y_pred, metric='cosine')\n",
    "\n",
    "silhouette_scores = pd.DataFrame([\n",
    "    {'N Clusters': k, 'Silhouette Score': v}\n",
    "    for k, v in silhouette_scores.items()\n",
    "])\n",
    "best = silhouette_scores.sort_values('Silhouette Score').iloc[-1]\n",
    "silhouette_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(silhouette_scores['N Clusters'], silhouette_scores['Silhouette Score'])\n",
    "plt.scatter([best['N Clusters']], [best['Silhouette Score']], label='Best')\n",
    "plt.legend()\n",
    "plt.title('Cluster size selection')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=int(best['N Clusters']), random_state=random_state)\n",
    "df_gene_expression_norm_km = pd.DataFrame({\n",
    "    'Cluster': [\n",
    "        str(c)\n",
    "        for c in km.fit_predict(df_gene_expression_norm_umap.values)\n",
    "    ]\n",
    "}, index=df_gene_expression_norm_umap.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA with Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "  merge(\n",
    "    df_gene_expression_norm_pca,\n",
    "    df_gene_expression_norm_km,\n",
    "    df_library_size,\n",
    "  ),\n",
    "  x=df_gene_expression_norm_pca.columns[0],\n",
    "  y=df_gene_expression_norm_pca.columns[1],\n",
    "  size='n_reads',\n",
    "  size_max=8,\n",
    "  color='Cluster',\n",
    "  hover_data=[df_gene_expression_norm.columns],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP with Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "  merge(\n",
    "    df_gene_expression_norm_umap,\n",
    "    df_gene_expression_norm_km,\n",
    "    df_library_size,\n",
    "  ),\n",
    "  x=df_gene_expression_norm_umap.columns[0],\n",
    "  y=df_gene_expression_norm_umap.columns[1],\n",
    "  size='n_reads',\n",
    "  size_max=8,\n",
    "  color='Cluster',\n",
    "  hover_data=[df_gene_expression_norm.columns],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differential Expression\n",
    "\n",
    "We perform differential expression for each cluster in a one vs rest fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform differential expression for each cluter\n",
    "top_genes = {}\n",
    "for cluster, samples in df_gene_expression_norm_km.groupby('Cluster'):\n",
    "  top_genes[cluster] = up_down_from_characteristic_direction(\n",
    "    characteristic_direction(\n",
    "      # expression outside of this cluster\n",
    "      df_gene_expression_norm.loc[:, df_gene_expression_norm.columns.difference(samples.index)],\n",
    "      # expression in this cluster\n",
    "      df_gene_expression_norm.loc[:, samples.index],\n",
    "    ),\n",
    "    top_n_genes,\n",
    "  )\n",
    "\n",
    "display(top_genes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enrichment Analysis\n",
    "\n",
    "### We submit differentially expressed genes to Enrichr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Enrichr links for each cluster\n",
    "enrichr_links = {}\n",
    "\n",
    "for cluster, genes in top_genes.items():\n",
    "  up_link, dn_link = None, None\n",
    "  if len(genes.up):\n",
    "    up_link = enrichr_link_from_genes(sorted(genes.up), 'cluster %s up' % (cluster))\n",
    "    # display_link_inline(up_link['link'])\n",
    "  else:\n",
    "    print('cluster %s up: empty' % (cluster))\n",
    "  if len(genes.down):\n",
    "    dn_link = enrichr_link_from_genes(sorted(genes.down), 'cluster %s down' % (cluster))\n",
    "    # display_link_inline(dn_link['link'])\n",
    "  else:\n",
    "    print('cluster %s down: empty' % (cluster))\n",
    "  enrichr_links[cluster] = {\n",
    "    'up': up_link,\n",
    "    'down': dn_link,\n",
    "  }\n",
    "\n",
    "pd.DataFrame(enrichr_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab top results from Enrichr results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab top results for each cluster\n",
    "all_results = []\n",
    "for cluster, links in enrichr_links.items():\n",
    "  for link_type, link in links.items():\n",
    "    if link is None:\n",
    "      continue\n",
    "    for category, libraries in useful_libs.items():\n",
    "      for library in libraries:\n",
    "        try:\n",
    "          results = enrichr_get_top_results(link['userListId'], library).sort_values('pvalue').iloc[:top_n_results]\n",
    "          results['link'] = link['link']\n",
    "          results['library'] = library\n",
    "          results['category'] = category\n",
    "          results['direction'] = link_type\n",
    "          results['cluster'] = cluster\n",
    "          all_results.append(results)\n",
    "        except:\n",
    "          print('{}: {} {} {} cluster {} failed, continuing'.format(link, library, category, link_type, cluster))\n",
    "\n",
    "df_all_results = pd.concat(all_results)\n",
    "df_all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export results for scEnrichr Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = merge(df_gene_expression_norm_km, df_gene_expression_norm_pca)\n",
    "g.index.rename('Barcode', inplace=True)\n",
    "g.reset_index().to_csv(\n",
    "  'df_pca.tsv',\n",
    "  sep='\\t',\n",
    "  index=None,\n",
    ")\n",
    "\n",
    "g = merge(df_gene_expression_norm_km, df_gene_expression_norm_umap)\n",
    "g.index.rename('Barcode', inplace=True)\n",
    "g.reset_index().to_csv(\n",
    "  'df_umap.tsv',\n",
    "  sep='\\t',\n",
    "  index=None,\n",
    ")\n",
    "\n",
    "df_all_results.to_csv(\n",
    "  'df_enrich.tsv',\n",
    "  sep='\\t',\n",
    "  index=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "\n",
    "The files are now available for download and for display with the scEnrichr Dashboard:\n",
    "\n",
    "- [df_pca.tsv](./df_pca.tsv)\n",
    "- [df_umap.tsv](./df_umap.tsv)\n",
    "- [df_enrich.tsv](./df_enrich.tsv)\n",
    "\n",
    "\n",
    "**[View Dashboard](../dashboard/{{ _session }})**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
