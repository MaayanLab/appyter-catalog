{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%appyter init\n",
    "from appyter import magic\n",
    "magic.init(lambda _=globals: _())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNA-seq Data and Metadata Analysis Appyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook template provides a pipeline for the visualization and analysis of RNA-seq gene read counts. \n",
    "\n",
    "### Analysis Overview \n",
    "\n",
    "The RNA-seq data first undergoes normalization and dimensionality reduction via Principle Component Analysis (PCA) and Uniform Manifold Approximation and Projection (UMAP). Samples are then clustered based on their most-associated highly-variable genes and metadata features. The number of clusters is determined based on a modified silhouette score which prioritizes having more clusters over having larger clusters. Clusters are visualized using the [React-Scatter-Board](https://github.com/MaayanLab/react-scatter-board) package. \n",
    "\n",
    "The most up-regulated and down-regulated genes are also identified for each cluster. These genes are used to perform enrichment analysis via the [Enrichr](https://maayanlab.cloud/Enrichr/) API. The enrichment results are visualized with the [React-GSEA](https://github.com/MaayanLab/react-GSEA/tree/simplified) package. \n",
    "\n",
    "Finally, similar and opposite drug/small molecule signatures are queried using the [L1000FWD](https://maayanlab.cloud/L1000FWD/) API. \n",
    "\n",
    "*Note: If using GTEx data or other healthy tissue sample data for which querying drug signatures is not relevant, please use the GTEx Tissue-Specific RNA-seq Analysis Appyter instead. If using GEO data, please use the [Bulk RNA-seq Analysis Appyter](https://appyters.maayanlab.cloud/Bulk_RNA_seq/).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Notebook Setup\n",
    "Import packages and set appropriate file names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from matplotlib import pyplot as plt \n",
    "import seaborn as sns\n",
    "from umap import UMAP\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, silhouette_samples, silhouette_score, plot_roc_curve\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.cm as cm\n",
    "from maayanlab_bioinformatics.dge import characteristic_direction\n",
    "from maayanlab_bioinformatics.normalization import log2_normalize, filter_by_var, zscore_normalize\n",
    "from maayanlab_bioinformatics.utils import merge\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "from react_scatter_board.jupyter_compat import ScatterBoard\n",
    "from IPython.display import display, IFrame, Markdown, HTML\n",
    "from textwrap import wrap\n",
    "from react_gsea import ReactGSEA, dataFromResult\n",
    "from react_gsea.jupyter_compat import ReactGSEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook display util functions\n",
    "def download_button(content, label, filename):\n",
    "    # Add download button\n",
    "    outname = filename.split('.')[0]\n",
    "    display(HTML('<textarea id=\"textbox_{outname}\" style=\"display: none;\">{content}</textarea> <button style=\"margin:10px 0;\" id=\"create_{outname}\">{label}</button> <a download=\"{filename}\" id=\"downloadlink_{outname}\" style=\"display: none\">Download</a>'.format(**locals())))\n",
    "    display(HTML('<script type=\"text/javascript\">!function(){{var e=null,t=document.getElementById(\"create_{outname}\"),n=document.getElementById(\"textbox_{outname}\");t.addEventListener(\"click\",function(){{var t,l,c=document.getElementById(\"downloadlink_{outname}\");c.href=(t=n.value,l=new Blob([t],{{type:\"text/plain\"}}),null!==e&&window.URL.revokeObjectURL(e),e=window.URL.createObjectURL(l)),c.click()}},!1)}}();</script>'.format(**locals())))\n",
    "\n",
    "def make_clickable(link):\n",
    "    return f'<a target=\"_blank\" href=\"{link}\">{link}</a>'\n",
    "\n",
    "def figure_header(label,title):\n",
    "    display(HTML(f\"<div style='font-size:2rem; padding:1rem 0;'><b>{label}</b>: {title}</div>\"))\n",
    "    \n",
    "def figure_legend(label,title,content=\"\"):\n",
    "    display(HTML(f\"<div style='font-size:1.5rem;'><b>{label}</b>: <i>{title}</i>. {content} </div>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter hide\n",
    "{% do SectionField(\n",
    "    name = 'DATASETS',\n",
    "    title = 'Dataset Selection',\n",
    "    subtitle = 'Upload datasets for visualization and analysis. Both file uploads are required to run the analysis.'\n",
    ") %}\n",
    "\n",
    "{% do SectionField(\n",
    "    name = 'PARAMETERS',\n",
    "    title = 'Analysis Parameters',\n",
    "    subtitle = 'Set parameters for analysis.'\n",
    ") %}\n",
    "\n",
    "{% do SectionField(\n",
    "    name = \"ENRICHR_LIBS\",\n",
    "    title = \"Enrichment Analysis Library Selection\",\n",
    "    subtitle = \"Choose Enrichr geneset libraries for comparison against input genes. Multiple libraries can be selected from each section. If nothing is selected, default libraries will be used.\"\n",
    ") %}\n",
    "\n",
    "{% set data_filename = FileField(\n",
    "    name='data_filename',\n",
    "    label='RNA-seq data file',\n",
    "    description='TSV or CSV file containing RNA-seq read counts. Index should be Entrez gene symbols, and columns should be individual samples.',\n",
    "    default='',\n",
    "    examples = {\n",
    "        'GSE159266 Data': 'https://appyters.maayanlab.cloud/storage/RNAseq_Data_Metadata_Analysis/GSE159266_data_cleaned.txt'\n",
    "    },\n",
    "    section='DATASETS'\n",
    ") %}\n",
    "\n",
    "{% set metadata_filename = FileField(\n",
    "    name='metadata_filename',\n",
    "    label='Sample metadata file',\n",
    "    description='TSV or CSV file containing sample metadata. Index should be sample IDs corresponding to columns of RNA-seq data file, and columns should be different sample attributes.',\n",
    "    default='',\n",
    "    examples = {\n",
    "        'GSE159266 Metadata': 'https://appyters.maayanlab.cloud/storage/RNAseq_Data_Metadata_Analysis/GSE159266_metadata_cleaned.txt'\n",
    "    },\n",
    "    section='DATASETS'\n",
    ") %}\n",
    "\n",
    "{% set n_neighbors = IntField(\n",
    "    name = 'n_neighbors',\n",
    "    label = 'Number of neighbors to use for UMAP calculations',\n",
    "    description = 'Smaller values preserve local structure, while larger values emphasize global structure.',\n",
    "    default = 40,\n",
    "    min = 2,\n",
    "    max = 200,\n",
    "    section = 'PARAMETERS'\n",
    ") %}\n",
    "\n",
    "{% set min_cluster_dist = FloatField(\n",
    "    name = 'min_cluster_dist',\n",
    "    label = 'Minimum distance between UMAP-projected points',\n",
    "    description = 'Determines how close/distant points belonging to different clusters are from each other.',\n",
    "    default = 0.3,\n",
    "    min = 0.1,\n",
    "    max = 1,\n",
    "    section = 'PARAMETERS'\n",
    ") %}\n",
    "\n",
    "{% set top_n_genes = IntField(\n",
    "    name = 'top_n_genes',\n",
    "    label = 'Number of genes to analyze',\n",
    "    description = 'Number of top variable genes to use in analysis.',\n",
    "    default = 2500,\n",
    "    section = 'PARAMETERS'\n",
    ") %}\n",
    "\n",
    "{% set top_n_genes_enrichment = IntField(\n",
    "    name = 'top_n_genes_enrichment',\n",
    "    label = 'Number of genes to use for enrichment analysis',\n",
    "    description = 'Number of top variable genes to use for enrichment analysis; must be less than top_n_genes.',\n",
    "    default = 250,\n",
    "    section = 'PARAMETERS'\n",
    ") %}\n",
    "\n",
    "{% set do_l1000 = BoolField(\n",
    "    name = 'do_l1000',\n",
    "    label = 'Query L1000 signatures?',\n",
    "    description = 'Option to query opposite and similar L1000 signatures to input data using L1000FWD.',\n",
    "    default = True,\n",
    "    section = 'PARAMETERS'\n",
    ") %}\n",
    "\n",
    "{% set transcription_libraries = MultiChoiceField(\n",
    "    name = 'transcription_libraries',\n",
    "    label = 'Transcription Libraries',\n",
    "    description = 'Default library is ENCODE_TF_ChIP-seq_2015',\n",
    "    choices = [\n",
    "        'ARCHS4_TFs_Coexp',\n",
    "        'ChEA_2016',\n",
    "        'ENCODE_and_ChEA_Consensus_TFs_from_ChIP-X',\n",
    "        'ENCODE_Histone_Modifications_2015',\n",
    "        'ENCODE_TF_ChIP-seq_2015',\n",
    "        'Epigenomics_Roadmap_HM_ChIP-seq',\n",
    "        'Enrichr_Submissions_TF-Gene_Coocurrence',\n",
    "        'Genome_Browser_PWMs',\n",
    "        'lncHUB_lncRNA_Co-Expression',\n",
    "        'miRTarBase_2017',\n",
    "        'TargetScan_microRNA_2017',\n",
    "        'TF-LOF_Expression_from_GEO',\n",
    "        'TF_Perturbations_Followed_by_Expression',\n",
    "        'Transcription_Factor_PPIs',\n",
    "        'TRANSFAC_and_JASPAR_PWMs',\n",
    "        'TRRUST_Transcription_Factors_2019'\n",
    "    ],\n",
    "    default = [\n",
    "        'ENCODE_TF_ChIP-seq_2015'\n",
    "    ],\n",
    "    section = 'ENRICHR_LIBS'\n",
    ") %}\n",
    "\n",
    "{% set pathway_libraries = MultiChoiceField(\n",
    "    name = \"pathway_libraries\",\n",
    "    label = \"Pathway Libraries\",\n",
    "    description = 'Default libraries are KEGG_2019_Human and KEGG_2019_Mouse',\n",
    "    choices = [\n",
    "        'ARCHS4_Kinases_Coexp',\n",
    "        'BioCarta_2016',\n",
    "        'BioPlanet_2019',\n",
    "        'BioPlex_2017',\n",
    "        'CORUM',\n",
    "        'Elsevier_Pathway_Collection',\n",
    "        'HMS_LINCS_KinomeScan',\n",
    "        'HumanCyc_2016',\n",
    "        'huMAP',\n",
    "        'KEA_2015',\n",
    "        'KEGG_2019_Human',\n",
    "        'KEGG_2019_Mouse',\n",
    "        'Kinase_Perturbations_from_GEO_down',\n",
    "        'Kinase_Perturbations_from_GEO_up',\n",
    "        'L1000_Kinase_and_GPCR_Perturbations_down',\n",
    "        'L1000_Kinase_and_GPCR_Perturbations_up',\n",
    "        'NCI-Nature_2016',\n",
    "        'NURSA_Human_Endogenous_Complexome',\n",
    "    ],\n",
    "    default = [\n",
    "        'KEGG_2019_Human', \n",
    "        'KEGG_2019_Mouse'\n",
    "    ],\n",
    "    section = 'ENRICHR_LIBS'\n",
    ") %}\n",
    "\n",
    "{% set ontology_libraries = MultiChoiceField(\n",
    "    name = 'ontology_libraries',\n",
    "    label = 'Ontology Libraries',\n",
    "    description = 'Default libraries are GO_Biological_Process_2018 and MGI_Mammalian_Phenotype_Level_4_2019',\n",
    "    choices = [\n",
    "        'GO_Biological_Process_2018',\n",
    "        'GO_Cellular_Component_2018',\n",
    "        'GO_Molecular_Function_2018',\n",
    "        'Human_Phenotype_Ontology',\n",
    "        'Jensen_COMPARTMENTS',\n",
    "        'Jensen_DISEASES',\n",
    "        'Jensen_TISSUES',\n",
    "        'MGI_Mammalian_Phenotype_Level_4_2019'\n",
    "    ],\n",
    "    default = [\n",
    "        'GO_Biological_Process_2018', \n",
    "        'MGI_Mammalian_Phenotype_Level_4_2019'],\n",
    "    section = 'ENRICHR_LIBS'\n",
    ") %}\n",
    "\n",
    "{% set disease_drug_libraries = MultiChoiceField(\n",
    "    name = 'disease_drug_libraries',\n",
    "    label = 'Disease Drug Libraries',\n",
    "    description = 'Default library is GWAS_Catalog_2019',\n",
    "    choices = [\n",
    "        'Achilles_fitness_decrease',\n",
    "        'Achilles_fitness_increase',\n",
    "        'ARCHS4_IDG_Coexp',\n",
    "        'ClinVar_2019',\n",
    "        'dbGaP',\n",
    "        'DepMap_WG_CRISPR_Screens_Broad_CellLines_2019',\n",
    "        'DepMap_WG_CRISPR_Screens_Sanger_CellLines_2019',\n",
    "        'DisGeNET',\n",
    "        'DrugMatrix',\n",
    "        'DSigDB',\n",
    "        'GeneSigDB',\n",
    "        'GWAS_Catalog_2019',\n",
    "        'LINCS_L1000_Chem_Pert_down',\n",
    "        'LINCS_L1000_Chem_Pert_up',\n",
    "        'LINCS_L1000_Ligand_Perturbations_down',\n",
    "        'LINCS_L1000_Ligand_Perturbations_up',\n",
    "        'MSigDB_Computational',\n",
    "        'MSigDB_Oncogenic_Signatures',\n",
    "        'Old_CMAP_down',\n",
    "        'Old_CMAP_up',\n",
    "        'OMIM_Disease',\n",
    "        'OMIM_Expanded',\n",
    "        'PheWeb_2019',\n",
    "        'Rare_Diseases_AutoRIF_ARCHS4_Predictions',\n",
    "        'Rare_Diseases_AutoRIF_Gene_Lists',\n",
    "        'Rare_Diseases_GeneRIF_ARCHS4_Predictions',\n",
    "        'Rare_Diseases_GeneRIF_Gene_Lists',\n",
    "        'UK_Biobank_GWAS_v1',\n",
    "        'Virus_Perturbations_from_GEO_down',\n",
    "        'Virus_Perturbations_from_GEO_up',\n",
    "        'VirusMINT'\n",
    "    ],\n",
    "    default = [\n",
    "        'GWAS_Catalog_2019'\n",
    "    ],\n",
    "    section = 'ENRICHR_LIBS'\n",
    ") %}\n",
    "\n",
    "{% set cell_type_libraries = MultiChoiceField(\n",
    "    name = 'cell_type_libraries',\n",
    "    label = 'Cell Type Libraries',\n",
    "    description = 'No libraries selected by default',\n",
    "    choices = [\n",
    "        'Allen_Brain_Atlas_down',\n",
    "        'Allen_Brain_Atlas_up',\n",
    "        'ARCHS4_Cell-lines',\n",
    "        'ARCHS4_Tissues',\n",
    "        'Cancer_Cell_Line_Encyclopedia',\n",
    "        'CCLE_Proteomics_2020',\n",
    "        'ESCAPE',\n",
    "        'GTEx_Tissue_Sample_Gene_Expression_Profiles_down',\n",
    "        'GTEx_Tissue_Sample_Gene_Expression_Profiles_up',\n",
    "        'Human_Gene_Atlas',\n",
    "        'Mouse_Gene_Atlas',\n",
    "        'NCI-60_Cancer_Cell_Lines',\n",
    "        'ProteomicsDB_2020',\n",
    "        'Tissue_Protein_Expression_from_Human_Proteome_Map'\n",
    "    ],\n",
    "    default = [],\n",
    "    section = 'ENRICHR_LIBS'\n",
    ") %}\n",
    "\n",
    "{% set misc_libraries = MultiChoiceField(\n",
    "    name = 'misc_libraries',\n",
    "    label = 'Miscellaneous Libraries',\n",
    "    description = 'No libraries selected by default',\n",
    "    choices = [\n",
    "        'Chromosome_Location_hg19',\n",
    "        'Data_Acquisition_Method_Most_Popular_Genes',\n",
    "        'Enrichr_Libraries_Most_Popular_Genes',\n",
    "        'Genes_Associated_with_NIH_Grants',\n",
    "        'HMDB_Metabolites',\n",
    "        'HomoloGene',\n",
    "        'InterPro_Domains_2019',\n",
    "        'NIH_Funded_PIs_2017_AutoRIF_ARCHS4_Predictions',\n",
    "        'NIH_Funded_PIs_2017_GeneRIF_ARCHS4_Predictions',\n",
    "        'NIH_Funded_PIs_2017_Human_AutoRIF',\n",
    "        'NIH_Funded_PIs_2017_Human_GeneRIF',\n",
    "        'Pfam_Domains_2019',\n",
    "        'Pfam_InterPro_Domains',\n",
    "        'Table_Mining_of_CRISPR_Studies'\n",
    "    ],\n",
    "    default = [],\n",
    "    section = 'ENRICHR_LIBS'\n",
    ") %}\n",
    "\n",
    "{% set legacy_libraries = MultiChoiceField(\n",
    "    name = 'legacy_libraries',\n",
    "    label = 'Legacy Libraries',\n",
    "    description = 'No libraries selected by default',\n",
    "    choices = [\n",
    "        'BioCarta_2013',\n",
    "        'BioCarta_2015',\n",
    "        'ChEA_2013',\n",
    "        'ChEA_2015',\n",
    "        'Chromosome_Location',\n",
    "        'Disease_Signatures_from_GEO_down_2014',\n",
    "        'Disease_Signatures_from_GEO_up_2014',\n",
    "        'Drug_Perturbations_from_GEO_2014',\n",
    "        'ENCODE_Histone_Modifications_2013',\n",
    "        'ENCODE_TF_ChIP-seq_2014',\n",
    "        'GO_Biological_Process_2013',\n",
    "        'GO_Biological_Process_2015',\n",
    "        'GO_Biological_Process_2017',\n",
    "        'GO_Biological_Process_2017b',\n",
    "        'GO_Cellular_Component_2013',\n",
    "        'GO_Cellular_Component_2015',\n",
    "        'GO_Cellular_Component_2017',\n",
    "        'GO_Cellular_Component_2017b',\n",
    "        'GO_Molecular_Function_2013',\n",
    "        'GO_Molecular_Function_2015',\n",
    "        'GO_Molecular_Function_2017',\n",
    "        'GO_Molecular_Function_2017b',\n",
    "        'HumanCyc_2015',\n",
    "        'KEA_2013',\n",
    "        'KEGG_2013',\n",
    "        'KEGG_2015',\n",
    "        'KEGG_2016',\n",
    "        'MGI_Mammalian_Phenotype_2013',\n",
    "        'MGI_Mammalian_Phenotype_2017',\n",
    "        'MGI_Mammalian_Phenotype_Level_3',\n",
    "        'MGI_Mammalian_Phenotype_Level_4',\n",
    "        'NCI-Nature_2015',\n",
    "        'Panther_2015',\n",
    "        'Reactome_2013',\n",
    "        'Reactome_2015',\n",
    "        'TargetScan_microRNA',\n",
    "        'Tissue_Protein_Expression_from_ProteomicsDB',\n",
    "        'WikiPathways_2013',\n",
    "        'WikiPathways_2015',\n",
    "        'WikiPathways_2016'\n",
    "    ],\n",
    "    default = [],\n",
    "    section = 'ENRICHR_LIBS'\n",
    ") %}\n",
    "\n",
    "{% set crowd_libraries = MultiChoiceField(\n",
    "    name = 'crowd_libraries',\n",
    "    label = 'Crowd Libraries',\n",
    "    description = 'No libraries selected by default',\n",
    "    choices = [\n",
    "        'Aging_Perturbations_from_GEO_down',\n",
    "        'Aging_Perturbations_from_GEO_up',\n",
    "        'Disease_Perturbations_from_GEO_down',\n",
    "        'Disease_Perturbations_from_GEO_up',\n",
    "        'Drug_Perturbations_from_GEO_down',\n",
    "        'Drug_Perturbations_from_GEO_up',\n",
    "        'Gene_Perturbations_from_GEO_down',\n",
    "        'Gene_Perturbations_from_GEO_up',\n",
    "        'Ligand_Perturbations_from_GEO_down',\n",
    "        'Ligand_Perturbations_from_GEO_up',\n",
    "        'MCF7_Perturbations_from_GEO_down',\n",
    "        'MCF7_Perturbations_from_GEO_up',\n",
    "        'Microbe_Perturbations_from_GEO_down',\n",
    "        'Microbe_Perturbations_from_GEO_up',\n",
    "        'RNA-Seq_Disease_Gene_and_Drug_Signatures_from_GEO',\n",
    "        'SysMyo_Muscle_Gene_Sets'\n",
    "    ],\n",
    "    default = [],\n",
    "    section = 'ENRICHR_LIBS'\n",
    ") %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "data_filename = {{ data_filename }}\n",
    "metadata_filename = {{ metadata_filename }}\n",
    "\n",
    "n_neighbors = {{ n_neighbors }}\n",
    "min_cluster_dist = {{ min_cluster_dist }}\n",
    "top_n_genes = {{ top_n_genes }}\n",
    "top_n_genes_enrichment = {{ top_n_genes_enrichment }}\n",
    "do_l1000 = {{ do_l1000 }}\n",
    "\n",
    "transcription_libraries = {{ transcription_libraries }}\n",
    "pathway_libraries = {{ pathway_libraries }}\n",
    "ontology_libraries = {{ ontology_libraries }}\n",
    "disease_drug_libraries = {{ disease_drug_libraries }}\n",
    "cell_type_libraries = {{ cell_type_libraries }}\n",
    "misc_libraries = {{ misc_libraries }}\n",
    "legacy_libraries = {{ legacy_libraries }}\n",
    "crowd_libraries = {{ crowd_libraries }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_filename == '' or metadata_filename == '':\n",
    "    print(\"One or both user-uploaded files missing, use example GEO data.\")\n",
    "    data_filename = 'https://appyters.maayanlab.cloud/storage/RNAseq_Data_Metadata_Analysis/GSE159266_data_cleaned.txt'\n",
    "    metadata_filename = 'https://appyters.maayanlab.cloud/storage/RNAseq_Data_Metadata_Analysis/GSE159266_metadata_cleaned.txt'\n",
    "    print(data_filename + '\\n' + metadata_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Datasets\n",
    "Load RNA-seq gene read counts and associated sample metadata into dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataframe(file):\n",
    "    ''' Load a file by downloading it or reading it if already downloaded.\n",
    "    '''\n",
    "    ext = os.path.splitext(file)[1]\n",
    "    if ext in {'.tsv', '.txt'}:\n",
    "        df = pd.read_csv(file, sep='\\t', index_col=0)\n",
    "    elif ext == '.csv':\n",
    "        df = pd.read_csv(file, index_col=0)\n",
    "    else:\n",
    "        raise Exception('Unrecognized file format', ext)\n",
    "\n",
    "    # Fix any type coersion on identifiers\n",
    "    df.index = df.index.astype(str)\n",
    "    df.columns = df.columns.astype(str)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_index = \"symbol\"\n",
    "metadata_index = \"sample_id\"\n",
    "\n",
    "print(f\"Loading user-uploaded data...\")\n",
    "df_data = load_dataframe(data_filename).sort_index()\n",
    "df_metadata = load_dataframe(metadata_filename).sort_index()\n",
    "\n",
    "df_data.index.name = \"symbol\"\n",
    "df_metadata.index.name = \"sample_id\" \n",
    "\n",
    "print(\"Data loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. RNA-seq Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_legend(\"Table 1\", \"RNA-seq data\", \"The RNA-seq data contains a row per gene and a column per sample.\")\n",
    "display(df_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_legend(\"Table 2\",\"Metadata\", \"The column indices are sample metadata attributes, while the row indices are sample IDs corresponding to the columns of the RNA-seq data.\")\n",
    "display(df_metadata.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listed below are all the metadata categories. These categories will be used to cluster samples later in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_metadata.columns.values\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Normalize Data\n",
    "Given the highly variable nature of expression level between different genes, it is necessary to normalize the read counts before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe to display sample stats\n",
    "df_library_size = pd.DataFrame(\n",
    "    {\n",
    "        'n_reads': df_data[df_data > 0].count(),\n",
    "        'log_n_reads': np.log2(df_data[df_data > 0].count() + 1),\n",
    "        'n_expressed_genes': df_data.sum(),\n",
    "    }).sort_values('n_reads', ascending=False)\n",
    "\n",
    "df_library_size.index.name = \"sample_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_legend(\"Table 3\",\"Library size\", \"By default, the first five entries are shown. A gene read is counted toward n_reads for a single sample if its value is greater than 0.\")\n",
    "display(df_library_size.head()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, the overall library distribution is shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_library_size[\"n_reads\"]); plt.show()\n",
    "figure_legend(\"Figure 1\",\"Library size distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two versions of the dataset are normalized: one with just the `top_n_genes` most variable genes and one with all genes. The former will be used to compute clusters after dimensionality reduction, and the latter to compute the characteristic direction (up or down) of each gene in a cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy full dataset for computing characteristic directions later\n",
    "df_data_norm_all_genes = df_data.copy()\n",
    "\n",
    "# take top_n_genes most variable rows\n",
    "df_data_norm = filter_by_var(df_data,top_n = top_n_genes)\n",
    "\n",
    "# compute log normalization of matrix\n",
    "df_data_norm = log2_normalize(df_data_norm)\n",
    "df_data_norm_all_genes = log2_normalize(df_data_norm_all_genes)\n",
    "\n",
    "# convert to zscores\n",
    "df_data_norm = zscore_normalize(df_data_norm)\n",
    "df_data_norm_all_genes = zscore_normalize(df_data_norm_all_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_legend(\"Table 4\",\"Normalized RNA-seq data for most variable genes\", \"Counts are filtered for the most variable genes. The resulting dataset is log transformed and normalized, then converted to z-scores.\")\n",
    "display(df_data_norm.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the first gene distribution\n",
    "gene = df_data_norm.index.values[0]\n",
    "sns.distplot(df_data_norm.iloc[0, :]); plt.show()\n",
    "figure_legend(\"Figure 2\",f\"Sample gene expression distibution for {gene}\", f\"In this dataset, {gene} is the most variably expressed across all samples.\")\n",
    "\n",
    "# plot the last gene distribution\n",
    "gene = df_data_norm.index.values[-1]\n",
    "sns.distplot(df_data_norm.iloc[-1, :]); plt.show()\n",
    "figure_legend(\"Figure 3\",f\"Sample gene expression distibution for {gene}\", f\"In this dataset, {gene} is the least variably expressed across all samples among the most variably expressed genes.\")\n",
    "\n",
    "# plot a single RNA-seq sample distribution\n",
    "sns.distplot(df_data_norm.iloc[:, 0]); plt.show()\n",
    "figure_legend(\"Figure 4\",f\"RNA-seq profile distribution for sample {df_data_norm.columns[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reduce Data Dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data has been loaded and normalized, the most variable genes across the dataset can be identified and visualized with hierachical clustering and heatmaps. Dimensionality reduction facilitates the differentiation of the data in a more efficient manner by reducing the number of attributes to be considered. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Principle Component Analysis \n",
    "PCA is used first to reduce the dimensionality of the dataset, while still maintaining most of the variability. In PCA, a large number of dimensions -- in this case, the different sample metadata attributes -- can be reduced to a few new dimensions that capture the relevant information of the original attributes. \n",
    "\n",
    "First, all data values are scaled to (0, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_scaler = MinMaxScaler()\n",
    "df_data_norm[df_data_norm.columns.tolist()] = pca_scaler.fit_transform(df_data_norm[df_data_norm.columns.tolist()])\n",
    "df_data_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of manually setting the number of PCA components, the number of components is chosen automatically to maximize variance (> 95%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA \n",
    "data_norm_pca = PCA(\n",
    "  random_state=42,\n",
    "  n_components=0.95\n",
    ")\n",
    "\n",
    "data_norm_pca.fit(df_data_norm.values.T)\n",
    "\n",
    "df_data_norm_pca = pd.DataFrame(\n",
    "    data_norm_pca.transform(df_data_norm.values.T),\n",
    "    index=df_data_norm.T.index\n",
    ")\n",
    "\n",
    "df_data_norm_pca.columns = [\n",
    "    f'PCA-{c}' # ({r:.3f})'\n",
    "    for c, r in zip(df_data_norm_pca.columns, data_norm_pca.explained_variance_ratio_)\n",
    "]\n",
    "\n",
    "df_data_norm_pca.index.name = \"sample_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_legend(\"Table 5\",\"Principle components of RNA-seq data\", \"The top principle components are the projections of each datapoint onto the axes along which there is the most variation in the dataset.\")\n",
    "display(df_data_norm_pca.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data can now be plotted with the [React-Scatter-Board](https://github.com/MaayanLab/react-scatter-board) package. The points can be shaped and colored by various metadata categories, with the default being the first two metadata columns. They can also be individually searched by sample_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine metadata with RNA-seq data; note this will fail if sample_ids are\n",
    "# not exactly matched between both datasets\n",
    "pca_data = merge(\n",
    "        df_data_norm_pca[[\"PCA-0\", \"PCA-1\"]],\n",
    "        df_library_size,\n",
    "        df_metadata\n",
    "      )\n",
    "\n",
    "# name columns for plotting purposes\n",
    "pca_data = pca_data.rename(columns={'PCA-0': 'x', 'PCA-1': 'y'})\n",
    "pca_data['sample_id'] = pca_data.index\n",
    "\n",
    "# normalize dimensions to -10, 10\n",
    "pca_min, pca_max = -10, 10\n",
    "\n",
    "pca_x_min, pca_x_max = pca_data['x'].min(), pca_data['x'].max()\n",
    "pca_y_min, pca_y_max = pca_data['y'].min(), pca_data['y'].max()\n",
    "pca_data['x'] = (pca_data['x'] - pca_x_min) / (pca_x_max - pca_x_min) * (pca_max - pca_min) + pca_min\n",
    "pca_data['y'] = (pca_data['y'] - pca_y_min) / (pca_y_max - pca_y_min) * (pca_max - pca_min) + pca_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_scatter_data = pca_data.to_dict('records')\n",
    "\n",
    "color_def = df_metadata.columns.values[0]\n",
    "shape_def = df_metadata.columns.values[1]\n",
    "\n",
    "ScatterBoard(\n",
    "    id='pca-scatterboard',\n",
    "    is3d=False,\n",
    "    data=pca_scatter_data,\n",
    "    shapeKey=shape_def,\n",
    "    colorKey=color_def,\n",
    "    labelKeys=['sample_id'],\n",
    "    searchKeys=['sample_id'],\n",
    "    width=600,\n",
    "    height=600\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 5:** *First two PCA components of RNA-seq data.* Points are labeled by Sample ID and can be color- or shape-coded by any of the metadata categories using the dropdown menus. Points can also be isolated by searching by sample ID. Scroll to zoom, drag to move around."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Uniform Manifold Approximation and Projection\n",
    "\n",
    "The dimensionality of the dataset is further reduced by performing UMAP on the PCA components. Parameters such as `n_neighbors` and `min_dist` are set according to defaults used by the Seurat R Package for single cell genomics analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm_umap = UMAP(\n",
    "  random_state=42,\n",
    "  n_components=2,\n",
    "  n_neighbors=n_neighbors,\n",
    "  metric='cosine',\n",
    "  min_dist=min_cluster_dist,\n",
    ")\n",
    "\n",
    "# use top 10 components of PCA\n",
    "n_pca_components = min(10,df_data_norm_pca.shape[1])\n",
    "data_norm_umap.fit(df_data_norm_pca.iloc[:, :n_pca_components].values)\n",
    "\n",
    "# keep only first two UMAP components\n",
    "df_data_norm_umap = pd.DataFrame(\n",
    "  data_norm_umap.transform(df_data_norm_pca.iloc[:, :n_pca_components].values),\n",
    "  columns=['UMAP-0', 'UMAP-1'],\n",
    "  index=df_data_norm_pca.index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project data onto first two UMAP components for visualization\n",
    "umap_data = merge(\n",
    "        df_data_norm_umap[[\"UMAP-0\", \"UMAP-1\"]],\n",
    "        df_library_size,\n",
    "        df_metadata\n",
    "      )\n",
    "\n",
    "umap_data = umap_data.rename(columns={'UMAP-0': 'x', 'UMAP-1': 'y'})\n",
    "umap_data['sample_id'] = umap_data.index\n",
    "\n",
    "# normalize to (-10, 10)\n",
    "umap_min, umap_max = -10, 10\n",
    "\n",
    "umap_x_min, umap_x_max = umap_data['x'].min(), umap_data['x'].max()\n",
    "umap_y_min, umap_y_max = umap_data['y'].min(), umap_data['y'].max()\n",
    "umap_data['x'] = (umap_data['x'] - umap_x_min) / (umap_x_max - umap_x_min) * (umap_max - umap_min) + umap_min\n",
    "umap_data['y'] = (umap_data['y'] - umap_y_min) / (umap_y_max - umap_y_min) * (umap_max - umap_min) + umap_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_scatter_data = umap_data.to_dict('records')\n",
    "\n",
    "color_def = df_metadata.columns.values[0]\n",
    "shape_def = df_metadata.columns.values[1]\n",
    "\n",
    "ScatterBoard(\n",
    "    id='umap-scatterboard',\n",
    "    is3d=False,\n",
    "    data=umap_scatter_data,\n",
    "    shapeKey=shape_def,\n",
    "    colorKey=color_def,\n",
    "    labelKeys=['sample_id'],\n",
    "    searchKeys=['sample_id'],\n",
    "    width=600,\n",
    "    height=600\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 6:** *First two UMAP components of RNA-seq data.* The datapoints are again labeled by sample ID, and can be color- or shape-coded by any of the metadata categories using the dropdown menu. Points can also be isolated by searching by sample ID. Scroll to zoom, drag to move around."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first two UMAP components will be used from here on out. \n",
    "\n",
    "To compute sample clusters, the k-means method is used. The total number of clusters must be determined, by first testing a range for the number of total clusters, and then computing silhouette scores, which are a measure of how similar an entry is to its own cluster versus other clusters. The goal is to maximize both the similarity within a cluster and the differences between clusters, so the ideal number of clusters is that which produces the highest silhouette score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_scores = []\n",
    "\n",
    "# Set max clusters as a function of the sample size and the user-selected option\n",
    "max_clusters = math.ceil(df_data_norm_umap.shape[0]**0.5)\n",
    "max_clusters = int(math.ceil(max_clusters/2))\n",
    "\n",
    "cluster_range = range(2, (max(max_clusters, 3)))\n",
    "for n in cluster_range:\n",
    "    # apply k-means clustering for each possible k\n",
    "    X = df_data_norm_umap.values\n",
    "    clusterer = KMeans(n_clusters=n, random_state=42).fit(X)\n",
    "    y_pred = clusterer.predict(X)\n",
    "    \n",
    "    # The silhouette_score gives the average value for all the samples\n",
    "    silhouette_avg = silhouette_score(X, y_pred, metric='cosine')\n",
    "    \n",
    "    # Compute a weighted score that rewards higher numbers of clusters\n",
    "    # weighted_score = calc_weighted_score(silhouette_avg, n, max_clusters)\n",
    "\n",
    "    silhouette_scores.append({\n",
    "        \"N Clusters\": n,\n",
    "        \"Silhouette Score\": silhouette_avg\n",
    "        # \"Weighted Score\": weighted_score\n",
    "    })\n",
    "    \n",
    "    # Labeling the clusters\n",
    "    centers = clusterer.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use weighted scores\n",
    "points = {}\n",
    "threshold = 0.3\n",
    "    \n",
    "for s in silhouette_scores:\n",
    "    points[s[\"N Clusters\"]] = s[\"Silhouette Score\"]\n",
    "\n",
    "silhouette_scores = pd.DataFrame(silhouette_scores)\n",
    "\n",
    "figure_legend(\"Table 6\", \"Silhouette scores by number of clusters\", \"Values are sorted by the highest weighted score.\")\n",
    "display(silhouette_scores.head().sort_values([\"Silhouette Score\"], ascending=False).reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = int(silhouette_scores.sort_values([\"Silhouette Score\"], ascending=False)['N Clusters'].iloc[0])\n",
    "    \n",
    "print(f\"Ideal k: {k} clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the silhouette score as a function of # of clusters\n",
    "plt.plot(silhouette_scores['N Clusters'], silhouette_scores['Silhouette Score'], label='Silhouette Score', color='#7C88FB')\n",
    "plt.scatter(silhouette_scores['N Clusters'], silhouette_scores['Silhouette Score'], color='#7C88FB')\n",
    "plt.axvline(k, label = f\"Ideal k: {k} clusters\", color =\"#EF553B\", alpha=0.8,dashes=(3,3))\n",
    "plt.legend()\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.show()\n",
    "figure_legend(\"Figure 7\", \"Cluster size selection\", \"The dotted line indicates the value of the 'ideal' <i>k</i>. This value will be used in subsequent clustering.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the k-means dataframe using the ideal number of clusters\n",
    "km = KMeans(n_clusters=k, random_state=42)\n",
    "km_clusters = km.fit_predict(df_data_norm_umap.values)\n",
    "\n",
    "df_data_norm_km = pd.DataFrame({\n",
    "'Cluster': [\n",
    "    str(c)\n",
    "    for c in km_clusters\n",
    "]}, index=df_data_norm_umap.index)\n",
    "\n",
    "print(f'Computed {len(df_data_norm_km[\"Cluster\"].unique())} clusters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map each cluster to a color for later plots\n",
    "clusters = df_data_norm_km[\"Cluster\"].unique()\n",
    "plotly_colors = ['#636EFA', '#EF553B', '#00CC96', '#AB63FA', '#FFA15A', '#19D3F3', '#FF6692', '#B6E880', '#FF97FF', '#FECB52']\n",
    "cluster_colors = {}\n",
    "i = 0\n",
    "for c in clusters:\n",
    "    cluster_colors[c] = plotly_colors[i % len(plotly_colors)]\n",
    "    i += 1\n",
    "\n",
    "def cluster_heading(cluster):\n",
    "    display(HTML(f'''\n",
    "    <center>\n",
    "    <div style='background-color:{cluster_colors[cluster] + '98'};\n",
    "        width:100%;height:3rem;display:flex;align-items:center;\n",
    "        justify-content:center;color:white;font-size:2rem'>\n",
    "        <center>Cluster {cluster}</center>\n",
    "    </div>\n",
    "    </center>'''))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Differential Expression\n",
    "\n",
    "Next, the differential expression for each cluster is computed. The <a href=\"http://www.maayanlab.net/CD/\">Characteristic Direction method</a> is used for identifying differentially expressed genes among the different clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get differential expression for each cluster, using the dataset containing all genes\n",
    "diff_expr = {}\n",
    "for cluster, samples in df_data_norm_km.groupby('Cluster'):\n",
    "    diff_expr[f\"Cluster {cluster} CD\"] = characteristic_direction(\n",
    "        # expression outside of this cluster\n",
    "        df_data_norm_all_genes.loc[:, df_data_norm_all_genes.columns.difference(samples.index)],\n",
    "        # expression in this cluster\n",
    "        df_data_norm_all_genes.loc[:, samples.index],\n",
    "      )['CD-coefficient']\n",
    "\n",
    "df_diff_expr = pd.DataFrame(diff_expr)\n",
    "df_diff_expr = df_diff_expr.sort_values(by='Cluster 0 CD',ascending=True)\n",
    "df_diff_expr['Symbol'] = df_diff_expr.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_legend(\"Table 7\", \"Differential expression of genes by cluster\", \"By default, the top 5 most differentially expressed genes are shown, along with the corresponding characteristic directions for each cluster.\")\n",
    "display(df_diff_expr.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is performed for each metadata category to determine which categories most accurately predict cluster designations for each data point. ROC curves are also plotted for categories with the top two highest AUC scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR\n",
    "aucs = {}\n",
    "rocs = {}\n",
    "\n",
    "for cluster, samples in df_data_norm_km.groupby('Cluster'): \n",
    "    aucs[cluster] = {}\n",
    "    rocs[cluster] = []\n",
    "\n",
    "    for feature in features:\n",
    "        lr = LogisticRegression()\n",
    "        X = df_metadata.copy()\n",
    "        X = X[feature]\n",
    "        X = pd.merge(X, df_data_norm_km, left_index = True, right_index = True)\n",
    "\n",
    "        # drop NAs, and move on if dataset is empty\n",
    "        X.replace(\"not reported\", None)\n",
    "        X = X.dropna()\n",
    "        if (X.shape[0] == 0): continue\n",
    "\n",
    "        cluster_data = X[\"Cluster\"]\n",
    "        X = X.drop(columns= [\"Cluster\"])\n",
    "\n",
    "        # one-hot encode non numerical data\n",
    "        if (not isinstance(X[feature][0], (int, float, complex))):\n",
    "            X = pd.get_dummies(X[feature], prefix=feature)\n",
    "\n",
    "        y_true = (cluster_data == cluster)\n",
    "        \n",
    "        if (len(y_true.unique()) < 2): # if there is only one class in the dataset\n",
    "            print(f\"Not enough data to classify cluster {cluster} based on category {feature}\")\n",
    "            aucs[cluster][feature] = np.nan\n",
    "            continue \n",
    "                  \n",
    "        lr.fit(X, y_true)\n",
    "\n",
    "        y_score = lr.predict_proba(X)[:, 1]\n",
    "        auc_score = roc_auc_score(y_true, y_score)\n",
    "        aucs[cluster][feature] = auc_score\n",
    "        \n",
    "        # save the ROCs\n",
    "       \n",
    "        rocs[cluster].append({\"auc\":auc_score, \"lr\": lr, \"X\": X, \"y_true\":y_true, \"title\": f'Predictions of cluster {cluster} by category {feature}'})\n",
    "        \n",
    "df_cluster_aucs = pd.DataFrame(aucs)\n",
    "df_cluster_aucs.index.name=\"Category\"\n",
    "\n",
    "# sort features by avg AUC across all clusters\n",
    "df_cluster_aucs[\"avg\"] = [ np.mean(df_cluster_aucs.T[f]) for f in df_cluster_aucs.index.values ]\n",
    "df_cluster_aucs = df_cluster_aucs.sort_values(by = \"avg\", ascending=False)\n",
    "df_cluster_aucs = df_cluster_aucs.drop(columns = \"avg\")\n",
    "\n",
    "cols = [('Cluster', col) for col in df_cluster_aucs.columns ]\n",
    "df_cluster_aucs.columns = pd.MultiIndex.from_tuples(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_legend(\"Table 8\", \"Average AUC scores for top predictive metadata categories, by cluster\", \"Scores for the top 5 metadata categories for predicting clusters, as determined by the average AUC score across all clusters, are shown. Higher AUC scores correspond to better classifiers for distinguishing whether or not a datapoint belongs to a certain cluster.\")\n",
    "display(df_cluster_aucs.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot top 2 ROCs for each cluster\n",
    "plt.rc('font', size=16)\n",
    "\n",
    "for cluster, plots in rocs.items():\n",
    "    plots.sort(reverse=True, key=lambda x: x[\"auc\"])\n",
    "    cluster_heading(cluster)\n",
    "    \n",
    "    if len(plots) < 2:\n",
    "        best_rocs = plots\n",
    "    else:\n",
    "        best_rocs = plots[:2]\n",
    "\n",
    "    num_plots = len(best_rocs)\n",
    "    figure,axes = plt.subplots(int(math.ceil(num_plots / 2.)), 2, figsize=(15,(len(best_rocs)*3.5)))\n",
    "    \n",
    "    axes = axes.flatten()\n",
    "    for i in range(len(axes)):\n",
    "        if i >= len(best_rocs):\n",
    "            axes[i].remove()\n",
    "        else:\n",
    "            plot = best_rocs[i]\n",
    "            fig = plot_roc_curve(plot[\"lr\"], plot[\"X\"], plot[\"y_true\"], ax=axes[i])\n",
    "\n",
    "            axes[i].set_title('\\n'.join(wrap(plot[\"title\"], 40)))\n",
    "\n",
    "    figure.tight_layout(pad=2)\n",
    "    plt.show()\n",
    "    \n",
    "figure_legend(\"Figure 8\", \"ROCs for top cluster-predicting metadata categories\")\n",
    "\n",
    "plt.rcdefaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Identify Up- and Down-Regulated Genes\n",
    "Find the most up- and down-regulated genes for each cluster for visualization in heatmap, and for enrichment analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data\n",
    "df_clustered_umap = pd.merge(left=df_data_norm_km, left_on=\"sample_id\", right=df_data_norm_umap, right_on=\"sample_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top Genes for each cluster\n",
    "top_genes = {}\n",
    "all_top_genes = []\n",
    "heatmap_top_n = 100\n",
    "for cluster in df_clustered_umap['Cluster'].unique():\n",
    "    cd_col = f'Cluster {cluster} CD'\n",
    "    if cd_col in df_diff_expr.columns:\n",
    "        # top up genes\n",
    "        up_genes = df_diff_expr.loc[df_diff_expr[cd_col].sort_values(ascending=False).iloc[:top_n_genes_enrichment].index, 'Symbol'].values\n",
    "        # top down genes\n",
    "        dn_genes = df_diff_expr.loc[df_diff_expr[cd_col].sort_values(ascending=True).iloc[:top_n_genes_enrichment].index, 'Symbol'].values\n",
    "    else:\n",
    "        raise Exception('Cant find col for cluster')\n",
    "    all_top_genes.append(up_genes[:heatmap_top_n])\n",
    "    all_top_genes.append(dn_genes[:heatmap_top_n])\n",
    "    # save results\n",
    "    top_genes[cluster] = (up_genes, dn_genes)\n",
    "all_top_genes = [item for sublist in all_top_genes for item in sublist]  # flatten all genes to one list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data corresponding to only the top 100 up- and down-regulated genes for each cluster is selected for visualization in a heatmap, with log-transformation and normalization proceeding as before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_norm_heatmap_f = df_data.loc[all_top_genes, :]\n",
    "\n",
    "# compute log normalization of matrix\n",
    "df_data_norm_heatmap_f = log2_normalize(df_data_norm_heatmap_f)\n",
    "\n",
    "# convert to zscores\n",
    "df_data_norm_heatmap_f = zscore_normalize(df_data_norm_heatmap_f) \n",
    "\n",
    "# Plot heatmap\n",
    "cases = df_data_norm_heatmap_f.columns\n",
    "heatmap_cluster_colors = [ cluster_colors[x] for x in df_clustered_umap.loc[cases, :][\"Cluster\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(df_data_norm_heatmap_f,xticklabels=False,col_colors = heatmap_cluster_colors); plt.show()\n",
    "figure_legend(\"Figure 9\", \"Heatmap of most differentially expressed genes\", \"Color coding along the top edge indicates cluster designation of the corresponding sample.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  7. Enrichment Analysis with Enrichr\n",
    "\n",
    "Perform enrichment analysis for each cluster by querying the [Enrichr](https://maayanlab.cloud/Enrichr/) API. The background libraries are the default libraries from Enrichr. A link is provided to download the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enrichment analysis libraries\n",
    "enrichr_libraries = OrderedDict([\n",
    "    ('Diseases/Drugs', disease_drug_libraries), \n",
    "    ('Ontologies', ontology_libraries),\n",
    "    ('Cell Type', cell_type_libraries),\n",
    "    ('Pathways', pathway_libraries),\n",
    "    ('Transcription', transcription_libraries),\n",
    "    ('Legacy', legacy_libraries),\n",
    "    ('Crowd', crowd_libraries)\n",
    "])\n",
    "\n",
    "# handle no selected libraries\n",
    "all_empty = True\n",
    "for key, libs in enrichr_libraries.items():\n",
    "    if len(libs) > 0:\n",
    "        all_empty = False\n",
    "        break\n",
    "\n",
    "if all_empty:\n",
    "    enrichr_libraries = OrderedDict([\n",
    "        ('Diseases/Drugs', ['GWAS_Catalog_2019']),\n",
    "        ('Ontologies', ['GO_Biological_Process_2018', 'MGI_Mammalian_Phenotype_Level_4_2019']),\n",
    "        ('Pathways', ['KEGG_2019_Human', 'KEGG_2019_Mouse']),\n",
    "        ('Transcription', ['ENCODE_TF_ChIP-seq_2015'])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Util functions\n",
    "def enrichr_link_from_genes(genes, description='', enrichr_link='https://amp.pharm.mssm.edu/Enrichr'):\n",
    "    ''' Functional access to Enrichr API\n",
    "    '''\n",
    "    time.sleep(1)\n",
    "    resp = requests.post(enrichr_link + '/addList', files={\n",
    "    'list': (None, '\\n'.join(genes)),\n",
    "    'description': (None, description),\n",
    "    })\n",
    "    if resp.status_code != 200:\n",
    "        raise Exception('Enrichr failed with status {}: {}'.format(\n",
    "          resp.status_code,\n",
    "          resp.text,\n",
    "        ))\n",
    "    # wait a tinybit before returning link (backoff)\n",
    "    time.sleep(3)\n",
    "    result = resp.json()\n",
    "    return dict(result, link=enrichr_link + '/enrich?dataset=' + resp.json()['shortId'])\n",
    "\n",
    "def enrichr_get_top_results(userListId, bg, enrichr_link='https://amp.pharm.mssm.edu/Enrichr'):\n",
    "    time.sleep(1)\n",
    "    resp = requests.get(enrichr_link + '/enrich?userListId={}&backgroundType={}'.format(userListId, bg))\n",
    "    if resp.status_code != 200:\n",
    "        raise Exception('Enrichr failed with status {}: {}'.format(\n",
    "          resp.status_code,\n",
    "          resp.text,\n",
    "        ))\n",
    "    time.sleep(3)\n",
    "    return pd.DataFrame(resp.json()[bg], columns=['rank', 'term', 'pvalue', 'zscore', 'combinedscore', 'overlapping_genes', 'adjusted_pvalue', '', ''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Enrichr links for each cluster\n",
    "enrichr_links = {}\n",
    "\n",
    "for cluster, (up_genes, dn_genes) in top_genes.items():\n",
    "    up_link, dn_link = None, None\n",
    "    if up_genes.size:\n",
    "        try:\n",
    "            up_link = enrichr_link_from_genes(up_genes, f'cluster {cluster} up')\n",
    "        except:\n",
    "            print(f'Enrichr failed for cluster {cluster} up genes')\n",
    "    else:\n",
    "        print(f'cluster {cluster} up: empty')\n",
    "    if dn_genes.size:\n",
    "        try:\n",
    "            dn_link = enrichr_link_from_genes(dn_genes, f'cluster {cluster} down')\n",
    "        except:\n",
    "            print(f'Enrichr failed for cluster {cluster} down genes')\n",
    "    else:\n",
    "        print(f'cluster {cluster} down: empty')\n",
    "    enrichr_links[cluster] = (up_link, dn_link)\n",
    "\n",
    "# Grab top results for each cluster\n",
    "all_enrichr_results = []\n",
    "for cluster, (up_link, dn_link) in enrichr_links.items():\n",
    "    for link_type, link in [('up', up_link), ('down', dn_link)]:\n",
    "        if link is None:\n",
    "            continue\n",
    "        for category, libraries in enrichr_libraries.items():\n",
    "            for library in libraries:\n",
    "                try:\n",
    "                    results = enrichr_get_top_results(link['userListId'], library).sort_values('pvalue').iloc[:5]\n",
    "                    results['link'] = link['link']\n",
    "                    results['library'] = library\n",
    "                    results['category'] = category\n",
    "                    results['direction'] = link_type\n",
    "                    results['cluster'] = cluster\n",
    "                    all_enrichr_results.append(results)\n",
    "                except:\n",
    "                    print('{}: {} {} {} cluster {} failed, continuing'.format(link, library, category, link_type, cluster))\n",
    "\n",
    "df_enrichr_results = pd.concat(all_enrichr_results).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a dataframe with clickable enrichr links\n",
    "figure_legend(\"Table 10\",\"Enrichment analysis results from Enrichr\", \"Results are grouped by expression direction (up/down) and gene set library. Within groups, results are sorted by lowest p-value (highest rank) first.\")\n",
    "df_clickable = df_enrichr_results.copy()\n",
    "df_clickable['link'] = df_clickable[\"link\"].apply(make_clickable)\n",
    "table_html = df_clickable.to_html(escape=False)\n",
    "display(HTML(f'<div style=\"max-height: 250px; overflow-y: auto; margin-bottom: 25px;\">{table_html}</div>'))\n",
    "download_button(df_enrichr_results.to_csv(), 'Download Enrichr results', 'Enrichr results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7a. Barplots\n",
    "Horizontal barplots are used to display the top Enrichr results for each cluster, by library and characteristic expression direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make horizontal barplots to visualize top Enrichr results\n",
    "clusters = df_enrichr_results[\"cluster\"].unique()\n",
    "for cluster in clusters:\n",
    "    cluster_results = df_enrichr_results.loc[df_enrichr_results[\"cluster\"] == cluster, :]\n",
    "    libraries = cluster_results[\"library\"].unique()\n",
    "    num_rows = len(libraries)\n",
    "\n",
    "    count = 1 # keep track of which subplot we're on\n",
    "    fig = plt.figure(figsize=(15,5*num_rows))\n",
    "    \n",
    "    for library in cluster_results[\"library\"].unique():\n",
    "            library_results = cluster_results.loc[cluster_results[\"library\"] == library, :]\n",
    "            for direction in library_results[\"direction\"].unique():\n",
    "                plot_results = library_results.loc[cluster_results[\"direction\"] == direction, :]\n",
    "                plot_results = plot_results.sort_values(\"pvalue\",ascending=False)\n",
    "                labels = plot_results[\"term\"]\n",
    "                labels = [ '\\n'.join(wrap(l, 20)) for l in labels ]\n",
    "                values = plot_results[\"pvalue\"]\n",
    "                values = -np.log(values)\n",
    "                \n",
    "                # normalize values to map from 0-1 -> color, with opacity also based on normalized pvalue\n",
    "                cmap = plt.get_cmap('cool')\n",
    "                norm_values = [ 0.3 + (x - min(values))/(max(values) - min(values))*0.7 for x in values]\n",
    "                colors = [ [*cmap(val)[:3], 0.4  + 0.2*val] for val in norm_values]\n",
    "                \n",
    "                # plot result\n",
    "                ax = fig.add_subplot(num_rows,2,count)\n",
    "                ax.barh(labels,values,color = colors)\n",
    "                ax.set_title(f'{library}\\n{direction} genes')\n",
    "                ax.set_xlabel(' – log(pvalue)')\n",
    "                count += 1\n",
    "                \n",
    "    cluster_heading(cluster)\n",
    "    fig.tight_layout(pad=3, w_pad=2, h_pad=6)\n",
    "    plt.show()\n",
    "    display(HTML(\"<br><br>\"))\n",
    "    \n",
    "figure_legend(\"Figure 11\", \"Enrichment results by cluster\", \"Bar plots indicate the negative log of the p-value for the specified term. One plot is presented per cluster, per gene-set library, per expression direction (up/down).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7b. Running Sum Visualizations\n",
    "While the above barplots display the top enriched terms for each cluster in each direction, individual enriched terms can also be compared to the tissue data using a random walk [GSEA running sum visualization](https://github.com/MaayanLab/react-GSEA/tree/master).\n",
    "\n",
    "First, each of the four default background libraries from Enrichr can be queried and saved as a JSON object which maps terms to their complete genesets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "libresp = {}\n",
    "for lib in df_enrichr_results['library'].unique():\n",
    "    resp = requests.get('https://maayanlab.cloud/Enrichr/geneSetLibrary?mode=json&libraryName=' + lib)\n",
    "    if resp.status_code == 200:\n",
    "        libresp[lib] = resp.json()[lib]['terms']\n",
    "    else: \n",
    "        print(f\"Failed to access library {lib}, continuing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each cluster, the most enriched term for that cluster from each library can then be compared against the most up-regulated genes in the cluster. Below, GSEA plots display the overlap between the genes from each cluster and their most enriched genesets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through each cluster\n",
    "for cluster in clusters:\n",
    "    cluster_heading(cluster)\n",
    "\n",
    "    # iterate through each library for each cluster\n",
    "    for lib in libresp.keys():\n",
    "\n",
    "        # obtain the most enriched library term for the cluster in the up direction\n",
    "        up_df = df_enrichr_results[df_enrichr_results.direction.isin(['up'])\n",
    "                                    & df_enrichr_results.cluster.isin([cluster])\n",
    "                                    & df_enrichr_results.library.isin([lib])]\n",
    "        top_up_term = up_df[up_df['rank'] == 1]['term'].iloc[0]\n",
    "\n",
    "        # store the geneset for the most enriched term\n",
    "        top_up_set = list(libresp[lib][top_up_term])\n",
    "\n",
    "        display(HTML(f\"<div style='font-size:1.25rem;'><b>Comparison of up-regulated genes in Cluster {cluster} to most enriched {lib} term</b> </div>\"))\n",
    "        print(f\"Most enriched {lib} geneset for up-regulated genes:\", top_up_term)\n",
    "\n",
    "        # display the GSEA plot comparing the enriched genes and the top up-regulated cluster genes\n",
    "        display(ReactGSEA(\n",
    "            data=dataFromResult(\n",
    "                input_set=top_up_set,\n",
    "                ranked_entities=df_diff_expr['Cluster ' + cluster + ' CD'].sort_values(ascending=False).iloc[:math.ceil((df_diff_expr.shape[0]/2))].index.tolist()\n",
    "            )\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. L1000 Analysis\n",
    "\n",
    "If selected during user input, the most up- and down-regulated genes from each cluster, as identified from above, can be input into the [L1000FWD](https://amp.pharm.mssm.edu/L1000FWD/) API, which will then return the most similar and opposite gene expression signatures from the L1000 database. Links are provided to the interactive L1000FWD projections for each set of results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1000fwd_results_from_genes(up_genes, down_genes, description='', l100fwd_link='http://amp.pharm.mssm.edu/L1000FWD/'):\n",
    "    ''' Functional access to L1000FWD API\n",
    "    '''\n",
    "    import time\n",
    "    time.sleep(1)\n",
    "    response = requests.post(l100fwd_link + 'sig_search', json={\n",
    "    'up_genes': list(up_genes),\n",
    "    'down_genes': list(down_genes),\n",
    "    })\n",
    "    l1000fwd_results =  {}\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('L1000FWD failed with status {}: {}'.format(\n",
    "          response.status_code,\n",
    "          response.text,\n",
    "        ))\n",
    "    if 'KeyError' in response.text:\n",
    "        l1000fwd_results['result_url'] = None\n",
    "    else:\n",
    "        # Get ID and URL\n",
    "        result_id = response.json()['result_id']\n",
    "        l1000fwd_results['result_url'] = 'https://amp.pharm.mssm.edu/l1000fwd/vanilla/result/'+result_id\n",
    "        l1000fwd_results['result_id'] = result_id\n",
    "\n",
    "        # Get Top\n",
    "        l1000fwd_results['signatures'] = requests.get(l100fwd_link + 'result/topn/' + result_id).json()\n",
    "\n",
    "    # wait a tinybit before returning link (backoff)\n",
    "    time.sleep(1)\n",
    "    return l1000fwd_results\n",
    "\n",
    "def l1000fwd_sig_link(sig_id):\n",
    "    return 'https://amp.pharm.mssm.edu/dmoa/sig/' + sig_id\n",
    "\n",
    "def get_signature_by_id(sig_id):\n",
    "    response = requests.get(\"http://amp.pharm.mssm.edu/L1000FWD/sig/\" + sig_id)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('L1000FWD signature query  failed with status {}: {}'.format(\n",
    "          response.status_code,\n",
    "          response.text,\n",
    "        ))\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_l1000fwd_results(l1000fwd_results, plot_counter,cluster_id,nr_drugs=7, height=300):\n",
    "    # Check if results\n",
    "    if l1000fwd_results['result_url']:\n",
    "\n",
    "        # Display cluster title\n",
    "        display(HTML('<br><br>'))\n",
    "        cluster_heading(cluster)\n",
    "\n",
    "        # Display IFrae\n",
    "        display(HTML(f\"<a href='{l1000fwd_results['result_url']}' target='_blank'> View L1000FWD for cluster {cluster_id}</a>\"))\n",
    "    \n",
    "        # Display tables\n",
    "        for direction, signature_list in l1000fwd_results['signatures'].items():\n",
    "\n",
    "            # Fix dataframe\n",
    "            rename_dict = {'sig_id': 'Signature ID', 'pvals': 'P-value', 'qvals': 'FDR', 'zscores': 'Z-score', 'combined_scores': 'Combined Score'}\n",
    "            signature_dataframe = pd.DataFrame(signature_list)[list(rename_dict.keys())].rename(columns=rename_dict).sort_values('P-value').rename_axis('Rank')\n",
    "            signature_dataframe.index = [x + 1 for x in range(len(signature_dataframe.index))]\n",
    "            signature_csv = signature_dataframe.to_csv(sep=\",\")\n",
    "\n",
    "            # Display table\n",
    "            pd.set_option('max.colwidth', None)\n",
    "            signature_dataframe['Signature ID'] = [f'<a href={l1000fwd_sig_link(x)} target=\"_blank\">{x}</a>' for x in signature_dataframe['Signature ID']]\n",
    "            table_html = signature_dataframe.to_html(escape=False, classes='w-100')\n",
    "            display(HTML(f'<h3>{direction.title()} Signatures: </h3>'))\n",
    "            display(HTML(f'<style>.w-100{{width: 100% !important;}}</style><div style=\"max-height: 250px; overflow-y: auto; margin-bottom: 25px;\">{table_html}</div>'))\n",
    "\n",
    "            # Display download button\n",
    "            download_button(signature_csv, f'Download {direction.title()} Signatures', f'Cluster {cluster_id} L1000FWD {direction.title()} signatures.csv')\n",
    "        # Link\n",
    "        display(HTML('Full results available at: <a href=\"{result_url}\" target=\"_blank\">{result_url}</a>.'.format(**l1000fwd_results)))\n",
    "        \n",
    "    # Display error\n",
    "    else:\n",
    "        display(Markdown('### No results were found.\\n This is likely due to the fact that the gene identifiers were not recognized by L1000FWD. Please note that L1000FWD currently only supports HGNC gene symbols (https://www.genenames.org/). If your dataset uses other gene identifier systems, such as Ensembl IDs or Entrez IDs, consider converting them to HGNC. Automated gene identifier conversion is currently under development.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_l1000:\n",
    "    plot_counter = 0\n",
    "    all_l1000fwd_results = {}\n",
    "    figure_header(\"Figure 14\", \"Most similar and opposite L1000 signatures, by cluster\")\n",
    "    for cluster, (up_genes, dn_genes) in top_genes.items():\n",
    "        try:\n",
    "            results = l1000fwd_results_from_genes(up_genes,dn_genes)\n",
    "            all_l1000fwd_results[cluster] = results\n",
    "            display_l1000fwd_results(results,plot_counter,cluster)\n",
    "            plot_counter += 1\n",
    "        except:\n",
    "            print(f'L1000FWD API failed for cluster {cluster}, continuing')\n",
    "\n",
    "            \n",
    "    figure_legend(\"Figure 14\", \"Most similar and opposite L1000 signatures, by cluster\", \"Results are sorted by smallest p-value.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of disease state RNA-seq data, the reverse signatures provide a potential set of drugs that could perturb the cells/tissues towards a \"healthy\" direction. These may present novel treatments for patients whose samples belong to a certain cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_l1000:\n",
    "    df_drugs = pd.read_csv(\"https://amp.pharm.mssm.edu/l1000fwd/download/Drugs_metadata.csv\")\n",
    "\n",
    "    # Load top drug suggestions for each cluster based on the drugs used to produce the top five opposite signatures\n",
    "    drug_results = {}\n",
    "    for cluster, results in all_l1000fwd_results.items():\n",
    "        opposite_sigs = results[\"signatures\"][\"opposite\"][:5]\n",
    "        sig_ids = [sig[\"sig_id\"] for sig in opposite_sigs]\n",
    "        pert_ids = []\n",
    "        for sig_id in sig_ids:\n",
    "            try:\n",
    "                signature = get_signature_by_id(sig_id)\n",
    "                pert_ids.append(signature[\"pert_id\"])\n",
    "            except: \n",
    "                print(f'L1000FWD API failed for cluster {cluster}, sig_id {sig_id}, continuing')\n",
    "        \n",
    "        df_cluster_drugs = df_drugs[df_drugs[\"pert_id\"].isin(pert_ids)].copy()\n",
    "        df_cluster_drugs[\"cluster\"] = cluster\n",
    "        df_cluster_drugs = df_cluster_drugs[[\"cluster\", *list(filter(lambda x: x!=\"cluster\", df_cluster_drugs.columns))]]\n",
    "        drug_results[cluster] = df_cluster_drugs\n",
    "        \n",
    "    df_all_drugs = pd.concat(drug_results).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_l1000:\n",
    "    figure_header(\"Table 13\", \"Drugs used to produce most opposite signatures for each cluster\")\n",
    "    df_clickable = df_all_drugs.copy()\n",
    "    df_clickable['pert_url'] = df_clickable[\"pert_url\"].apply(make_clickable)\n",
    "    table_html = df_clickable.to_html(escape=False)\n",
    "    display(HTML(f'<div style=\"max-height: 250px; overflow-y: auto; margin-bottom: 25px;\">{table_html}</div>'))\n",
    "    download_button(df_all_drugs.to_csv(), 'Download L1000FWD drug results', 'L1000FWD drugs.csv')\n",
    "    figure_legend(\"Table 13\", \"Drugs used to produce most opposite signatures for each cluster\", \"Each entry is a drug/chemical used for perturbation in the L1000 experiments that resulted in a gene-expression signature most opposite to that of the specified cluster.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('gtex': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a5c32a0f6a752fb2bcd8102aa6c1779b0b17d87af3834a21c5e66dd831f456f7"
    }
   },
   "name": "Python 3.7.9 64-bit ('gtex': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
