{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%appyter init\n",
    "from appyter import magic\n",
    "magic.init(lambda _=globals: _())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputing Knowledge about Gene and Protein Function with Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "## Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "## Machine Learning\n",
    "import sklearn as sk\n",
    "from sklearn import (\n",
    "    calibration, decomposition, ensemble, feature_selection,\n",
    "    linear_model, manifold, metrics, model_selection, multioutput,\n",
    "    pipeline, preprocessing, svm, tree,\n",
    ")\n",
    "## Plotting\n",
    "from matplotlib import pyplot as plt\n",
    "## Harmonizome API\n",
    "from harmonizome import Harmonizome\n",
    "## Utility\n",
    "import re\n",
    "import json\n",
    "from functools import reduce\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "\n",
    "def try_json_loads(s):\n",
    "    try:\n",
    "        return json.loads(s)\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "## Create custom \"randfloat\" that behaves like randint but for floats\n",
    "from scipy.stats import uniform, randint\n",
    "def randfloat(start, end):\n",
    "    ''' Utility function for generating a float uniform distribution '''\n",
    "    return uniform(start, end - start)\n",
    "\n",
    "# reproducable random seed\n",
    "rng = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs\n",
    "\n",
    "Given a target attribute of interest, we will use machine learning to predict genes that are strongly correlated with that target. Using the Harmonizome data query API, we download the dataset containing the target attribute as well as a number of well-populated Omics datasets for more genes and features and build a large sparse dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select Omics datasets are downloaded and joined on the Gene producing a large association matrix. Only association is preserved in order to create a binary classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter hide_code\n",
    "{% do SectionField(\n",
    "    name='DATASETS',\n",
    "    title='ATTRIBUTE AND PREDICTION CLASS DATASET SELECTION',\n",
    "    subtitle='Select the datasets to use for learning and classification.',\n",
    ") %}\n",
    "{% set attribute_datasets = MultiChoiceField(\n",
    "    name='attribute_datasets',\n",
    "    label='Attribute Selection (place cursor inside the box to add more datasets)',\n",
    "    hint='Databases to use for prediction',\n",
    "    description='The selected datasets will be concatenated and used to train the model.',\n",
    "    default=[\n",
    "        'CCLE Cell Line Gene Expression Profiles',\n",
    "        'ENCODE Transcription Factor Targets',\n",
    "    ],\n",
    "    choices=[\n",
    "        'CCLE Cell Line Gene Expression Profiles',\n",
    "        'ENCODE Transcription Factor Targets',\n",
    "        'Allen Brain Atlas Adult Human Brain Tissue Gene Expression Profiles',\n",
    "        'CHEA Transcription Factor Targets',\n",
    "        'BioGPS Cell Line Gene Expression Profiles',\n",
    "        'GTEx Tissue Gene Expression Profiles',\n",
    "    ],\n",
    "    section='DATASETS',\n",
    ") %}\n",
    "{% set target = TabField(\n",
    "    name='target',\n",
    "    label='Target Selection',\n",
    "    default='Class',\n",
    "    choices={\n",
    "        'Class': [StringField(\n",
    "            name='target_class',\n",
    "            label='Class',\n",
    "            default='cancer (DOID:162 from DISEASES Text-mining Gene-Disease Assocation Evidence Scores)',\n",
    "        )],\n",
    "        'Gene': [StringField(\n",
    "            name='target_gene',\n",
    "            label='Gene',\n",
    "            default='STAT3 (DOID:162 from DISEASES Text-mining Gene-Disease Assocation Evidence Scores)',\n",
    "        )],\n",
    "    },\n",
    "    section='DATASETS',\n",
    ") %}\n",
    "{% set target_label, target_group, target_dataset = target.value[0].value|re_match('^(.+) \\\\((.+) from (.+)\\\\)$') %}\n",
    "{% set target_name = (target_label + ' ' + target_group).strip() %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "attribute_datasets = {{ attribute_datasets }}\n",
    "df_attributes = list(Harmonizome.download_df(\n",
    "    [dataset\n",
    "     for dataset in attribute_datasets],\n",
    "    ['gene_attribute_matrix.txt.gz'],\n",
    "))\n",
    "for name, df in zip(attribute_datasets, df_attributes):\n",
    "    df.index.name = json.loads(df.index.name)[0]\n",
    "    df.index = df.index.map(lambda s: json.loads(s)[0])\n",
    "    df.columns = df.columns.map(lambda s: ' '.join(ss for ss in try_json_loads(s) if ss != 'na'))\n",
    "    print('%s shape:' % (name), df.shape)\n",
    "    display(df.head())\n",
    "\n",
    "# Assemble all attribute datasets\n",
    "if len(df_attributes) > 1:\n",
    "    # Obtain merged dataframe with omics and target data\n",
    "    df = reduce(\n",
    "        lambda a, b: pd.merge( # Merge two dataframes item by item\n",
    "            a, # left\n",
    "            b, # right\n",
    "            # Items with the same left and right index are merged\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            how='outer', # Keep mis-matched index\n",
    "        ),\n",
    "        df_attributes,\n",
    "    )\n",
    "else:\n",
    "    df = df_attributes[0]\n",
    "\n",
    "X = df.applymap(lambda f: 1 if f!=0 else 0)\n",
    "print('Total Shape:', X.shape)\n",
    "display(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "We download the dataset containtaining the target ({{ target_name }}), {{ target_dataset }}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "target_datasets = ['{{ target_dataset }}']\n",
    "\n",
    "# Download attribute datasets from Harmonizome\n",
    "df_targets = list(Harmonizome.download_df(\n",
    "    [dataset\n",
    "     for dataset in target_datasets],\n",
    "    ['gene_attribute_matrix.txt.gz'],\n",
    "))\n",
    "\n",
    "for name, df in zip(target_datasets, df_targets):\n",
    "    df.index.name = json.loads(df.index.name)[0]\n",
    "    df.index = df.index.map(lambda s: json.loads(s)[0])\n",
    "    df.columns = df.columns.map(lambda s: ' '.join(ss for ss in try_json_loads(s) if ss != 'na'))\n",
    "    print('%s shape:' % (name), df.shape)\n",
    "    display(df.head())\n",
    "\n",
    "# Assemble all target datasets\n",
    "if len(df_targets) > 1:\n",
    "    # Obtain merged dataframe with omics and target data\n",
    "    df = reduce(\n",
    "        lambda a, b: pd.merge( # Merge two dataframes item by item\n",
    "            a, # left\n",
    "            b, # right\n",
    "            # Items with the same left and right index are merged\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            how='outer', # Keep mis-matched index\n",
    "        ),\n",
    "        df_targets,\n",
    "    )\n",
    "else:\n",
    "    df = df_targets[0]\n",
    "\n",
    "Y = df.applymap(lambda f: 1 if f!=0 else 0)\n",
    "print('Total Shape:', Y.shape)\n",
    "display(Y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "{% if target.raw_value == 'Gene' %}\n",
    "For each class in the dataset, we build a list (1 if gene is associated, otherwise 0) building a matrix of gene lists to predict. We remove irrelevant classes (less than 10 available associations).\n",
    "{% elif target.raw_value == 'Class' %}\n",
    "For the target class, we build a list (1 if gene is associated, otherwise 0)\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "# {{ target.raw_value }}\n",
    "{% if target.raw_value == 'Gene' %}\n",
    "y = pd.DataFrame(index=X.index, columns=Y.columns)\n",
    "for yy in Y.columns:\n",
    "    y.loc[:, yy] = np.in1d(X.index, Y[Y[yy] != 0].index).astype(np.int8)\n",
    "y = y.loc[:, y.sum() > 10]\n",
    "\n",
    "print('Known Targets: %d (%0.3f %%)' % (y.sum().sum(), 100*y.sum().sum()/np.product(y.shape)))\n",
    "{% elif target.raw_value == 'Class' %}\n",
    "y = np.in1d(X.index, Y[Y['{{ target_name }}'] == 1].index).astype(np.int8)\n",
    "\n",
    "print('Known Targets: %d (%0.3f %%)' % (y.sum(), 100*y.sum()/len(y)))\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We produce a target array containing 1 if the gene is associated and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "We download the dataset containing the target ({{ target_name }}), {{ target_dataset }}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Output data shapes\n",
    "print('Input shape:', X.shape)\n",
    "print('Target shape:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter hide_code\n",
    "{% do SectionField(\n",
    "    name='SETTINGS',\n",
    "    title='SETTINGS',\n",
    "    subtitle='From here you can select the various available Machine Learning algorithms, their unique settings, and the methods to use to evaluate the classifier.',\n",
    ") %}\n",
    "{% set dimensionality_reduction = ChoiceField(\n",
    "    name='dimensionality_reduction',\n",
    "    label='Dimensionality Reduction Algorithm',\n",
    "    description='A dimensionality reduction algorithm should be selected to improve the quality of the classifier.',\n",
    "    default='PCA',\n",
    "    choices={\n",
    "        'PCA': 'sk.decomposition.PCA(n_components=64)',\n",
    "        'TruncatedSVD': 'sk.decomposition.TruncatedSVD(n_components=64)',\n",
    "        'IncrementalPCA': 'sk.decomposition.IncrementalPCA(n_components=64)',\n",
    "        'ICA': 'sk.decomposition.FastICA(n_components=64)',\n",
    "        'SparsePCA': 'sk.decomposition.SparsePCA(n_components=64)',\n",
    "    },\n",
    "    section='SETTINGS'\n",
    ") %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "## Dimensionality Reduction\n",
    "\n",
    "We reduce the dimensionality of our omics feature space with {{ dimensionality_reduction }}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "{% if target.raw_value == 'Class' %}\n",
    "clf_dimensionality_reduction = {{ dimensionality_reduction }}\n",
    "X_reduced = clf_dimensionality_reduction.fit_transform(X.values)\n",
    "{% if dimensionality_reduction == 'PCA' %}\n",
    "print('Explained variance:', np.sum(clf_dimensionality_reduction.explained_variance_))\n",
    "{% endif %}\n",
    "{% if dimensionality_reduction == 'TSNE' %}\n",
    "# Perform TSNE for low dimensional visualization\n",
    "tsne = sk.manifold.TSNE(n_components=2, random_state=rng)\n",
    "X_transformed = tsne.fit_transform(X_reduced, y)\n",
    "plt.scatter(\n",
    "   X_transformed_tsne[:, 0],\n",
    "   X_transformed_tsne[:, 1],\n",
    "   c=y,\n",
    ")\n",
    "{% else %}\n",
    "plt.title('Low dimension representation')\n",
    "plt.scatter(\n",
    "    X_reduced[:, 0],\n",
    "    X_reduced[:, 1],\n",
    "    c=y,\n",
    ")\n",
    "plt.show()\n",
    "{% endif %}\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_hide\n",
    "{% set feature_selection = ChoiceField(\n",
    "    name='feature_selection',\n",
    "    label='Machine Learning Feature Selection',\n",
    "    default='None',\n",
    "    choices={\n",
    "        'None': 'None',\n",
    "        'SelectFromLinearSVC': 'sk.feature_selection.SelectFromModel(sk.svm.LinearSVC(loss=\"squared_hinge\", penalty=\"l1\", dual=False))',\n",
    "        'SelectFromExtraTrees': 'sk.feature_selection.SelectFromModel(sk.tree.ExtraTreesClassifier())',\n",
    "        'SelectKBest': 'sk.feature_selection.SelectKBest(\"f_classif\")',\n",
    "        'SelectKBestChi2': 'sk.feature_selection.SelectKBest(\"chi2\")',\n",
    "        'SelectKBestMultiInfo': 'sk.feature_selection.SelectKBest(\"mutual_info_classif\")',\n",
    "    },\n",
    "    section='SETTINGS',\n",
    ") %}\n",
    "{% set cv_algorithm = ChoiceField(\n",
    "    name='cv_algorithm',\n",
    "    label='Cross Validation Algorithm',\n",
    "    default='StratifiedKFold',\n",
    "    value='KFold',\n",
    "    choices={\n",
    "        'KFold': 'sk.model_selection.KFold',\n",
    "        'GroupKFold': 'sk.model_selection.GroupKFold',\n",
    "        'RepeatedKFold': 'sk.model_selection.RepeatedKFold',\n",
    "        'StratifiedKFold': 'sk.model_selection.StratifiedKFold',\n",
    "        'RepeatedStratifiedKFold': 'sk.model_selection.RepeatedStratifiedKFold',\n",
    "    },\n",
    "    section='SETTINGS',\n",
    ") %}\n",
    "{% set algorithm = ChoiceField(\n",
    "    name='algorithm',\n",
    "    label='Machine Learning Algorithm',\n",
    "    default='RandomForestClassifier',\n",
    "    description='A machine learning algorithm should be selected to construct the predictive model.',\n",
    "    choices={\n",
    "        'GradientBoostingClassifier': 'sk.ensemble.GradientBoostingClassifier()',\n",
    "        'RandomForestClassifier': 'sk.ensemble.RandomForestClassifier()',\n",
    "        'AdaBoostClassifier': 'sk.ensemble.AdaBoostClassifier()',\n",
    "        'ExtraTreesClassifier': 'sk.tree.ExtraTreesClassifier()',\n",
    "        'DecisionTreeClassifier': 'sk.tree.DecisionTreeClassifier()',\n",
    "        'KNeighborsClassifier': 'sk.neighbors.KNeighborsClassifier()',\n",
    "        'RadiusNeighborsClassifier': 'sk.neighbors.RadiusNeighborsClassifier()',\n",
    "        'MLPClassifier': 'sk.neural_network.MLPClassifier()',\n",
    "        'OneClassSVM': 'sk.svm.OneClassSVM()',\n",
    "    },\n",
    "    section='SETTINGS',\n",
    ") %}\n",
    "{% set calibrated = BoolField(\n",
    "    name='calibrated',\n",
    "    label='Calibrate algorithm predictions',\n",
    "    description='Calibrate the prediction probabilities eliminating model-imparted bias.',\n",
    "    default=True,\n",
    "    section='SETTINGS',\n",
    ") %}\n",
    "{% set hyper_param_search = ChoiceField(\n",
    "    name='hyper_param_search',\n",
    "    label='Hyper Parameter Search Type',\n",
    "    default='None',\n",
    "    description='Hyper parameter searching is used to automatically select the best parameters (using the primary metric as the criteria).',\n",
    "    choices={\n",
    "        'None': 'None',\n",
    "        'RandomizedSearchCV': 'sk.model_selection.RandomizedSearchCV',\n",
    "        'GridSearchCV': 'sk.model_selection.GridSearchCV',\n",
    "    },\n",
    "    section='SETTINGS',\n",
    ") %}\n",
    "{% set cross_validation_n_folds = IntField(\n",
    "    name='cross_validation_n_folds',\n",
    "    label='Cross-Validated Folds',\n",
    "    description='Cross validation is employed as a strategy to train the model on data that the model has not seen before, more folds will ensure that the model is generalizing well.',\n",
    "    default=3,\n",
    "    min=2,\n",
    "    max=10,\n",
    "    section='SETTINGS',\n",
    ") %}\n",
    "{% set primary_metric = ChoiceField(\n",
    "    name='primary_metric',\n",
    "    label='Primary Evaluation Metric',\n",
    "    default='roc_auc',\n",
    "    description='The primary evaluation metric is used for deciding how we assess the performance of our model.',\n",
    "    choices=[\n",
    "        'explained_variance',\n",
    "        'r2',\n",
    "        'neg_median_absolute_error',\n",
    "        'neg_mean_absolute_error',\n",
    "        'neg_mean_squared_error',\n",
    "        'neg_mean_squared_log_error',\n",
    "        'median_absolute_error',\n",
    "        'mean_absolute_error',\n",
    "        'mean_squared_error',\n",
    "        'accuracy',\n",
    "        'roc_auc',\n",
    "        'average_precision',\n",
    "        'log_loss',\n",
    "        'neg_log_loss',\n",
    "        'adjusted_rand_score',\n",
    "        'homogeneity_score',\n",
    "        'completeness_score',\n",
    "        'v_measure_score',\n",
    "        'mutual_info_score',\n",
    "        'adjusted_mutual_info_score',\n",
    "        'normalized_mutual_info_score',\n",
    "        'fowlkes_mallows_score',\n",
    "        'precision',\n",
    "        'precision_macro',\n",
    "        'precision_micro',\n",
    "        'precision_samples',\n",
    "        'precision_weighted',\n",
    "        'recall',\n",
    "        'recall_macro',\n",
    "        'recall_micro',\n",
    "        'recall_samples',\n",
    "        'recall_weighted',\n",
    "        'f1',\n",
    "        'f1_macro',\n",
    "        'f1_micro',\n",
    "        'f1_samples',\n",
    "        'f1_weighted'\n",
    "    ],\n",
    "    section='SETTINGS',\n",
    ") %}\n",
    "{% set evaluation_metrics = MultiChoiceField(\n",
    "    name='evaluation_metrics',\n",
    "    label='Evaluation Metrics',\n",
    "    default=[],\n",
    "    description='Additional evaluation metrics can be specified, these metrics will also be reported for all models trained.',\n",
    "    value=['recall', 'f1'],\n",
    "    choices=[\n",
    "        'explained_variance',\n",
    "        'r2',\n",
    "        'neg_median_absolute_error',\n",
    "        'neg_mean_absolute_error',\n",
    "        'neg_mean_squared_error',\n",
    "        'neg_mean_squared_log_error',\n",
    "        'median_absolute_error',\n",
    "        'mean_absolute_error',\n",
    "        'mean_squared_error',\n",
    "        'accuracy',\n",
    "        'roc_auc',\n",
    "        'average_precision',\n",
    "        'log_loss',\n",
    "        'neg_log_loss',\n",
    "        'adjusted_rand_score',\n",
    "        'homogeneity_score',\n",
    "        'completeness_score',\n",
    "        'v_measure_score',\n",
    "        'mutual_info_score',\n",
    "        'adjusted_mutual_info_score',\n",
    "        'normalized_mutual_info_score',\n",
    "        'fowlkes_mallows_score',\n",
    "        'precision',\n",
    "        'precision_macro',\n",
    "        'precision_micro',\n",
    "        'precision_samples',\n",
    "        'precision_weighted',\n",
    "        'recall',\n",
    "        'recall_macro',\n",
    "        'recall_micro',\n",
    "        'recall_samples',\n",
    "        'recall_weighted',\n",
    "        'f1',\n",
    "        'f1_macro',\n",
    "        'f1_micro',\n",
    "        'f1_samples',\n",
    "        'f1_weighted'\n",
    "    ],\n",
    "    section='SETTINGS',\n",
    ") %}\n",
    "{% set all_metrics = [primary_metric.value] + evaluation_metrics.value %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "## Machine Learning\n",
    "\n",
    "We apply a {% if hyper_param_search.raw_value != 'None' %}{{ hyper_param_search.raw_value }} search for the hyper parameters\n",
    "of a {% endif %}sklearn pipeline with a dimensionality reduction step of {{ dimensionality_reduction.raw_value }}\n",
    "{% if feature_selection.raw_value != 'None' %}and a feature selection step of {{ feature_selection.raw_value }}\n",
    "{% endif %} and a{% if calibrated %} calibrated{%endif %} {{ algorithm.raw_value }} classifier\n",
    "using {{ cross_validation_n_folds.raw_value }}-fold repeated\n",
    "stratified cross-validation, optimizing {{ primary_metric.raw_value }}\n",
    "{% if evaluation_metrics.raw_value %} and computing {{ ', '.join(evaluation_metrics.raw_value) }}{% endif %}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "{% if algorithm.raw_value == 'GradientBoostingClassifier' %}\n",
    "## Early stopping function\n",
    "def early_stopping(n_rounds, tol=0.001):\n",
    "    def early_stopping_func(i, self, local):\n",
    "        rounds = getattr(self, '__rounds', 0)\n",
    "        last = getattr(self, '__last', None)\n",
    "        current = self.train_score_[i]\n",
    "        if last and current and abs(current - last) < tol:\n",
    "            rounds += 1\n",
    "            if rounds > n_rounds:\n",
    "                return True\n",
    "        else:\n",
    "            rounds = 0\n",
    "        setattr(self, '__last', current)\n",
    "        setattr(self, '__rounds', rounds)\n",
    "        return False\n",
    "    return early_stopping_func\n",
    "{% endif %}\n",
    "\n",
    "{#\n",
    "param_grid = {\n",
    "    'reduce_dim__n_components': randint(2, 1024),\n",
    "{% if algorithm.raw_value == 'GradientBoostingClassifier' %}\n",
    "    'clf__loss': ['deviance', 'exponential'],\n",
    "    'clf__learning_rate': randfloat(0.001, 1.),\n",
    "    'clf__subsample': randfloat(0.01, 1.),\n",
    "{% elif algorithm.raw_value == 'RandomForestClassifier' %}\n",
    "    'clf__oob_score': [True],\n",
    "    'clf__criterion': ['gini', 'entropy'],\n",
    "{% endif %}\n",
    "    'clf__n_estimators': randint(10, 200),\n",
    "    'clf__max_depth': randint(20, 50),\n",
    "    'clf__max_features': ['sqrt', 'log2', None],\n",
    "    'clf__min_impurity_decrease': randfloat(0., 0.2),\n",
    "    'clf__min_weight_fraction_leaf': randfloat(0., 0.5),\n",
    "}\n",
    "\n",
    "fit_params = {\n",
    "{% if algorithm.raw_value == 'GradientBoostingClassifier' %}\n",
    "    'clf__monitor': early_stopping(5),\n",
    "{% endif %}\n",
    "}\n",
    "#}\n",
    "    \n",
    "cv = {{ cv_algorithm }}(\n",
    "    n_splits={{ cross_validation_n_folds }},\n",
    "    shuffle=True,\n",
    "    random_state=rng,\n",
    ")\n",
    "\n",
    "model =\n",
    "{%- if hyper_param_search.raw_value != 'None' %} {{ hyper_param_search }}({% endif -%}\n",
    "{%- if target.raw_value == 'Gene' %} multioutput.MultiOutputClassifier({% endif -%}\n",
    "    {%- if calibrated %} sk.calibration.CalibratedClassifierCV({% endif -%}\n",
    "        sk.pipeline.Pipeline([\n",
    "            ('reduce_dim', {{ dimensionality_reduction }}),\n",
    "            {%- if feature_selection.raw_value != 'None' %}('feature_selection', {{ feature_selection }}),{% endif %}\n",
    "            ('clf', {{ algorithm }}),\n",
    "        ]),\n",
    "    cv=cv,\n",
    "{% if calibrated %}){% endif -%}{% if target.raw_value == 'Gene' %}){% endif %}{%- if hyper_param_search.raw_value != 'None' %}){% endif %}\n",
    "\n",
    "# Scoring parameters\n",
    "primary_metric = '{{ primary_metric }}'\n",
    "evaluation_metrics = {{ evaluation_metrics }}\n",
    "scoring_params = {k: scorer\n",
    "                  for k, scorer in metrics.SCORERS.items()\n",
    "                  if k == primary_metric or k in evaluation_metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "{% if hyper_param_search.raw_value == 'None' %}\n",
    "df_results = pd.DataFrame()\n",
    "for fold, (train, test) in enumerate(cv.split(X.values, y)):\n",
    "    model.fit(X.values[train], y[train])\n",
    "    {% for metric in all_metrics %}\n",
    "    {% if target.raw_value == 'Class' %}\n",
    "    df_results.loc[fold, '{{ metric }}'] = scoring_params['{{ metric }}'](model, X.values[test], y[test])\n",
    "    {% elif target.raw_value == 'Gene' %}\n",
    "    df_results.loc[fold, '{{ metric }}', y.columns] = scoring_params['{{ metric }}'](model, X.values[test], y[test])\n",
    "    {% endif %}\n",
    "    {% endfor %}\n",
    "display(df_results.agg(['mean', 'std']))\n",
    "{% else %}\n",
    "model.fit(X, y)\n",
    "df_results = model.cv_results_\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This visualization shows illustrates the cross-validated performance of the model. Low fold variance and high AUC is desired in a well-generalized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "{% if 'roc_auc' in all_metrics %}\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "for fold, (train, test) in enumerate(cv.split(X.values, y)):\n",
    "    model.fit(X.values[train], y[train])\n",
    "    y_proba = model.predict_proba(X.values[test]) # Probability prediction will be True\n",
    "    fpr, tpr, _ = sk.metrics.roc_curve(y[test], y_proba[:, 1])\n",
    "    tprs.append(sp.interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = sk.metrics.auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    ax.plot(fpr, tpr, alpha=0.4, label='ROC Fold %d (AUC=%0.3f)' % (fold, roc_auc))\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = sk.metrics.auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "ax.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2)\n",
    "\n",
    "ax.plot([0,1],[0,1],'--', label='Luck')\n",
    "ax.legend()\n",
    "\n",
    "z = (mean_auc - 0.5)/std_auc\n",
    "cl = sp.stats.norm.cdf(z) * 100\n",
    "ci = sp.stats.norm.interval(0.95, loc=mean_auc, scale=std_auc)\n",
    "print('Confidence interval (95%)', ci)\n",
    "print(\"We are %0.3f %% confident the model's results are not just chance.\" % (cl))\n",
    "if cl > 95:\n",
    "    print('This is statistically significant. These results can be trusted.')\n",
    "else:\n",
    "    print('This is not statistically significant. These results should not be trusted.')\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will take a long time as we are evaluating n_iter different models n_splits different times each computing all the metrics on `product(X.shape)` data points--not to mention the size of each model dictated by the range of parameters specified in the params dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y, model.predict(X.values))\n",
    "display(cm)\n",
    "print('\\n',\n",
    "    'True labels predicted to be true:', cm[0,0], '\\n',\n",
    "    'True labels predicted to be false:', cm[0,1], '\\n',\n",
    "    'False labels predicted to be true:', cm[1,0], '\\n',\n",
    "    'False labels predicted to be false:', cm[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain prediction results\n",
    "y_probas = model.predict_proba(X)[:, 1]\n",
    "results = pd.DataFrame(np.array([\n",
    "    y,\n",
    "    y_probas > 0.5,\n",
    "    y_probas,\n",
    "]).T, columns=[\n",
    "    'Known',\n",
    "    'Predicted',\n",
    "    'Prediction Probability',\n",
    "], index=X.index)\n",
    "results[((results['Known'] != results['Predicted']) & (results['Prediction Probability'] > 0.5))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python38164bit1a447d370127449d809db2bf16ffa68f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}