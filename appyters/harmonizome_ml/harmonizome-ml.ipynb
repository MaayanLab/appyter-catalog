{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%appyter init\n",
    "from appyter import magic\n",
    "magic.init(lambda _=globals: _())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputing Knowledge about Gene and Protein Function with Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "## Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "## Machine Learning\n",
    "import sklearn as sk\n",
    "from sklearn import (\n",
    "    calibration, decomposition, ensemble, feature_selection,\n",
    "    linear_model, manifold, metrics, model_selection, multioutput,\n",
    "    pipeline, preprocessing, svm, tree, neural_network,\n",
    ")\n",
    "## Plotting\n",
    "import plotly.express as px\n",
    "from matplotlib import pyplot as plt\n",
    "## Harmonizome API\n",
    "from harmonizome import Harmonizome\n",
    "## Utility\n",
    "import re\n",
    "import json\n",
    "from functools import reduce\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "\n",
    "def try_json_loads(s):\n",
    "    try:\n",
    "        return json.loads(s)\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "## Create custom \"randfloat\" that behaves like randint but for floats\n",
    "from scipy.stats import uniform, randint\n",
    "def randfloat(start, end):\n",
    "    ''' Utility function for generating a float uniform distribution '''\n",
    "    return uniform(start, end - start)\n",
    "\n",
    "# reproducable random seed\n",
    "rng = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs\n",
    "\n",
    "Given a target attribute of interest, we will use machine learning to predict genes that are strongly correlated with that target. Using the Harmonizome data query API, we download the dataset containing the target attribute as well as a number of well-populated Omics datasets for more genes and features and build a large sparse dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select Omics datasets are downloaded and joined on the Gene producing a large association matrix. Only association is preserved in order to create a binary classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter hide_code\n",
    "{% do SectionField(\n",
    "    name='DATASETS',\n",
    "    title='ATTRIBUTE AND PREDICTION CLASS DATASET SELECTION',\n",
    "    subtitle='Select the datasets to use for learning and classification.',\n",
    "    img='attributes.png',\n",
    ") %}\n",
    "{% set harmonizome_attribute_datasets = MultiCheckboxField(\n",
    "    name='attribute_datasets',\n",
    "    label='Attribute Selection (place cursor inside the box to add more datasets)',\n",
    "    hint='Databases to use for prediction',\n",
    "    description='The selected datasets will be concatenated and used to train the model.',\n",
    "    default=[\n",
    "        'CCLE Cell Line Gene Expression Profiles',\n",
    "        'ENCODE Transcription Factor Targets',\n",
    "    ],\n",
    "    choices=[\n",
    "        'CCLE Cell Line Gene Expression Profiles',\n",
    "        'ENCODE Transcription Factor Targets',\n",
    "        'Allen Brain Atlas Adult Human Brain Tissue Gene Expression Profiles',\n",
    "        'CHEA Transcription Factor Targets',\n",
    "        'BioGPS Cell Line Gene Expression Profiles',\n",
    "        'GTEx Tissue Gene Expression Profiles',\n",
    "    ],\n",
    "    descriptions={\n",
    "        'CCLE Cell Line Gene Expression Profiles': 'MRNA expression profiles for cancer cell lines',\n",
    "        'ENCODE Transcription Factor Targets': 'Target genes of transcription factors from transcription factor binding site profiles',\n",
    "        'Allen Brain Atlas Adult Human Brain Tissue Gene Expression Profiles': 'MRNA expression profiles for 6 adult human brain tissue samples spanning ~300 brain structures',\n",
    "        'CHEA Transcription Factor Targets': 'Target genes of transcription factors from published ChIP-chip, ChIP-seq, and other transcription factor binding site profiling studies',\n",
    "        'BioGPS Cell Line Gene Expression Profiles': 'MRNA expression profiles for the NCI-60 panel of cancer cell lines',\n",
    "        'GTEx Tissue Gene Expression Profiles': 'MRNA expression profiles for tissues',\n",
    "    },\n",
    "    section='DATASETS',\n",
    ") %}\n",
    "{% set additional_attribute_dataset = FileField(\n",
    "    name='additional_attribute_dataset',\n",
    "    label='Custom Attribute Dataset (Optional)',\n",
    "    description='We will use this on top of the harmonizome attribute data (or only if you deselect the harmonizome data)',\n",
    "    default='',\n",
    "    section='DATASETS',\n",
    ") %}\n",
    "{% if additional_attribute_dataset.value %}\n",
    "{% set attribute_datasets = harmonizome_attribute_datasets.value + [additional_attribute_dataset.value] %}\n",
    "{% else %}\n",
    "{% set attribute_datasets = harmonizome_attribute_datasets.value %}\n",
    "{% endif %}\n",
    "\n",
    "{% set target = TabField(\n",
    "    name='target',\n",
    "    label='Target Selection',\n",
    "    default='Harmonizome',\n",
    "    choices={\n",
    "        'Harmonizome': [AutocompleteField(\n",
    "            name='harmonizome_class',\n",
    "            label='Harmonizome Class',\n",
    "            description='A class of genes annotated in select Harmonizome association datasets',\n",
    "            default='cancer (DOID:162 from DISEASES Text-mining Gene-Disease Assocation Evidence Scores)',\n",
    "            file_path='https://appyters.maayanlab.cloud/storage/Harmonizome_ML/class_list.json',\n",
    "        )],\n",
    "        'Custom': [TextListField(\n",
    "            name='custom_class',\n",
    "            label='Custom Geneset Class',\n",
    "            hint='Newline separated geneset of genes in the class',\n",
    "            description='A set of genes that make up your own class',\n",
    "            default='',\n",
    "        )],\n",
    "    },\n",
    "    section='DATASETS',\n",
    ") %}\n",
    "{% if target.raw_value == 'Harmonizome' %}\n",
    "{% set target_label, target_group, target_dataset = target.value[0].value|re_match('^(.+) \\\\((.+) from (.+)\\\\)$') %}\n",
    "{% set target_name = (target_label + ' ' + target_group).strip() %}\n",
    "{% else %}\n",
    "{% set target_name = 'target' %}\n",
    "{% set target_dataset = 'custom' %}\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "attribute_datasets = {{ attribute_datasets }}\n",
    "df_attributes = list(Harmonizome.download_df(\n",
    "    [dataset\n",
    "     for dataset in attribute_datasets],\n",
    "    ['gene_attribute_matrix.txt.gz'],\n",
    "))\n",
    "for name, df in zip(attribute_datasets, df_attributes):\n",
    "    df.index.name = json.loads(df.index.name)[0]\n",
    "    df.index = df.index.map(lambda s: json.loads(s)[0])\n",
    "    df.columns = df.columns.map(lambda s: ' '.join(ss for ss in try_json_loads(s) if ss != 'na'))\n",
    "    print('%s shape:' % (name), df.shape)\n",
    "    display(df.head())\n",
    "\n",
    "# Assemble all attribute datasets\n",
    "if len(df_attributes) > 1:\n",
    "    # Obtain merged dataframe with omics and target data\n",
    "    df = reduce(\n",
    "        lambda a, b: pd.merge( # Merge two dataframes item by item\n",
    "            a, # left\n",
    "            b, # right\n",
    "            # Items with the same left and right index are merged\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            how='outer', # Keep mis-matched index\n",
    "        ),\n",
    "        df_attributes,\n",
    "    )\n",
    "else:\n",
    "    df = df_attributes[0]\n",
    "\n",
    "X = df.applymap(lambda f: 1 if f!=0 else 0)\n",
    "print('Total Shape:', X.shape)\n",
    "display(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "We download the dataset containtaining the target{% if target.raw_value == 'Harmonizome' %} ({{ target_name }}), {{ target_dataset }}{% endif %}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "{%if target.raw_value == 'Harmonizome' %}\n",
    "target_datasets = ['{{ target_dataset }}']\n",
    "\n",
    "# Download attribute datasets from Harmonizome\n",
    "df_targets = list(Harmonizome.download_df(\n",
    "    [dataset\n",
    "     for dataset in target_datasets],\n",
    "    ['gene_attribute_matrix.txt.gz'],\n",
    "))\n",
    "\n",
    "for name, df in zip(target_datasets, df_targets):\n",
    "    df.index.name = json.loads(df.index.name)[0]\n",
    "    df.index = df.index.map(lambda s: json.loads(s)[0])\n",
    "    df.columns = df.columns.map(lambda s: ' '.join(ss for ss in try_json_loads(s) if ss != 'na'))\n",
    "    print('%s shape:' % (name), df.shape)\n",
    "    display(df.head())\n",
    "\n",
    "# Assemble all target datasets\n",
    "if len(df_targets) > 1:\n",
    "    # Obtain merged dataframe with omics and target data\n",
    "    df = reduce(\n",
    "        lambda a, b: pd.merge( # Merge two dataframes item by item\n",
    "            a, # left\n",
    "            b, # right\n",
    "            # Items with the same left and right index are merged\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            how='outer', # Keep mis-matched index\n",
    "        ),\n",
    "        df_targets,\n",
    "    )\n",
    "else:\n",
    "    df = df_targets[0]\n",
    "{% else %}\n",
    "target = {{ target.value[0].value }}\n",
    "df = pd.Series(\n",
    "    np.in1d(X.index, [gene.upper() for gene in target]),\n",
    "    index=X.index,\n",
    ").to_frame('{{ target_name }}')\n",
    "{% endif %}\n",
    "\n",
    "Y = df.applymap(lambda f: 1 if f!=0 else 0)\n",
    "print('Total Shape:', Y.shape)\n",
    "display(Y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "For the target class, we build a list (1 if gene is associated, otherwise 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "y = np.in1d(X.index, Y[Y['{{ target_name }}'] == 1].index).astype(np.int8)\n",
    "\n",
    "print('Known Targets: %d (%0.3f %%)' % (y.sum(), 100*y.sum()/len(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We produce a target array containing 1 if the gene is associated and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output data shapes\n",
    "print('Input shape:', X.shape)\n",
    "print('Target shape:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter hide_code\n",
    "{% do SectionField(\n",
    "    name='SETTINGS',\n",
    "    title='SETTINGS',\n",
    "    subtitle='From here you can select the various available Machine Learning algorithms, their unique settings, and the methods to use to evaluate the classifier.',\n",
    "    img='settings.png',\n",
    ") %}\n",
    "{% set dimensionality_reduction = ChoiceField(\n",
    "    name='dimensionality_reduction',\n",
    "    label='Dimensionality Reduction Algorithm',\n",
    "    description='A dimensionality reduction algorithm should be selected to improve the quality of the classifier.',\n",
    "    default='PCA',\n",
    "    choices={\n",
    "        'PCA': 'sk.decomposition.PCA(n_components=64)',\n",
    "        'TruncatedSVD': 'sk.decomposition.TruncatedSVD(n_components=64)',\n",
    "        'IncrementalPCA': 'sk.decomposition.IncrementalPCA(n_components=64)',\n",
    "        'ICA': 'sk.decomposition.FastICA(n_components=64)',\n",
    "        'SparsePCA': 'sk.decomposition.SparsePCA(n_components=64)',\n",
    "    },\n",
    "    section='SETTINGS'\n",
    ") %}\n",
    "{% set manifold_projection = ChoiceField(\n",
    "    name='manifold_projection',\n",
    "    label='Manifold Projection Algorithm',\n",
    "    description='A an algorithm for projecting the reduced dimensionality data into 2 dimensions.',\n",
    "    default='TSNE',\n",
    "    choices={\n",
    "        'TSNE': 'sk.manifold.TSNE(n_components=2)',\n",
    "        'UMAP': 'umap.UMAP(n_components=2)',\n",
    "    },\n",
    "    section='SETTINGS'\n",
    ") %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "## Dimensionality Reduction\n",
    "\n",
    "We reduce the dimensionality of our omics feature space with {{ dimensionality_reduction.raw_value }} and project it onto a manifold with {{ manifold_projection.raw_value }}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "clf_dimensionality_reduction = {{ dimensionality_reduction }}\n",
    "X_reduced = pd.DataFrame(\n",
    "    clf_dimensionality_reduction.fit_transform(X.values),\n",
    "    index=X.index,\n",
    ")\n",
    "display(\n",
    "    px.scatter_3d(\n",
    "        X_reduced,\n",
    "        x=X_reduced.columns[1],\n",
    "        y=X_reduced.columns[2],\n",
    "        z=X_reduced.columns[3],\n",
    "        color=y,\n",
    "        hover_data=[X_reduced.index],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "{% if manifold_projection.raw_value == 'UMAP' %}\n",
    "import umap\n",
    "{% endif %}\n",
    "proj = {{ manifold_projection }}\n",
    "X_transformed = pd.DataFrame(\n",
    "    proj.fit_transform(X_reduced.iloc[:, :10].values),\n",
    "    index=X_reduced.index,\n",
    ")\n",
    "display(\n",
    "    px.scatter(\n",
    "        X_transformed,\n",
    "        x=X_reduced.columns[0],\n",
    "        y=X_reduced.columns[1],\n",
    "        color=y,\n",
    "        hover_data=[X_transformed.index],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_hide\n",
    "{% set feature_selection = ChoiceField(\n",
    "    name='feature_selection',\n",
    "    label='Machine Learning Feature Selection',\n",
    "    default='None',\n",
    "    choices={\n",
    "        'None': 'None',\n",
    "        'SelectFromLinearSVC': 'sk.feature_selection.SelectFromModel(sk.svm.LinearSVC(loss=\"squared_hinge\", penalty=\"l1\", dual=False))',\n",
    "        'SelectFromExtraTrees': 'sk.feature_selection.SelectFromModel(sk.tree.ExtraTreeClassifier())',\n",
    "        'SelectKBest': 'sk.feature_selection.SelectKBest(sk.feature_selection.f_classif))',\n",
    "        'SelectKBestChi2': 'sk.feature_selection.SelectKBest(sk.feature_selection.chi2)',\n",
    "        'SelectKBestMultiInfo': 'sk.feature_selection.SelectKBest(sk.feature_selection.mutual_info_classif)',\n",
    "    },\n",
    "    section='SETTINGS',\n",
    ") %}\n",
    "{% set cv_algorithm = ChoiceField(\n",
    "    name='cv_algorithm',\n",
    "    label='Cross Validation Algorithm',\n",
    "    default='StratifiedKFold',\n",
    "    value='KFold',\n",
    "    choices={\n",
    "        'KFold': 'sk.model_selection.KFold',\n",
    "        'GroupKFold': 'sk.model_selection.GroupKFold',\n",
    "        'RepeatedKFold': 'sk.model_selection.RepeatedKFold',\n",
    "        'StratifiedKFold': 'sk.model_selection.StratifiedKFold',\n",
    "        'RepeatedStratifiedKFold': 'sk.model_selection.RepeatedStratifiedKFold',\n",
    "    },\n",
    "    section='SETTINGS',\n",
    ") %}\n",
    "{% set algorithm = ChoiceField(\n",
    "    name='algorithm',\n",
    "    label='Machine Learning Algorithm',\n",
    "    default='RandomForestClassifier',\n",
    "    description='A machine learning algorithm should be selected to construct the predictive model.',\n",
    "    choices={\n",
    "        'GradientBoostingClassifier': 'sk.ensemble.GradientBoostingClassifier()',\n",
    "        'RandomForestClassifier': 'sk.ensemble.RandomForestClassifier()',\n",
    "        'AdaBoostClassifier': 'sk.ensemble.AdaBoostClassifier()',\n",
    "        'ExtraTreeClassifier': 'sk.tree.ExtraTreeClassifier()',\n",
    "        'DecisionTreeClassifier': 'sk.tree.DecisionTreeClassifier()',\n",
    "        'KNeighborsClassifier': 'sk.neighbors.KNeighborsClassifier()',\n",
    "        'RadiusNeighborsClassifier': 'sk.neighbors.RadiusNeighborsClassifier()',\n",
    "        'MLPClassifier': 'sk.neural_network.MLPClassifier()',\n",
    "        'OneClassSVM': 'sk.svm.OneClassSVM()',\n",
    "    },\n",
    "    section='SETTINGS',\n",
    ") %}\n",
    "{% set calibrated = BoolField(\n",
    "    name='calibrated',\n",
    "    label='Calibrate algorithm predictions',\n",
    "    description='Calibrate the prediction probabilities eliminating model-imparted bias.',\n",
    "    default=True,\n",
    "    section='SETTINGS',\n",
    ") %}\n",
    "{% set hyper_param_search = ChoiceField(\n",
    "    name='hyper_param_search',\n",
    "    label='Hyper Parameter Search Type',\n",
    "    default='None',\n",
    "    description='Hyper parameter searching is used to automatically select the best parameters (using the primary metric as the criteria).',\n",
    "    choices={\n",
    "        'None': 'None',\n",
    "        'RandomizedSearchCV': 'sk.model_selection.RandomizedSearchCV',\n",
    "        'GridSearchCV': 'sk.model_selection.GridSearchCV',\n",
    "    },\n",
    "    section='SETTINGS',\n",
    ") %}\n",
    "{% set cross_validation_n_folds = IntField(\n",
    "    name='cross_validation_n_folds',\n",
    "    label='Cross-Validated Folds',\n",
    "    description='Cross validation is employed as a strategy to train the model on data that the model has not seen before, more folds will ensure that the model is generalizing well.',\n",
    "    default=3,\n",
    "    min=2,\n",
    "    max=10,\n",
    "    section='SETTINGS',\n",
    ") %}\n",
    "{# available_metrics from sk.metrics.SCORERS.keys() #}\n",
    "{% set primary_metric = ChoiceField(\n",
    "    name='primary_metric',\n",
    "    label='Primary Evaluation Metric',\n",
    "    default='roc_auc',\n",
    "    description='The primary evaluation metric is used for deciding how we assess the performance of our model.',\n",
    "    choices=['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_absolute_percentage_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_root_mean_squared_error', 'neg_mean_poisson_deviance', 'neg_mean_gamma_deviance', 'accuracy', 'top_k_accuracy', 'roc_auc', 'roc_auc_ovr', 'roc_auc_ovo', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'neg_brier_score', 'adjusted_rand_score', 'rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'],\n",
    "    section='SETTINGS',\n",
    ") %}\n",
    "{% set evaluation_metrics = MultiChoiceField(\n",
    "    name='evaluation_metrics',\n",
    "    label='Evaluation Metrics',\n",
    "    default=[],\n",
    "    description='Additional evaluation metrics can be specified, these metrics will also be reported for all models trained.',\n",
    "    value=['recall', 'f1'],\n",
    "    choices=['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_absolute_percentage_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_root_mean_squared_error', 'neg_mean_poisson_deviance', 'neg_mean_gamma_deviance', 'accuracy', 'top_k_accuracy', 'roc_auc', 'roc_auc_ovr', 'roc_auc_ovo', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'neg_brier_score', 'adjusted_rand_score', 'rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'],\n",
    "    section='SETTINGS',\n",
    ") %}\n",
    "{% set all_metrics = [primary_metric.value] + evaluation_metrics.value %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "## Machine Learning\n",
    "\n",
    "We apply a {% if hyper_param_search.raw_value != 'None' %}{{ hyper_param_search.raw_value }} search for the hyper parameters\n",
    "of a {% endif %}sklearn pipeline with a dimensionality reduction step of {{ dimensionality_reduction.raw_value }}\n",
    "{% if feature_selection.raw_value != 'None' %}and a feature selection step of {{ feature_selection.raw_value }}\n",
    "{% endif %} and a{% if calibrated %} calibrated{%endif %} {{ algorithm.raw_value }} classifier\n",
    "using {{ cross_validation_n_folds.raw_value }}-fold repeated\n",
    "stratified cross-validation, optimizing {{ primary_metric.raw_value }}\n",
    "{% if evaluation_metrics.raw_value %} and computing {{ ', '.join(evaluation_metrics.raw_value) }}{% endif %}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "{% if algorithm.raw_value == 'GradientBoostingClassifier' %}\n",
    "## Early stopping function\n",
    "def early_stopping(n_rounds, tol=0.001):\n",
    "    def early_stopping_func(i, self, local):\n",
    "        rounds = getattr(self, '__rounds', 0)\n",
    "        last = getattr(self, '__last', None)\n",
    "        current = self.train_score_[i]\n",
    "        if last and current and abs(current - last) < tol:\n",
    "            rounds += 1\n",
    "            if rounds > n_rounds:\n",
    "                return True\n",
    "        else:\n",
    "            rounds = 0\n",
    "        setattr(self, '__last', current)\n",
    "        setattr(self, '__rounds', rounds)\n",
    "        return False\n",
    "    return early_stopping_func\n",
    "{% endif %}\n",
    "\n",
    "{#\n",
    "param_grid = {\n",
    "    'reduce_dim__n_components': randint(2, 1024),\n",
    "{% if algorithm.raw_value == 'GradientBoostingClassifier' %}\n",
    "    'clf__loss': ['deviance', 'exponential'],\n",
    "    'clf__learning_rate': randfloat(0.001, 1.),\n",
    "    'clf__subsample': randfloat(0.01, 1.),\n",
    "{% elif algorithm.raw_value == 'RandomForestClassifier' %}\n",
    "    'clf__oob_score': [True],\n",
    "    'clf__criterion': ['gini', 'entropy'],\n",
    "{% endif %}\n",
    "    'clf__n_estimators': randint(10, 200),\n",
    "    'clf__max_depth': randint(20, 50),\n",
    "    'clf__max_features': ['sqrt', 'log2', None],\n",
    "    'clf__min_impurity_decrease': randfloat(0., 0.2),\n",
    "    'clf__min_weight_fraction_leaf': randfloat(0., 0.5),\n",
    "}\n",
    "\n",
    "fit_params = {\n",
    "{% if algorithm.raw_value == 'GradientBoostingClassifier' %}\n",
    "    'clf__monitor': early_stopping(5),\n",
    "{% endif %}\n",
    "}\n",
    "#}\n",
    "    \n",
    "cv = {{ cv_algorithm }}(\n",
    "    n_splits={{ cross_validation_n_folds }},\n",
    "    shuffle=True,\n",
    "    random_state=rng,\n",
    ")\n",
    "\n",
    "model =\n",
    "{%- if hyper_param_search.raw_value != 'None' %} {{ hyper_param_search }}({% endif -%}\n",
    "{%- if target.raw_value == 'Gene' %} multioutput.MultiOutputClassifier({% endif -%}\n",
    "    {%- if calibrated %} sk.calibration.CalibratedClassifierCV({% endif -%}\n",
    "        sk.pipeline.Pipeline([\n",
    "            ('reduce_dim', {{ dimensionality_reduction }}),\n",
    "            {%- if feature_selection.raw_value != 'None' %}('feature_selection', {{ feature_selection }}),{% endif %}\n",
    "            ('clf', {{ algorithm }}),\n",
    "        ]),\n",
    "    cv=cv,\n",
    "{% if calibrated %}){% endif -%}{% if target.raw_value == 'Gene' %}){% endif %}{%- if hyper_param_search.raw_value != 'None' %}){% endif %}\n",
    "\n",
    "# Scoring parameters\n",
    "primary_metric = '{{ primary_metric }}'\n",
    "evaluation_metrics = {{ evaluation_metrics }}\n",
    "scoring_params = {k: scorer\n",
    "                  for k, scorer in sk.metrics.SCORERS.items()\n",
    "                  if k == primary_metric or k in evaluation_metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "{% if hyper_param_search.raw_value == 'None' %}\n",
    "df_results = pd.DataFrame()\n",
    "for fold, (train, test) in enumerate(cv.split(X.values, y)):\n",
    "    model.fit(X.values[train], y[train])\n",
    "    {% for metric in all_metrics %}\n",
    "    df_results.loc[fold, '{{ metric }}'] = scoring_params['{{ metric }}'](model, X.values[test], y[test])\n",
    "    {% endfor %}\n",
    "display(df_results.agg(['mean', 'std']))\n",
    "{% else %}\n",
    "model.fit(X, y)\n",
    "df_results = model.cv_results_\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This visualization shows illustrates the cross-validated performance of the model. Low fold variance and high AUC is desired in a well-generalized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "{% if 'roc_auc' in all_metrics %}\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "for fold, (train, test) in enumerate(cv.split(X.values, y)):\n",
    "    model.fit(X.values[train], y[train])\n",
    "    y_proba = model.predict_proba(X.values[test]) # Probability prediction will be True\n",
    "    fpr, tpr, _ = sk.metrics.roc_curve(y[test], y_proba[:, 1])\n",
    "    tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = sk.metrics.auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    ax.plot(fpr, tpr, alpha=0.4, label='ROC Fold %d (AUC=%0.3f)' % (fold, roc_auc))\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = sk.metrics.auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "ax.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2)\n",
    "\n",
    "ax.plot([0,1],[0,1],'--', label='Luck')\n",
    "ax.legend()\n",
    "\n",
    "z = (mean_auc - 0.5)/std_auc\n",
    "cl = sp.stats.norm.cdf(z) * 100\n",
    "ci = sp.stats.norm.interval(0.95, loc=mean_auc, scale=std_auc)\n",
    "print('Confidence interval (95%)', ci)\n",
    "print(\"We are %0.3f %% confident the model's results are not just chance.\" % (cl))\n",
    "if cl > 95:\n",
    "    print('This is statistically significant')\n",
    "else:\n",
    "    print('This is not statistically significant')\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will take a long time as we are evaluating n_iter different models n_splits different times each computing all the metrics on `product(X.shape)` data points--not to mention the size of each model dictated by the range of parameters specified in the params dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X.values, y)\n",
    "sk.metrics.plot_confusion_matrix(model, X.values, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain prediction results\n",
    "y_proba = model.predict_proba(X)[:, 1]\n",
    "results = pd.DataFrame({\n",
    "    'Known': y,\n",
    "    'Predicted': (y_proba > 0.5).astype(int),\n",
    "    'Prediction Probability': y_proba,\n",
    "}, index=X.index).sort_values(\n",
    "    'Prediction Probability',\n",
    "    ascending=False,\n",
    ")\n",
    "results[((results['Known'] != results['Predicted']) & (results['Prediction Probability'] > 0.5))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('results.tsv', sep='\\t')\n",
    "display(Markdown('Download model predictions at [results.tsv](./results.tsv)'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
