{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%appyter init\n",
    "from appyter import magic\n",
    "magic.init(lambda _=globals: _())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter hide_code\n",
    "{% do SectionField(\n",
    "    name='PRIMARY',\n",
    "    title='Upload gene sets',\n",
    "    subtitle='Upload your up and down gene sets',\n",
    "    img='file-upload.png'\n",
    ") %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "\n",
    "{% set title = StringField(\n",
    "    name='title',\n",
    "    label='Notebook name',\n",
    "    default='LDP3 Consensus Perturbagens',\n",
    "    section=\"PRIMARY\",\n",
    ") %}\n",
    "\n",
    "# {{ title.raw_value }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import scipy.stats as st\n",
    "from IPython.display import display, IFrame, Markdown, HTML\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from umap import UMAP\n",
    "from sklearn.manifold import TSNE\n",
    "from maayanlab_bioinformatics.normalization import quantile_normalize, zscore_normalize\n",
    "from maayanlab_bioinformatics.harmonization import ncbi_genes_lookup\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METADATA_API = \"https://ldp3.cloud/metadata-api\"\n",
    "DATA_API = \"https://ldp3.cloud/data-api/api/v1\"\n",
    "CLUSTERGRAMMER_URL = 'https://maayanlab.cloud/clustergrammer/matrix_upload/'\n",
    "S3_PREFIX = \"https://appyters.maayanlab.cloud/storage/LDP3Consensus/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncbi_lookup = ncbi_genes_lookup('Mammalia/Homo_sapiens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = 1\n",
    "figure = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def convert_genes(up_genes, down_genes):\n",
    "    try:\n",
    "        payload = {\n",
    "           \"filter\": {\n",
    "               \"where\": {\n",
    "                   \"meta.symbol\": {\"inq\": up_genes + down_genes}\n",
    "               }\n",
    "           }\n",
    "        }\n",
    "        timeout = 0.5\n",
    "        for i in range(5):\n",
    "            res = requests.post(METADATA_API + \"/entities/find\", json=payload)\n",
    "            if res.ok:\n",
    "                break\n",
    "            else:\n",
    "                time.sleep(timeout)\n",
    "                if res.status >= 500:\n",
    "                    timeout = timeout * 2\n",
    "        else:\n",
    "            raise Exception(res.text)\n",
    "        results = res.json()\n",
    "        up = set(up_genes)\n",
    "        down = set(down_genes)\n",
    "        converted = {\n",
    "            \"up_entities\": [],\n",
    "            \"down_entities\": []\n",
    "        }\n",
    "        for i in results:\n",
    "            symbol = i[\"meta\"][\"symbol\"]\n",
    "            if symbol in up:\n",
    "                converted[\"up_entities\"].append(i[\"id\"])\n",
    "            elif symbol in down:\n",
    "                converted[\"down_entities\"].append(i[\"id\"])\n",
    "        return converted\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "def signature_search(genes, library):\n",
    "    try:\n",
    "        payload = {\n",
    "            **genes,\n",
    "            \"database\": library,\n",
    "            \"limit\": 1000\n",
    "        }\n",
    "        timeout = 0.5\n",
    "        for i in range(5):\n",
    "            res = requests.post(DATA_API + \"/enrich/ranktwosided\", json=payload)\n",
    "            if res.ok:\n",
    "                break\n",
    "            else:\n",
    "                time.sleep(timeout)\n",
    "                if res.status >= 500:\n",
    "                    timeout = timeout * 2\n",
    "        else:\n",
    "            raise Exception(res.text)\n",
    "        \n",
    "        return res.json()[\"results\"]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "def resolve_signatures(s):\n",
    "    try:\n",
    "        sigs = {}\n",
    "        for i in s:\n",
    "            uid = i[\"uuid\"]\n",
    "            i['z-down'] = -i['z-down']\n",
    "            i['direction-down'] = -i['direction-down']\n",
    "            if i['z-up'] > 0 and i['z-down'] > 0:\n",
    "                i[\"type\"] = \"mimicker\"\n",
    "                sigs[uid] = i\n",
    "            elif i['z-up'] < 0 and i['z-down'] < 0:\n",
    "                i[\"type\"] = \"reverser\"\n",
    "                sigs[uid] = i\n",
    "            \n",
    "        payload = {\n",
    "            \"filter\": {\n",
    "                \"where\": {\n",
    "                    \"id\": {\"inq\": list(sigs.keys())}\n",
    "                },\n",
    "                \"fields\": [\n",
    "                    \"id\",\n",
    "                    \"meta.pert_name\",\n",
    "                    \"meta.pert_type\"\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "        timeout=0.5\n",
    "        for i in range(5):\n",
    "            res = requests.post(METADATA_API + \"/signatures/find\", json=payload)\n",
    "            if res.ok:\n",
    "                break\n",
    "            else:\n",
    "                time.sleep(timeout)\n",
    "                if res.status >= 500:\n",
    "                    timeout = timeout * 2\n",
    "        else:\n",
    "            raise Exception(res.text)\n",
    "        results = res.json()\n",
    "        perturbagens = {\n",
    "            \"mimickers\": {},\n",
    "            \"reversers\": {}\n",
    "        }\n",
    "        for sig in results:\n",
    "            uid = sig[\"id\"]\n",
    "            scores = sigs[uid]\n",
    "            sig[\"scores\"] = scores\n",
    "            if \"pert_name\" in sig[\"meta\"]:\n",
    "                pert_name = sig[\"meta\"][\"pert_name\"]\n",
    "                if scores[\"type\"] == \"mimicker\":\n",
    "                    if pert_name not in perturbagens[\"mimickers\"]:\n",
    "                        perturbagens[\"mimickers\"][pert_name] = 0\n",
    "                    perturbagens[\"mimickers\"][pert_name] += 1\n",
    "                elif scores[\"type\"] == \"reverser\":\n",
    "                    if pert_name not in perturbagens[\"reversers\"]:\n",
    "                        perturbagens[\"reversers\"][pert_name] = 0\n",
    "                    perturbagens[\"reversers\"][pert_name] += 1\n",
    "        return perturbagens\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustergrammer(df, name, figure, label=\"Clustergrammer\"):\n",
    "    clustergram_df = df.rename(columns={i:\"Signature: %s\"%i for i in df.columns}, index={i:\"Drug: %s\"%i for i in df.index})\n",
    "    clustergram_df.to_csv(name, sep=\"\\t\")\n",
    "    response = ''\n",
    "    for i in range(5):\n",
    "        try:\n",
    "            res = requests.post(CLUSTERGRAMMER_URL, files={'file': open(name, 'rb')})\n",
    "            timeout = 1\n",
    "            if not res.ok:\n",
    "                response = res.text\n",
    "                time.sleep(timeout)\n",
    "                if res.status >= 500:\n",
    "                    timeout = timeout * 2\n",
    "            else:\n",
    "                clustergrammer_url = res.text.replace(\"http:\",\"https:\")   \n",
    "                break\n",
    "        except Exception as e:\n",
    "            response = e\n",
    "            time.sleep(2)\n",
    "    else:\n",
    "        if type(response) == Exception:\n",
    "            raise response\n",
    "        else:\n",
    "            raise Exception(response)\n",
    "    print(clustergrammer_url)\n",
    "    display(IFrame(clustergrammer_url, width=\"1000\", height=\"1000\"))\n",
    "    display(Markdown(\"**Figure %d** %s [Go to url](%s)\"%(figure, label, clustergrammer_url)))\n",
    "    figure += 1\n",
    "    return figure\n",
    "\n",
    "cmap = sns.cubehelix_palette(50, hue=0.05, rot=0, light=1, dark=0)\n",
    "\n",
    "def heatmap(df, filename, figure, label, width=15, height=15):\n",
    "    fig = plt.figure(figsize=(width,height))\n",
    "    cg = sns.clustermap(df, cmap=cmap, figsize=(width, height))\n",
    "    cg.ax_row_dendrogram.set_visible(False)\n",
    "    cg.ax_col_dendrogram.set_visible(False)\n",
    "    display(cg)\n",
    "    plt.show()\n",
    "    cg.savefig(filename)\n",
    "    display(Markdown(\"**Figure %d** %s\"%(figure, label)))\n",
    "    figure+=1\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "{% set up_gene_sets = FileField(\n",
    "    name='up_gene_sets',\n",
    "    label='up gene sets',\n",
    "    default='covid19_up.gmt',\n",
    "    section=\"PRIMARY\",\n",
    "    examples={\n",
    "        'covid19_up.gmt': 'https://appyters.maayanlab.cloud/storage/LDP3Consensus/covid19_up.gmt'\n",
    "    }\n",
    ") %}\n",
    "\n",
    "{% set down_gene_sets = FileField(\n",
    "    name='down_gene_sets',\n",
    "    label='down gene sets',\n",
    "    default='covid19_down.gmt',\n",
    "    section=\"PRIMARY\",\n",
    "    examples={\n",
    "        'covid19_down.gmt': 'https://appyters.maayanlab.cloud/storage/LDP3Consensus/covid19_down.gmt'\n",
    "    }\n",
    ") %}\n",
    "\n",
    "{% set input_meta = FileField(\n",
    "    name='input_meta',\n",
    "    label='Metadata File',\n",
    "    default='covid19_meta.tsv',\n",
    "    section=\"PRIMARY\",\n",
    "    examples={\n",
    "        'covid19_meta.tsv': 'https://appyters.maayanlab.cloud/storage/LDP3Consensus/covid19_meta.tsv',\n",
    "    }\n",
    ") %}\n",
    "{% set color_by =  StringField(name='group_by', label='Group By', description=\"Group By Metadata\", default='', section='PRIMARY')%}\n",
    "\n",
    "\n",
    "up_gene_sets = {{ up_gene_sets }}\n",
    "down_gene_sets = {{ down_gene_sets }}\n",
    "input_meta = {{ input_meta }}\n",
    "color_by = {{ color_by }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = pd.read_csv(input_meta, sep=\"\\t\", index_col=0)\n",
    "display(meta_df.head())\n",
    "display(Markdown(\"**Table %d** Input Metadata\"%table))\n",
    "table+=1\n",
    "if color_by == \"\":\n",
    "    color_by = meta_df.columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "alpha = {{FloatField(name='alpha', label='p-value cutoff', default=0.05, section='PRIMARY')}}\n",
    "perc = {{FloatField(name='perc',\n",
    "                         label='percentage',\n",
    "                         description='Minimum percentage cutoff for perturbagen instances in signatures',\n",
    "                         default=0.1, section='PRIMARY')}}\n",
    "top_perts = {{IntField(name='top_perts', label='top perturbation', default=50, section='PRIMARY')}}\n",
    "perplexity = {{IntField(name='perplexity', label='Perplexity', description=\"t-SNE perplexity\", default=15, section='PRIMARY')}}\n",
    "n_neighbors = {{IntField(name='n_neighbors', label='n_neighbors', description=\"UMAP's n_neighbors\", default=15, section='PRIMARY')}}\n",
    "random_state = {{IntField(name='random_state', label='Random State', description=\"Random State\", default=21, section='PRIMARY')}}\n",
    "\n",
    "width = {{FloatField(name='width', label='image width', default=10, section='PRIMARY')}}\n",
    "height = {{FloatField(name='height', label='image height', default=10, section='PRIMARY')}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signatures = {}\n",
    "with open(up_gene_sets) as upfile:\n",
    "    for line in upfile:\n",
    "        unpacked = line.strip().split(\"\\t\\t\")\n",
    "        if not len(unpacked) == 2:\n",
    "            raise ValueError(\"GMT is not formatted properly, please consult the README of the appyter for proper formatting\")\n",
    "        sigid, geneset_str = unpacked\n",
    "        genes = []\n",
    "        for i in geneset_str.split(\"\\t\"):\n",
    "            gene = i.split(\",\")[0]\n",
    "            gene_name = ncbi_lookup(gene.upper())\n",
    "            if gene_name:\n",
    "                genes.append(gene_name)\n",
    "        signatures[sigid] = {\n",
    "            \"up_genes\": genes\n",
    "        }\n",
    "with open(down_gene_sets) as downfile:\n",
    "    for line in downfile:\n",
    "        unpacked = line.strip().split(\"\\t\\t\")\n",
    "        if not len(unpacked) == 2:\n",
    "            raise ValueError(\"GMT is not formatted properly, please consult the README of the appyter for proper formatting\")\n",
    "        sigid, geneset_str = unpacked\n",
    "        if sigid not in signatures:\n",
    "            raise ValueError(\"%s did not match any of the up signatures, make sure that the signature names are the same for both up and down genes\"%sigid)\n",
    "        else:\n",
    "            genes = []\n",
    "            for i in geneset_str.split(\"\\t\"):\n",
    "                gene = i.split(\",\")[0]\n",
    "                gene_name = ncbi_lookup(gene)\n",
    "                if gene_name:\n",
    "                    genes.append(gene_name)\n",
    "            signatures[sigid][\"down_genes\"] = genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "datasets = {{ MultiChoiceField(name='datasets',\n",
    "                                description='Select the LINCS Dataset that you want to use for Signature Search',\n",
    "                                label='LINCS Datasets',\n",
    "                                default=[\n",
    "                                    \"LINCS L1000 CRISPR Perturbations (2021)\",\n",
    "                                    \"LINCS L1000 Chemical Perturbations (2021)\",\n",
    "                                ],\n",
    "                                section = 'PRIMARY',\n",
    "                                choices=[\n",
    "                                    \"LINCS L1000 Antibody Perturbations (2021)\",\n",
    "                                    \"LINCS L1000 Ligand Perturbations (2021)\",\n",
    "                                    \"LINCS L1000 Overexpression Perturbations (2021)\",\n",
    "                                    \"LINCS L1000 CRISPR Perturbations (2021)\",\n",
    "                                    \"LINCS L1000 shRNA Perturbations (2021)\",\n",
    "                                    \"LINCS L1000 Chemical Perturbations (2021)\",\n",
    "                                    \"LINCS L1000 siRNA Perturbations (2021)\",\n",
    "                                ]\n",
    "                              )                           \n",
    "}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_map = {\n",
    "  \"LINCS L1000 Antibody Perturbations (2021)\": \"l1000_aby\",\n",
    "  \"LINCS L1000 Ligand Perturbations (2021)\": \"l1000_lig\",\n",
    "  \"LINCS L1000 Overexpression Perturbations (2021)\": \"l1000_oe\",\n",
    "  \"LINCS L1000 CRISPR Perturbations (2021)\": \"l1000_xpr\",\n",
    "  \"LINCS L1000 shRNA Perturbations (2021)\": \"l1000_shRNA\",\n",
    "  \"LINCS L1000 Chemical Perturbations (2021)\": \"l1000_cp\",\n",
    "  \"LINCS L1000 siRNA Perturbations (2021)\": \"l1000_siRNA\"\n",
    "}\n",
    "\n",
    "gene_page = {\n",
    "  \"LINCS L1000 Ligand Perturbations (2021)\",\n",
    "  \"LINCS L1000 Overexpression Perturbations (2021)\",\n",
    "  \"LINCS L1000 CRISPR Perturbations (2021)\",\n",
    "  \"LINCS L1000 shRNA Perturbations (2021)\",\n",
    "  \"LINCS L1000 siRNA Perturbations (2021)\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enriched = {lib:{\"mimickers\": {}, \"reversers\": {}} for lib in datasets}\n",
    "enriched = {\"mimickers\": {lib: {} for lib in datasets}, \"reversers\": {lib: {} for lib in datasets}}\n",
    "\n",
    "for k,sig in tqdm(signatures.items()):    \n",
    "    try:\n",
    "        time.sleep(0.1)\n",
    "        genes = convert_genes(sig[\"up_genes\"],sig[\"down_genes\"])\n",
    "        if len(genes[\"up_entities\"]) > 5 and len(genes[\"down_entities\"]) > 5:\n",
    "            for lib in datasets:\n",
    "                library = dataset_map[lib]\n",
    "                s = signature_search(genes, library)\n",
    "                perturbagens = resolve_signatures(s)\n",
    "                enriched[\"mimickers\"][lib][k] = perturbagens[\"mimickers\"]\n",
    "                enriched[\"reversers\"][lib][k] = perturbagens[\"reversers\"]\n",
    "                time.sleep(0.1)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_clickable(link):\n",
    "    # target _blank to open new window\n",
    "    # extract clickable text to display for your link\n",
    "    text = link.split('=')[1]\n",
    "    return f'<a target=\"_blank\" href=\"{link}\">{text}</a>'\n",
    "\n",
    "def metadata_plot(df, x,y):\n",
    "    colors = meta_df.columns\n",
    "    plot_rows = int(len(colors)/2) if len(colors) % 2 == 0 else int(len(colors)/2 + 1)\n",
    "    fig, axes = plt.subplots(plot_rows, 2, sharex=True, sharey=True, figsize=(20,8*plot_rows))\n",
    "    ax_1 = 0\n",
    "    ax_2 = 0\n",
    "    for color in colors:\n",
    "        if ax_2 == 2:\n",
    "            ax_2 = 0\n",
    "            ax_1+=1\n",
    "        sns.scatterplot(\n",
    "            data=df,\n",
    "            x=x, y=y,\n",
    "            hue=color,\n",
    "            ax=axes[ax_1, ax_2] if plot_rows > 1 else axes[ax_2]\n",
    "        )\n",
    "        if plot_rows > 1:\n",
    "            axes[ax_1, ax_2].set_title(color)\n",
    "        else:\n",
    "            axes[ax_2].set_title(color)\n",
    "        ax_2+=1\n",
    "    if plot_rows * 2 > len(colors):\n",
    "        if plot_rows > 1:\n",
    "            fig.delaxes(axes[ax_1, ax_2])\n",
    "        else:\n",
    "            fig.delaxes(axes[ax_2])\n",
    "    plt.show()\n",
    "\n",
    "def get_tsne(df, label, figure):\n",
    "#     perplexity = min(10, len(df.columns)-1)\n",
    "    X_embedded = TSNE(n_components=2,\n",
    "                      perplexity=perplexity,\n",
    "                      random_state=random_state,\n",
    "                     ).fit_transform(df.T)\n",
    "    tsne_df = pd.DataFrame(X_embedded, columns=[\"t-SNE 1\", \"t-SNE 2\"])\n",
    "    tsne_df['label'] = df.columns\n",
    "    if (not input_meta == \"\"):\n",
    "        tsne_df = tsne_df.merge(right=meta_df, left_on=\"label\", right_index=True)\n",
    "    if color_by:\n",
    "        display(\n",
    "            px.scatter(\n",
    "                tsne_df.loc[~tsne_df[color_by].isna()],\n",
    "                x=\"t-SNE 1\",\n",
    "                y=\"t-SNE 2\",\n",
    "                color=color_by,\n",
    "                hover_data=tsne_df.columns,\n",
    "              )\n",
    "        )\n",
    "        display(Markdown(\"**Figure %d** t-SNE plot of %s colored by %s\"%(figure, label, color_by)))\n",
    "    else:\n",
    "        px.scatter(\n",
    "            tsne_df,\n",
    "            x=\"t-SNE 1\",\n",
    "            y=\"t-SNE 2\",\n",
    "            hover_data=tsne_df.columns,\n",
    "          )\n",
    "        display(Markdown(\"**Figure %d** t-SNE plot of %s\"%(figure, label)))\n",
    "    if not input_meta == \"\" and len(meta_df.columns) > 1:\n",
    "        metadata_plot(tsne_df, 't-SNE 1', 't-SNE 2')\n",
    "        figure+=1\n",
    "        display(Markdown(\"**Figure %d** t-SNE plot of %s colored by metadata\"%(figure, label)))\n",
    "    return figure + 1\n",
    "\n",
    "def get_umap(df, label, figure):\n",
    "#     n_neighbors = min(15, len(df.columns)-1)\n",
    "    \n",
    "    consensus_umap = UMAP(\n",
    "      random_state=random_state,\n",
    "      n_neighbors=n_neighbors,\n",
    "      n_components=2,\n",
    "      metric='cosine',\n",
    "      min_dist=0.3,\n",
    "    )\n",
    "    consensus_umap.fit(df.T.values)\n",
    "    umap_df = pd.DataFrame(consensus_umap.transform(df.T.values),\n",
    "                           columns=[\"UMAP 1\", \"UMAP 2\"])\n",
    "    umap_df['label'] = df.columns\n",
    "    if (not input_meta == \"\"):\n",
    "        umap_df = umap_df.merge(right=meta_df, left_on=\"label\", right_index=True)\n",
    "#     display(app.run_server(mode='inline'))\n",
    "    if color_by:\n",
    "        display(\n",
    "            px.scatter(\n",
    "                umap_df.loc[~umap_df[color_by].isna()],\n",
    "                x=\"UMAP 1\",\n",
    "                y=\"UMAP 2\",\n",
    "                color=color_by,\n",
    "                hover_data=umap_df.columns,\n",
    "              )\n",
    "        )\n",
    "        display(Markdown(\"**Figure %d** UMAP plot of %s colored by %s\"%(figure, label, color_by)))\n",
    "    else:\n",
    "        display(\n",
    "            px.scatter(\n",
    "                umap_df,\n",
    "                x=\"UMAP 1\",\n",
    "                y=\"UMAP 2\",\n",
    "                color=color_by,\n",
    "                hover_data=umap_df.columns,\n",
    "              )\n",
    "        )\n",
    "        display(Markdown(\"**Figure %d** UMAP plot of %s\"%(figure, label)))\n",
    "    if not input_meta == \"\" and len(meta_df.columns) > 1:\n",
    "        metadata_plot(umap_df, 'UMAP 1', 'UMAP 2')\n",
    "        figure+=1\n",
    "        display(Markdown(\"**Figure %d** UMAP plot of %s colored by metadata\"%(figure, label)))\n",
    "    return figure + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mimickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction = \"mimickers\"\n",
    "for lib in datasets:\n",
    "    display(Markdown(\"### %s\"%lib))\n",
    "    index = set()\n",
    "    pert_dict = enriched[direction][lib]\n",
    "    for v in pert_dict.values():\n",
    "        index = index.union(v.keys())\n",
    "    df = pd.DataFrame(0, index=index, columns=pert_dict.keys())\n",
    "    for k,v in pert_dict.items():\n",
    "        for pert, cnt in v.items():\n",
    "            df.at[pert, k] += cnt\n",
    "    df = df.loc[df.sum(1).sort_values(ascending=False).index]\n",
    "    filename = \"pert_matrix_%s_%s.tsv\"%(lib.replace(\" \",\"_\"), direction)\n",
    "    df.to_csv(filename, sep=\"\\t\")\n",
    "#     display(df.head())\n",
    "#     display(Markdown(\"**Table %d** Mimicker perturbagens using %s dataset ([download](./%s))\"%\n",
    "#                      (table, lib, filename)))\n",
    "    table += 1\n",
    "    # stat_df = pd.DataFrame(0, index=df.index, columns=[\"count\", \"z-score\", \"p-value\"])\n",
    "    empirical_stat = pd.read_csv(S3_PREFIX + \"%s_%s.tsv\" % (dataset_map[lib], direction), sep=\"\\t\", index_col=0)\n",
    "    df = df[(df>0).sum(1) > len(df.columns) * perc]\n",
    "    index = set(df.index).intersection(empirical_stat.index)\n",
    "    filtered_df = df.loc[index]    \n",
    "    if lib in gene_page:\n",
    "        stat_df = pd.DataFrame(0, index=index, columns=[\"count\", \"z-score\", \"p-value\", \"Enrichr gene page\"])\n",
    "        stat_df['count'] = filtered_df.sum(1)\n",
    "        # Compute zstat and p value\n",
    "        stat_df[\"z-score\"] = (filtered_df.mean(1) - empirical_stat[\"mean\"]) / empirical_stat[\"std\"]\n",
    "        stat_df[\"p-value\"] = stat_df['z-score'].apply(lambda x: 1-st.norm.cdf(x))\n",
    "\n",
    "        #Filter by p-value\n",
    "        stat_df = stat_df[stat_df[\"p-value\"]<alpha].sort_values(by=[\"z-score\"], ascending=False)\n",
    "\n",
    "        stat_df['Enrichr gene page'] = [\"https://maayanlab.cloud/Enrichr/#find!gene=%s\"%i for i in stat_df.index]\n",
    "        filename = \"pert_stat_%s_%s.tsv\"%(lib.replace(\" \",\"_\"), direction)\n",
    "        stat_df.to_csv(filename, sep=\"\\t\")\n",
    "        stat_df['Enrichr gene page'] = stat_df['Enrichr gene page'].apply(make_clickable)\n",
    "        stat_html = stat_df.head(25).to_html(escape=False)\n",
    "        display(HTML(stat_html))\n",
    "    else:\n",
    "        stat_df = pd.DataFrame(0, index=index, columns=[\"count\", \"z-score\", \"p-value\"])\n",
    "        stat_df['count'] = filtered_df.sum(1)\n",
    "        # Compute zstat and p value\n",
    "        stat_df[\"z-score\"] = (filtered_df.mean(1) - empirical_stat[\"mean\"]) / empirical_stat[\"std\"]\n",
    "        stat_df[\"p-value\"] = stat_df['z-score'].apply(lambda x: 1-st.norm.cdf(x))\n",
    "\n",
    "        #Filter by p-value\n",
    "        stat_df = stat_df[stat_df[\"p-value\"]<alpha].sort_values(by=[\"z-score\"], ascending=False)\n",
    "\n",
    "        filename = \"pert_stat_%s_%s.tsv\"%(lib.replace(\" \",\"_\"), direction)\n",
    "        stat_df.to_csv(filename, sep=\"\\t\")\n",
    "        display(stat_df.head(25))\n",
    "    display(Markdown(\"**Table %d** Top 25 mimicker perturbagens using %s dataset ([download](./%s))\"%\n",
    "                     (table, lib, filename)))\n",
    "\n",
    "    table+=1\n",
    "\n",
    "    consensus = df.loc[stat_df.index[0:top_perts]]\n",
    "    #consensus_norm = zscore_normalize(consensus.T).T\n",
    "    consensus_norm = consensus.subtract(empirical_stat.loc[consensus.index, \"mean\"], axis=0).divide(empirical_stat.loc[consensus.index, \"std\"], axis=0)\n",
    "    plot_label = \"%s %s\"%(lib, direction)\n",
    "    figure = get_tsne(consensus_norm, plot_label, figure)\n",
    "    figure = get_umap(consensus_norm, plot_label, figure)\n",
    "    if len(consensus.index) > top_perts:\n",
    "        consensus = consensus.loc[consensus.index[:top_perts]]\n",
    "    filename = \"consensus_matrix_%s_%s.tsv\"%(lib.replace(\" \",\"_\"), direction)\n",
    "    consensus.to_csv(filename, sep=\"\\t\")\n",
    "    display(consensus.head())\n",
    "    display(Markdown(\"**Table %d** Consensus mimicker perturbation matrix for %s ([download](./%s))\"%\n",
    "                     (table, lib, filename)))\n",
    "\n",
    "    table+=1\n",
    "\n",
    "    label = \"Clustergrammer of consensus mimicker perturbation of %s\"%lib\n",
    "    name = \"clustergrammer_%s_%s.tsv\"%(lib.replace(\" \", \"_\"), direction)\n",
    "    figure = clustergrammer(consensus, name, figure, label)\n",
    "\n",
    "    label = \"Heatmap of consensus mimicker perturbation of %s\"%lib\n",
    "    name = \"heatmap_%s_%s.png\"%(lib.replace(\" \", \"_\"), direction)\n",
    "    figure = heatmap(consensus, name, figure, label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reversers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction = \"reversers\"\n",
    "for lib in datasets:\n",
    "    display(Markdown(\"### %s\"%lib))\n",
    "    index = set()\n",
    "    pert_dict = enriched[direction][lib]\n",
    "    for v in pert_dict.values():\n",
    "        index = index.union(v.keys())\n",
    "    df = pd.DataFrame(0, index=index, columns=pert_dict.keys())\n",
    "    for k,v in pert_dict.items():\n",
    "        for pert, cnt in v.items():\n",
    "            df.at[pert, k] += cnt\n",
    "    df = df.loc[df.sum(1).sort_values(ascending=False).index]\n",
    "    filename = \"pert_matrix_%s_%s.tsv\"%(lib.replace(\" \",\"_\"), direction)\n",
    "    df.to_csv(filename, sep=\"\\t\")\n",
    "#     display(df.head())\n",
    "#     display(Markdown(\"**Table %d** Reverser perturbagens using %s dataset ([download](./%s))\"%\n",
    "#                      (table, lib, filename)))\n",
    "    table += 1\n",
    "    # stat_df = pd.DataFrame(0, index=df.index, columns=[\"count\", \"z-score\", \"p-value\"])\n",
    "    empirical_stat = pd.read_csv(S3_PREFIX + \"%s_%s.tsv\" % (dataset_map[lib], direction), sep=\"\\t\", index_col=0)\n",
    "    df = df[(df>0).sum(1) > len(df.columns) * perc]\n",
    "    index = set(df.index).intersection(empirical_stat.index)\n",
    "    filtered_df = df.loc[index]    \n",
    "    if lib in gene_page:\n",
    "        stat_df = pd.DataFrame(0, index=index, columns=[\"count\", \"z-score\", \"p-value\", \"Enrichr gene page\"])\n",
    "        stat_df['count'] = filtered_df.sum(1)\n",
    "        # Compute zstat and p value\n",
    "        stat_df[\"z-score\"] = (filtered_df.mean(1) - empirical_stat[\"mean\"]) / empirical_stat[\"std\"]\n",
    "        stat_df[\"p-value\"] = stat_df['z-score'].apply(lambda x: 1-st.norm.cdf(x))\n",
    "\n",
    "        #Filter by p-value\n",
    "        stat_df = stat_df[stat_df[\"p-value\"]<alpha].sort_values(by=[\"z-score\"], ascending=False)\n",
    "\n",
    "        stat_df['Enrichr gene page'] = [\"https://maayanlab.cloud/Enrichr/#find!gene=%s\"%i for i in stat_df.index]\n",
    "        filename = \"pert_stat_%s_%s.tsv\"%(lib.replace(\" \",\"_\"), direction)\n",
    "        stat_df.to_csv(filename, sep=\"\\t\")\n",
    "        stat_df['Enrichr gene page'] = stat_df['Enrichr gene page'].apply(make_clickable)\n",
    "        stat_html = stat_df.head(25).to_html(escape=False)\n",
    "        display(HTML(stat_html))\n",
    "    else:\n",
    "        stat_df = pd.DataFrame(0, index=index, columns=[\"count\", \"z-score\", \"p-value\"])\n",
    "        stat_df['count'] = filtered_df.sum(1)\n",
    "        # Compute zstat and p value\n",
    "        stat_df[\"z-score\"] = (filtered_df.mean(1) - empirical_stat[\"mean\"]) / empirical_stat[\"std\"]\n",
    "        stat_df[\"p-value\"] = stat_df['z-score'].apply(lambda x: 1-st.norm.cdf(x))\n",
    "\n",
    "        #Filter by p-value\n",
    "        stat_df = stat_df[stat_df[\"p-value\"]<alpha].sort_values(by=[\"z-score\"], ascending=False)\n",
    "\n",
    "        filename = \"pert_stat_%s_%s.tsv\"%(lib.replace(\" \",\"_\"), direction)\n",
    "        stat_df.to_csv(filename, sep=\"\\t\")\n",
    "        display(stat_df.head(25))\n",
    "    display(Markdown(\"**Table %d** Top 25 reverser perturbagens using %s dataset ([download](./%s))\"%\n",
    "                     (table, lib, filename)))\n",
    "\n",
    "    table+=1\n",
    "\n",
    "    consensus = df.loc[stat_df.index[0:top_perts]]\n",
    "    #consensus_norm = zscore_normalize(consensus.T).T\n",
    "    consensus_norm = consensus.subtract(empirical_stat.loc[consensus.index, \"mean\"], axis=0).divide(empirical_stat.loc[consensus.index, \"std\"], axis=0)\n",
    "    plot_label = \"%s %s\"%(lib, direction)\n",
    "    figure = get_tsne(consensus_norm, plot_label, figure)\n",
    "    figure = get_umap(consensus_norm, plot_label, figure)\n",
    "    if len(consensus.index) > top_perts:\n",
    "        consensus = consensus.loc[consensus.index[:top_perts]]\n",
    "    filename = \"consensus_matrix_%s_%s.tsv\"%(lib.replace(\" \",\"_\"), direction)\n",
    "    consensus.to_csv(filename, sep=\"\\t\")\n",
    "    display(consensus.head())\n",
    "    display(Markdown(\"**Table %d** Consensus reverser perturbation matrix for %s ([download](./%s))\"%\n",
    "                     (table, lib, filename)))\n",
    "\n",
    "    table+=1\n",
    "\n",
    "    label = \"Clustergrammer of consensus reverser perturbation of %s\"%lib\n",
    "    name = \"clustergrammer_%s_%s.tsv\"%(lib.replace(\" \", \"_\"), direction)\n",
    "    figure = clustergrammer(consensus, name, figure, label)\n",
    "\n",
    "    label = \"Heatmap of consensus reverser perturbation of %s\"%lib\n",
    "    name = \"heatmap_%s_%s.png\"%(lib.replace(\" \", \"_\"), direction)\n",
    "    figure = heatmap(consensus, name, figure, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-default",
   "language": "python",
   "name": "jupyter-default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
