{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%appyter init\n",
    "from appyter import magic\n",
    "magic.init(lambda _=globals: _())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter hide_code\n",
    "{% do SectionField(\n",
    "    name='PRIMARY',\n",
    "    title='1. Upload your data',\n",
    "    subtitle='Upload up and down gene-sets to perform two-sided rank enrichment. '+\n",
    "             'Upload up- or down-only gene-sets to perform rank analysis for that direction. '+\n",
    "             'Metadata should be a tab-separated file where the rows are the signatures and the '+\n",
    "             'columns, the metadata fields. Scatter plots are colored by the second column of the metadata '+\n",
    "             'matrix by default.',\n",
    "    img='file-upload.png'\n",
    ") %}\n",
    "{% do SectionField(\n",
    "    name='ENRICHMENT',\n",
    "    title='2. Choose libraries for enrichment',\n",
    "    subtitle='Select the libraries that would be used for consensus analysis, as well as the Enrichr and '+\n",
    "             'Drugmonizome libraries to use for enriching the consensus perturbagens.',\n",
    "    img='find-replace.png'\n",
    "    \n",
    ") %}\n",
    "{% do SectionField(\n",
    "    name='PARAMETER',\n",
    "    title='3. Tweak the parameters',\n",
    "    subtitle='Modify the parameters to suit the needs of your analysis.',\n",
    "    img='hammer-screwdriver.png'\n",
    ") %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "\n",
    "{% set title = StringField(\n",
    "    name='title',\n",
    "    label='Notebook Name',\n",
    "    default='LDP3 Consensus Perturbagens',\n",
    "    section=\"PRIMARY\",\n",
    ") %}\n",
    "\n",
    "# {{ title.raw_value }}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LINCS Data Portal 3.0 (LDP 3.0) hosts ranked L1000 [1] perturbation signatures from a variety of perturbation types including: drugs and other small molecules, CRISPR knockouts, shRNA knockdowns, and single overexpression. LDP 3.0's RESTful APIs enable querying the signatures programmatically to identify mimickers or reversers for input up and down gene sets. This appyter extends this functionality by enabling analysis for a collection of input signatures to identify consistently reoccuring mimickers and reversers. The appyter takes as input a set of two-sided or one-sided gene sets and constructs a count matrix of mimicking and reversing perturbagens. From this matrix the appyter computzs the consensus. The pipeline also includes (1) Clustergrammer [2] interactive heatmap, and (2) enrichment analysis of the top gene perturbations [3-6] to elucidate the pathways that are being targeted by the consensus perturbagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import scipy.stats as st\n",
    "from IPython.display import display, IFrame, Markdown, HTML\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from umap import UMAP\n",
    "from sklearn.manifold import TSNE\n",
    "from maayanlab_bioinformatics.normalization import quantile_normalize, zscore_normalize\n",
    "from maayanlab_bioinformatics.harmonization import ncbi_genes_lookup\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from matplotlib.ticker import MaxNLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METADATA_API = \"https://ldp3.cloud/metadata-api\"\n",
    "DATA_API = \"https://ldp3.cloud/data-api/api/v1\"\n",
    "CLUSTERGRAMMER_URL = 'https://maayanlab.cloud/clustergrammer/matrix_upload/'\n",
    "S3_PREFIX = \"https://appyters.maayanlab.cloud/storage/LDP3Consensus/\"\n",
    "drugmonizome_meta_api = \"https://maayanlab.cloud/drugmonizome/metadata-api\"\n",
    "drugmonizome_data_api = \"https://maayanlab.cloud/drugmonizome/data-api/api/v1\"\n",
    "enrichr_api = 'https://maayanlab.cloud/Enrichr/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = 1\n",
    "figure = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "{% set up_gene_sets = FileField(\n",
    "    name='up_gene_sets',\n",
    "    label='Up Gene-sets',\n",
    "    default='covid19_up.gmt',\n",
    "    section=\"PRIMARY\",\n",
    "    examples={\n",
    "        'covid19_up.gmt': 'https://appyters.maayanlab.cloud/storage/LDP3Consensus/covid19_up.gmt'\n",
    "    }\n",
    ") %}\n",
    "\n",
    "{% set down_gene_sets = FileField(\n",
    "    name='down_gene_sets',\n",
    "    label='Down Gene-sets',\n",
    "    default='covid19_down.gmt',\n",
    "    section=\"PRIMARY\",\n",
    "    examples={\n",
    "        'covid19_down.gmt': 'https://appyters.maayanlab.cloud/storage/LDP3Consensus/covid19_down.gmt'\n",
    "    }\n",
    ") %}\n",
    "\n",
    "{% set input_meta = FileField(\n",
    "    name='input_meta',\n",
    "    label='Metadata File',\n",
    "    default='covid19_meta.tsv',\n",
    "    section=\"PRIMARY\",\n",
    "    examples={\n",
    "        'covid19_meta.tsv': 'https://appyters.maayanlab.cloud/storage/LDP3Consensus/covid19_meta.tsv',\n",
    "    }\n",
    ") %}\n",
    "{% set color_by =  StringField(name='group_by', label='Color By', description=\"Group By Metadata\", default='', section='PRIMARY')%}\n",
    "\n",
    "\n",
    "up_gene_sets = {{ up_gene_sets }}\n",
    "down_gene_sets = {{ down_gene_sets }}\n",
    "input_meta = {{ input_meta }}\n",
    "color_by = {{ color_by }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_set_direction = None\n",
    "if up_gene_sets == '':\n",
    "    gene_set_direction = \"down\"\n",
    "    print(\"Up gene-sets was not uploaded. Gene-set direction is set to down.\")\n",
    "elif down_gene_sets == '':\n",
    "    gene_set_direction = \"up\"\n",
    "    print(\"Down gene-sets was not uploaded. Gene-set direction is set to up.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "datasets = {{ MultiChoiceField(name='datasets',\n",
    "                                label='LINCS Datasets',\n",
    "                                description='Select the LINCS datasets to use for the consensus analysis',\n",
    "                                default=[\n",
    "                                    \"LINCS L1000 CRISPR Perturbations (2021)\",\n",
    "                                    \"LINCS L1000 Chemical Perturbations (2021)\",\n",
    "                                ],\n",
    "                                section = 'ENRICHMENT',\n",
    "                                choices=[\n",
    "                                    \"LINCS L1000 Antibody Perturbations (2021)\",\n",
    "                                    \"LINCS L1000 Ligand Perturbations (2021)\",\n",
    "                                    \"LINCS L1000 Overexpression Perturbations (2021)\",\n",
    "                                    \"LINCS L1000 CRISPR Perturbations (2021)\",\n",
    "                                    \"LINCS L1000 shRNA Perturbations (2021)\",\n",
    "                                    \"LINCS L1000 Chemical Perturbations (2021)\",\n",
    "                                    \"LINCS L1000 siRNA Perturbations (2021)\",\n",
    "                                ]\n",
    "                              )                           \n",
    "}}\n",
    "\n",
    "drugmonizome_datasets = {{ MultiChoiceField(name='drugmonizome_datasets',\n",
    "                                description='Select the Drugmonizome libraries to use for the enrichment analysis of the consensus drugs',\n",
    "                                label='Drugmonizome Libraries',\n",
    "                                default=[\"L1000FWD_GO_Biological_Processes_drugsetlibrary_up\", \"L1000FWD_GO_Biological_Processes_drugsetlibrary_down\"],\n",
    "                                section = 'ENRICHMENT',\n",
    "                                choices=[\n",
    "                                    \"KinomeScan_kinase_drugsetlibrary\",\n",
    "                                    \"L1000FWD_GO_Cellular_Component_drugsetlibrary_up\",\n",
    "                                    \"L1000FWD_KEGG_Pathways_drugsetlibrary_down\",\n",
    "                                    \"L1000FWD_signature_drugsetlibrary_up\",\n",
    "                                    \"Geneshot_associated_drugsetlibrary\",\n",
    "                                    \"Geneshot_predicted_generif_drugsetlibrary\",\n",
    "                                    \"SIDER_indications_drugsetlibrary\",\n",
    "                                    \"L1000FWD_GO_Molecular_Function_drugsetlibrary_up\",\n",
    "                                    \"L1000FWD_GO_Molecular_Function_drugsetlibrary_down\",\n",
    "                                    \"L1000FWD_KEGG_Pathways_drugsetlibrary_up\",\n",
    "                                    \"SIDER_side_effects_drugsetlibrary\",\n",
    "                                    \"DrugRepurposingHub_target_drugsetlibrary\",\n",
    "                                    \"L1000FWD_GO_Biological_Processes_drugsetlibrary_down\",\n",
    "                                    \"L1000FWD_GO_Biological_Processes_drugsetlibrary_up\",\n",
    "                                    \"L1000FWD_GO_Cellular_Component_drugsetlibrary_down\",\n",
    "                                    \"ATC_drugsetlibrary\",\n",
    "                                    \"Drugbank_smallmolecule_target_drugsetlibrary\",\n",
    "                                    \"STITCH_target_drugsetlibrary\",\n",
    "                                    \"Geneshot_predicted_autorif_drugsetlibrary\",\n",
    "                                    \"Drugbank_smallmolecule_enzyme_drugsetlibrary\",\n",
    "                                    \"PharmGKB_OFFSIDES_side_effects_drugsetlibrary\",\n",
    "                                    \"CREEDS_signature_drugsetlibrary_down\",\n",
    "                                    \"Geneshot_predicted_tagger_drugsetlibrary\",\n",
    "                                    \"RDKIT_maccs_fingerprints_drugsetlibrary\",\n",
    "                                    \"CREEDS_signature_drugsetlibrary_up\",\n",
    "                                    \"DrugCentral_target_drugsetlibrary\",\n",
    "                                    \"L1000FWD_signature_drugsetlibrary_down\",\n",
    "                                    \"L1000FWD_predicted_side_effects\",\n",
    "                                    \"Drugbank_smallmolecule_carrier_drugsetlibrary\",\n",
    "                                    \"PubChem_fingerprints_drugsetlibrary\",\n",
    "                                    \"Geneshot_predicted_enrichr_drugsetlibrary\",\n",
    "                                    \"DrugRepurposingHub_moa_drugsetlibrary\",\n",
    "                                    \"Geneshot_predicted_coexpression_drugsetlibrary\",\n",
    "                                    \"Drugbank_smallmolecule_transporter_drugsetlibrary\",\n",
    "                                    \"PharmGKB_snp_drugsetlibrary\"\n",
    "                                ]\n",
    "                              )                           \n",
    "}}\n",
    "\n",
    "transcription_libraries = {{ MultiChoiceField(name='transcription_libraries', \n",
    "                                            description='Select the Enrichr libraries to use for the enrichment of the consensus genes.',\n",
    "                                              label='Enrichr Transcription Libraries', \n",
    "                                              default=[], \n",
    "                                              section = 'ENRICHMENT',\n",
    "                                              choices=[\n",
    "                                                'ARCHS4_TFs_Coexp',\n",
    "                                                'ChEA_2016',\n",
    "                                                'ENCODE_and_ChEA_Consensus_TFs_from_ChIP-X',\n",
    "                                                'ENCODE_Histone_Modifications_2015',\n",
    "                                                'ENCODE_TF_ChIP-seq_2015',\n",
    "                                                'Epigenomics_Roadmap_HM_ChIP-seq',\n",
    "                                                'Enrichr_Submissions_TF-Gene_Coocurrence',\n",
    "                                                'Genome_Browser_PWMs',\n",
    "                                                'lncHUB_lncRNA_Co-Expression',\n",
    "                                                'miRTarBase_2017',\n",
    "                                                'TargetScan_microRNA_2017',\n",
    "                                                'TF-LOF_Expression_from_GEO',\n",
    "                                                'TF_Perturbations_Followed_by_Expression',\n",
    "                                                'Transcription_Factor_PPIs',\n",
    "                                                'TRANSFAC_and_JASPAR_PWMs',\n",
    "                                                'TRRUST_Transcription_Factors_2019']) \n",
    "                           }}\n",
    "\n",
    "\n",
    "pathways_libraries = {{ MultiChoiceField(name='pathways_libraries',\n",
    "                                         description='Select the Enrichr libraries to use for the enrichment of the consensus genes.',\n",
    "                                         label='Enrichr Pathway Libraries',\n",
    "                                         default=[],\n",
    "                                         section = 'ENRICHMENT',\n",
    "                                         choices=[\n",
    "                                            'ARCHS4_Kinases_Coexp',\n",
    "                                            'BioCarta_2016',\n",
    "                                            'BioPlanet_2019',\n",
    "                                            'BioPlex_2017',\n",
    "                                            'CORUM',\n",
    "                                            'Elsevier_Pathway_Collection',\n",
    "                                            'HMS_LINCS_KinomeScan',\n",
    "                                            'HumanCyc_2016',\n",
    "                                            'huMAP',\n",
    "                                            'KEA_2015',\n",
    "                                            'KEGG_2019_Human',\n",
    "                                            'KEGG_2019_Mouse',\n",
    "                                            'Kinase_Perturbations_from_GEO_down',\n",
    "                                            'Kinase_Perturbations_from_GEO_up',\n",
    "                                            'L1000_Kinase_and_GPCR_Perturbations_down',\n",
    "                                            'L1000_Kinase_and_GPCR_Perturbations_up',\n",
    "                                            'NCI-Nature_2016',\n",
    "                                            'NURSA_Human_Endogenous_Complexome',\n",
    "                                            'Panther_2016',\n",
    "                                            'Phosphatase_Substrates_from_DEPOD',\n",
    "                                            'PPI_Hub_Proteins',\n",
    "                                            'Reactome_2016',\n",
    "                                            'SILAC_Phosphoproteomics',\n",
    "                                            'SubCell_BarCode',\n",
    "                                            'Virus-Host_PPI_P-HIPSTer_2020',\n",
    "                                            'WikiPathways_2019_Human',\n",
    "                                            'WikiPathways_2019_Mouse']) \n",
    "                      }}    \n",
    "    \n",
    "  \n",
    "ontologies_libraries = {{ MultiChoiceField(name='ontologies_libraries', \n",
    "                                           description='Select the Enrichr libraries to use for the enrichment of the consensus genes.',\n",
    "                                           label='Enrichr Ontology Libraries',\n",
    "                                           default=['GO_Biological_Process_2018'],\n",
    "                                           section = 'ENRICHMENT',\n",
    "                                           choices=[\n",
    "                                            'GO_Biological_Process_2018',\n",
    "                                            'GO_Cellular_Component_2018',\n",
    "                                            'GO_Molecular_Function_2018',\n",
    "                                            'Human_Phenotype_Ontology',\n",
    "                                            'Jensen_COMPARTMENTS',\n",
    "                                            'Jensen_DISEASES',\n",
    "                                            'Jensen_TISSUES',\n",
    "                                            'MGI_Mammalian_Phenotype_Level_4_2019']) \n",
    "                        }} \n",
    "\n",
    "    \n",
    "diseases_drugs_libraries = {{ MultiChoiceField(name='diseases_drugs_libraries',\n",
    "                                               description='Select the Enrichr libraries to use for the enrichment of the consensus genes.',\n",
    "                                               label='Enrichr Disease/Drug Libraries',\n",
    "                                               default=[],\n",
    "                                               section = 'ENRICHMENT',\n",
    "                                               choices=[    \n",
    "                                                    'Achilles_fitness_decrease',\n",
    "                                                    'Achilles_fitness_increase',\n",
    "                                                    'ARCHS4_IDG_Coexp',\n",
    "                                                    'ClinVar_2019',\n",
    "                                                    'dbGaP',\n",
    "                                                    'DepMap_WG_CRISPR_Screens_Broad_CellLines_2019',\n",
    "                                                    'DepMap_WG_CRISPR_Screens_Sanger_CellLines_2019',\n",
    "                                                    'DisGeNET',\n",
    "                                                    'DrugMatrix',\n",
    "                                                    'DSigDB',\n",
    "                                                    'GeneSigDB',\n",
    "                                                    'GWAS_Catalog_2019',\n",
    "                                                    'LINCS_L1000_Chem_Pert_down',\n",
    "                                                    'LINCS_L1000_Chem_Pert_up',\n",
    "                                                    'LINCS_L1000_Ligand_Perturbations_down',\n",
    "                                                    'LINCS_L1000_Ligand_Perturbations_up',\n",
    "                                                    'MSigDB_Computational',\n",
    "                                                    'MSigDB_Oncogenic_Signatures',\n",
    "                                                    'Old_CMAP_down',\n",
    "                                                    'Old_CMAP_up',\n",
    "                                                    'OMIM_Disease',\n",
    "                                                    'OMIM_Expanded',\n",
    "                                                    'PheWeb_2019',\n",
    "                                                    'Rare_Diseases_AutoRIF_ARCHS4_Predictions',\n",
    "                                                    'Rare_Diseases_AutoRIF_Gene_Lists',\n",
    "                                                    'Rare_Diseases_GeneRIF_ARCHS4_Predictions',\n",
    "                                                    'Rare_Diseases_GeneRIF_Gene_Lists',\n",
    "                                                    'UK_Biobank_GWAS_v1',\n",
    "                                                    'Virus_Perturbations_from_GEO_down',\n",
    "                                                    'Virus_Perturbations_from_GEO_up',\n",
    "                                                    'VirusMINT']) \n",
    "                            }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "alpha = {{FloatField(name='alpha', label='p-value cutoff', default=0.05, section='PARAMETER')}}\n",
    "perc = {{FloatField(name='perc',\n",
    "                         label='percentage',\n",
    "                         description='Minimum percentage cutoff for perturbagen instances in signatures',\n",
    "                         default=0.1, section='PARAMETER')}}\n",
    "top_perts = {{IntField(name='top_perts', label='top perturbation', default=50, section='PARAMETER')}}\n",
    "consensus_method = {{ ChoiceField(\n",
    "  name='consensus_method',\n",
    "  label='consensus method',\n",
    "  description='Please select a method for getting the consensus',\n",
    "  default='zscore',\n",
    "  choices={\n",
    "    'zscore': \"'zscore'\",\n",
    "    'top count': \"'count'\",\n",
    "  },\n",
    "  section='PARAMETER') }}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gene Harmonization\n",
    "To ensure that the gene names are consistent throughout the analysis, the input gene sets are harmonized to NCBI Gene symbols [7-8] using an [in-house gene harmonization module](https://github.com/MaayanLab/maayanlab-bioinformatics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncbi_lookup = ncbi_genes_lookup('Mammalia/Homo_sapiens')\n",
    "print('Loaded NCBI genes!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signatures = {}\n",
    "if not up_gene_sets == '':\n",
    "    with open(up_gene_sets) as upfile:\n",
    "        for line in upfile:\n",
    "            unpacked = line.strip().split(\"\\t\")\n",
    "            if len(unpacked) < 3:\n",
    "                raise ValueError(\"GMT is not formatted properly, please consult the README of the appyter for proper formatting\")\n",
    "            sigid = unpacked[0]\n",
    "            geneset = unpacked[2:]\n",
    "            genes = []\n",
    "            for i in geneset:\n",
    "                gene = i.split(\",\")[0]\n",
    "                gene_name = ncbi_lookup(gene.upper())\n",
    "                if gene_name:\n",
    "                    genes.append(gene_name)\n",
    "            signatures[sigid] = {\n",
    "                \"up_genes\": genes,\n",
    "                \"down_genes\": []\n",
    "            }\n",
    "if not down_gene_sets == '':\n",
    "    with open(down_gene_sets) as downfile:\n",
    "        for line in downfile:\n",
    "            unpacked = line.strip().split(\"\\t\")\n",
    "            if len(unpacked) < 3:\n",
    "                raise ValueError(\"GMT is not formatted properly, please consult the README of the appyter for proper formatting\")\n",
    "            sigid = unpacked[0]\n",
    "            geneset = unpacked[2:]\n",
    "            if sigid not in signatures and gene_set_direction == None:\n",
    "                raise ValueError(\"%s did not match any of the up signatures, make sure that the signature names are the same for both up and down genes\"%sigid)\n",
    "            else:\n",
    "                genes = []\n",
    "                for i in geneset:\n",
    "                    gene = i.split(\",\")[0]\n",
    "                    gene_name = ncbi_lookup(gene)\n",
    "                    if gene_name:\n",
    "                        genes.append(gene_name)\n",
    "                if sigid in signatures:\n",
    "                    signatures[sigid][\"down_genes\"] = genes\n",
    "                else:\n",
    "                    signatures[sigid] = {\n",
    "                        \"up_genes\": [],\n",
    "                        \"down_genes\": genes\n",
    "                    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Signatures Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = pd.read_csv(input_meta, sep=\"\\t\", index_col=0)\n",
    "display(meta_df.head(10))\n",
    "display(Markdown(\"**Table %d** 1 Input Signatures Metadata. This table shows the metadata associated with the input up and down gene sets.\"%table))\n",
    "table+=1\n",
    "if color_by == \"\":\n",
    "    color_by = meta_df.columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrichr_libraries = transcription_libraries + pathways_libraries + ontologies_libraries + diseases_drugs_libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_map = {\n",
    "  \"LINCS L1000 Antibody Perturbations (2021)\": \"l1000_aby\",\n",
    "  \"LINCS L1000 Ligand Perturbations (2021)\": \"l1000_lig\",\n",
    "  \"LINCS L1000 Overexpression Perturbations (2021)\": \"l1000_oe\",\n",
    "  \"LINCS L1000 CRISPR Perturbations (2021)\": \"l1000_xpr\",\n",
    "  \"LINCS L1000 shRNA Perturbations (2021)\": \"l1000_shRNA\",\n",
    "  \"LINCS L1000 Chemical Perturbations (2021)\": \"l1000_cp\",\n",
    "  \"LINCS L1000 siRNA Perturbations (2021)\": \"l1000_siRNA\"\n",
    "}\n",
    "\n",
    "labeller = {\n",
    "  \"LINCS L1000 Antibody Perturbations (2021)\": \"antibody\",\n",
    "  \"LINCS L1000 Ligand Perturbations (2021)\": \"ligand\",\n",
    "  \"LINCS L1000 Overexpression Perturbations (2021)\": \"overexpression\",\n",
    "  \"LINCS L1000 CRISPR Perturbations (2021)\": \"CRISPR\",\n",
    "  \"LINCS L1000 shRNA Perturbations (2021)\": \"shRNA\",\n",
    "  \"LINCS L1000 Chemical Perturbations (2021)\": \"chemical\",\n",
    "  \"LINCS L1000 siRNA Perturbations (2021)\": \"siRNA\"\n",
    "}\n",
    "\n",
    "gene_page = {\n",
    "  \"LINCS L1000 Ligand Perturbations (2021)\",\n",
    "  \"LINCS L1000 Overexpression Perturbations (2021)\",\n",
    "  \"LINCS L1000 CRISPR Perturbations (2021)\",\n",
    "  \"LINCS L1000 shRNA Perturbations (2021)\",\n",
    "  \"LINCS L1000 siRNA Perturbations (2021)\"\n",
    "}\n",
    "\n",
    "drug_page = {\n",
    "  \"LINCS L1000 Chemical Perturbations (2021)\": \"l1000_cp\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDP 3.0 Signature Search\n",
    "LDP 3.0 provides RESTful APIs to perform rank enrichment analysis on two-sided (up and down) gene-sets or one-sided (up-only, down-only) gene sets. This returns mimicking and reversing signatures which the appyter converts to perturbagen counts for each input signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def convert_genes(up_genes=[], down_genes=[]):\n",
    "    try:\n",
    "        payload = {\n",
    "           \"filter\": {\n",
    "               \"where\": {\n",
    "                   \"meta.symbol\": {\"inq\": up_genes + down_genes}\n",
    "               }\n",
    "           }\n",
    "        }\n",
    "        timeout = 0.5\n",
    "        for i in range(5):\n",
    "            res = requests.post(METADATA_API + \"/entities/find\", json=payload)\n",
    "            if res.ok:\n",
    "                break\n",
    "            else:\n",
    "                time.sleep(timeout)\n",
    "                if res.status_code >= 500:\n",
    "                    timeout = timeout * 2\n",
    "        else:\n",
    "            raise Exception(res.text)\n",
    "        results = res.json()\n",
    "        up = set(up_genes)\n",
    "        down = set(down_genes)\n",
    "        if len(up_genes) == 0 or len(down_genes) == 0:\n",
    "            converted = {\n",
    "                \"entities\": [],\n",
    "            }\n",
    "        else:\n",
    "            converted = {\n",
    "                \"up_entities\": [],\n",
    "                \"down_entities\": []\n",
    "            }\n",
    "        for i in results:\n",
    "            symbol = i[\"meta\"][\"symbol\"]\n",
    "            if \"entities\" in converted:\n",
    "                converted[\"entities\"].append(i[\"id\"])\n",
    "            elif symbol in up:\n",
    "                converted[\"up_entities\"].append(i[\"id\"])\n",
    "            elif symbol in down:\n",
    "                converted[\"down_entities\"].append(i[\"id\"])\n",
    "        return converted\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "def signature_search(genes, library):\n",
    "    try:\n",
    "        payload = {\n",
    "            **genes,\n",
    "            \"database\": library,\n",
    "            \"limit\": 1000\n",
    "        }\n",
    "        timeout = 0.5\n",
    "        for i in range(5):\n",
    "            endpoint = \"/enrich/rank\" if \"entities\" in payload else \"/enrich/ranktwosided\"\n",
    "            res = requests.post(DATA_API + endpoint, json=payload)\n",
    "            if res.ok:\n",
    "                break\n",
    "            else:\n",
    "                time.sleep(timeout)\n",
    "                if res.status_code >= 500:\n",
    "                    timeout = timeout * 2\n",
    "        else:\n",
    "            raise Exception(res.text)\n",
    "        \n",
    "        return res.json()[\"results\"]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "def resolve_rank(s, gene_set_direction):\n",
    "    try:\n",
    "        sigs = {}\n",
    "        for i in s:\n",
    "            if i[\"p-value\"] < 0.05:\n",
    "                uid = i[\"uuid\"]\n",
    "                direction = \"up\" if i[\"zscore\"] > 0 else \"down\"\n",
    "                if direction == gene_set_direction:\n",
    "                    i[\"type\"] = \"mimicker\"\n",
    "                    sigs[uid] = i\n",
    "                else:\n",
    "                    i[\"type\"] = \"reverser\"\n",
    "                    sigs[uid] = i\n",
    "            \n",
    "        payload = {\n",
    "            \"filter\": {\n",
    "                \"where\": {\n",
    "                    \"id\": {\"inq\": list(sigs.keys())}\n",
    "                },\n",
    "                \"fields\": [\n",
    "                    \"id\",\n",
    "                    \"meta.pert_name\",\n",
    "                    \"meta.pert_type\"\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "        timeout = 0.5\n",
    "        for i in range(5):\n",
    "            res = requests.post(METADATA_API + \"/signatures/find\", json=payload)\n",
    "            if res.ok:\n",
    "                break\n",
    "            else:\n",
    "                time.sleep(timeout)\n",
    "                if res.status_code >= 500:\n",
    "                    timeout = timeout * 2\n",
    "        else:\n",
    "            raise Exception(res.text)\n",
    "        results = res.json()\n",
    "        perturbagens = {\n",
    "            \"mimickers\": {},\n",
    "            \"reversers\": {}\n",
    "        }\n",
    "        for sig in results:\n",
    "            uid = sig[\"id\"]\n",
    "            scores = sigs[uid]\n",
    "            sig[\"scores\"] = scores\n",
    "            if \"pert_name\" in sig[\"meta\"]:\n",
    "                pert_name = sig[\"meta\"][\"pert_name\"]\n",
    "                if scores[\"type\"] == \"mimicker\":\n",
    "                    if pert_name not in perturbagens[\"mimickers\"]:\n",
    "                        perturbagens[\"mimickers\"][pert_name] = 0\n",
    "                    perturbagens[\"mimickers\"][pert_name] += 1\n",
    "                elif scores[\"type\"] == \"reverser\":\n",
    "                    if pert_name not in perturbagens[\"reversers\"]:\n",
    "                        perturbagens[\"reversers\"][pert_name] = 0\n",
    "                    perturbagens[\"reversers\"][pert_name] += 1\n",
    "        return perturbagens\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "def resolve_ranktwosided(s):\n",
    "    try:\n",
    "        sigs = {}\n",
    "        for i in s:\n",
    "            if i['p-down'] < 0.05 and i['p-up'] < 0.05:\n",
    "                uid = i[\"uuid\"]\n",
    "                i['z-down'] = -i['z-down']\n",
    "                i['direction-down'] = -i['direction-down']\n",
    "                if i['z-up'] > 0 and i['z-down'] > 0:\n",
    "                    i[\"type\"] = \"mimicker\"\n",
    "                    sigs[uid] = i\n",
    "                elif i['z-up'] < 0 and i['z-down'] < 0:\n",
    "                    i[\"type\"] = \"reverser\"\n",
    "                    sigs[uid] = i\n",
    "            \n",
    "        payload = {\n",
    "            \"filter\": {\n",
    "                \"where\": {\n",
    "                    \"id\": {\"inq\": list(sigs.keys())}\n",
    "                },\n",
    "                \"fields\": [\n",
    "                    \"id\",\n",
    "                    \"meta.pert_name\",\n",
    "                    \"meta.pert_type\"\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "        timeout = 0.5\n",
    "        for i in range(5):\n",
    "            res = requests.post(METADATA_API + \"/signatures/find\", json=payload)\n",
    "            if res.ok:\n",
    "                break\n",
    "            else:\n",
    "                time.sleep(timeout)\n",
    "                if res.status_code >= 500:\n",
    "                    timeout = timeout * 2\n",
    "        else:\n",
    "            raise Exception(res.text)\n",
    "        results = res.json()\n",
    "        perturbagens = {\n",
    "            \"mimickers\": {},\n",
    "            \"reversers\": {}\n",
    "        }\n",
    "        for sig in results:\n",
    "            uid = sig[\"id\"]\n",
    "            scores = sigs[uid]\n",
    "            sig[\"scores\"] = scores\n",
    "            if \"pert_name\" in sig[\"meta\"]:\n",
    "                pert_name = sig[\"meta\"][\"pert_name\"]\n",
    "                if scores[\"type\"] == \"mimicker\":\n",
    "                    if pert_name not in perturbagens[\"mimickers\"]:\n",
    "                        perturbagens[\"mimickers\"][pert_name] = 0\n",
    "                    perturbagens[\"mimickers\"][pert_name] += 1\n",
    "                elif scores[\"type\"] == \"reverser\":\n",
    "                    if pert_name not in perturbagens[\"reversers\"]:\n",
    "                        perturbagens[\"reversers\"][pert_name] = 0\n",
    "                    perturbagens[\"reversers\"][pert_name] += 1\n",
    "        return perturbagens\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enriched = {lib:{\"mimickers\": {}, \"reversers\": {}} for lib in datasets}\n",
    "enriched = {\"mimickers\": {lib: {} for lib in datasets}, \"reversers\": {lib: {} for lib in datasets}}\n",
    "\n",
    "for k,sig in tqdm(signatures.items()):    \n",
    "    try:\n",
    "        time.sleep(0.1)\n",
    "        genes = convert_genes(sig[\"up_genes\"],sig[\"down_genes\"])\n",
    "        if (\"entities\" in genes and len(genes[\"entities\"]) > 5) or (len(genes[\"up_entities\"]) > 5 and len(genes[\"down_entities\"]) > 5):\n",
    "            for lib in datasets:\n",
    "                library = dataset_map[lib]\n",
    "                s = signature_search(genes, library)\n",
    "                if gene_set_direction == None:\n",
    "                    perturbagens = resolve_ranktwosided(s)\n",
    "                else:\n",
    "                    perturbagens = resolve_rank(s, gene_set_direction)\n",
    "                enriched[\"mimickers\"][lib][k] = perturbagens[\"mimickers\"]\n",
    "                enriched[\"reversers\"][lib][k] = perturbagens[\"reversers\"]\n",
    "                time.sleep(0.1)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustergrammer(df, name, figure, label=\"Clustergrammer\"):\n",
    "    clustergram_df = df.rename(columns={i:\"Signature: %s\"%i for i in df.columns}, index={i:\"Drug: %s\"%i for i in df.index})\n",
    "    clustergram_df.to_csv(name, sep=\"\\t\")\n",
    "    response = ''\n",
    "    timeout = 0.5\n",
    "    for i in range(5):\n",
    "        try:\n",
    "            res = requests.post(CLUSTERGRAMMER_URL, files={'file': open(name, 'rb')})\n",
    "            if not res.ok:\n",
    "                response = res.text\n",
    "                time.sleep(timeout)\n",
    "                if res.status_code >= 500:\n",
    "                    timeout = timeout * 2\n",
    "            else:\n",
    "                clustergrammer_url = res.text.replace(\"http:\",\"https:\")   \n",
    "                break\n",
    "        except Exception as e:\n",
    "            response = e\n",
    "            time.sleep(2)\n",
    "    else:\n",
    "        if type(response) == Exception:\n",
    "            raise response\n",
    "        else:\n",
    "            raise Exception(response)\n",
    "    display(IFrame(clustergrammer_url, width=\"1000\", height=\"1000\"))\n",
    "    display(Markdown(\"**Figure %d** %s [Go to url](%s)\"%(figure, label, clustergrammer_url)))\n",
    "    figure += 1\n",
    "    return figure\n",
    "\n",
    "cmap = sns.cubehelix_palette(50, hue=0.05, rot=0, light=1, dark=0)\n",
    "\n",
    "def heatmap(df, filename, figure, label, width=15, height=15):\n",
    "    fig = plt.figure(figsize=(width,height))\n",
    "    cg = sns.clustermap(df, cmap=cmap, figsize=(width, height))\n",
    "    cg.ax_row_dendrogram.set_visible(False)\n",
    "    cg.ax_col_dendrogram.set_visible(False)\n",
    "    display(cg)\n",
    "    plt.show()\n",
    "    cg.savefig(filename)\n",
    "    display(Markdown(\"**Figure %d** %s\"%(figure, label)))\n",
    "    figure+=1\n",
    "    return figure\n",
    "\n",
    "def make_clickable(link):\n",
    "    # target _blank to open new window\n",
    "    # extract clickable text to display for your link\n",
    "    text = link.split('=')[1]\n",
    "    return f'<a target=\"_blank\" href=\"{link}\">{text}</a>'\n",
    "\n",
    "\n",
    "annot_dict = {}\n",
    "def bar_chart(enrichment, title=''):\n",
    "    bar_color = 'mediumspringgreen'\n",
    "    bar_color_not_sig = 'lightgrey'\n",
    "    edgecolor=None\n",
    "    linewidth=0\n",
    "    if len(enrichment) > 10:\n",
    "        enrichment = enrichment[0:10]\n",
    "    enrichment_names = [i[\"name\"] for i in enrichment]\n",
    "    enrichment_scores = [i[\"pval\"] for i in enrichment]\n",
    "    plt.figure(figsize=(10,4))\n",
    "    bar_colors = [bar_color if (x < 0.05) else bar_color_not_sig for x in enrichment_scores]\n",
    "    fig = sns.barplot(x=np.log10(enrichment_scores)*-1, y=enrichment_names, palette=bar_colors, edgecolor=edgecolor, linewidth=linewidth)\n",
    "    fig.axes.get_yaxis().set_visible(False)\n",
    "    fig.set_title(title.replace('_',' '),fontsize=20)\n",
    "    fig.set_xlabel('-Log10(p-value)',fontsize=19)\n",
    "    fig.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    fig.tick_params(axis='x', which='major', labelsize=20)\n",
    "    if max(np.log10(enrichment_scores)*-1)<1:\n",
    "        fig.xaxis.set_ticks(np.arange(0, max(np.log10(enrichment_scores)*-1), 0.1))\n",
    "    for ii,annot in enumerate(enrichment_names):\n",
    "        if annot in annot_dict.keys():\n",
    "            annot = annot_dict[annot]\n",
    "        if enrichment_scores[ii] < 0.05:\n",
    "            annot = '  *'.join([annot, str(str(np.format_float_scientific(enrichment_scores[ii],precision=2)))]) \n",
    "        else:\n",
    "            annot = '  '.join([annot, str(str(np.format_float_scientific(enrichment_scores[ii],precision=2)))])\n",
    "\n",
    "        title_start= max(fig.axes.get_xlim())/200\n",
    "        fig.text(title_start,ii,annot,ha='left',wrap = True, fontsize = 12)\n",
    "        fig.patch.set_edgecolor('black')  \n",
    "        fig.patch.set_linewidth('2')\n",
    "    plt.show()\n",
    "        \n",
    "\n",
    "def get_drugmonizome_plot(consensus, label, figure, dataset):\n",
    "    payload = {\n",
    "        \"filter\":{\n",
    "            \"where\": {\n",
    "                \"meta.Name\": {\n",
    "                    \"inq\": [i.lower() for i in consensus.index]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    res = requests.post(drugmonizome_meta_api + \"/entities/find\", json=payload)\n",
    "\n",
    "    entities = {}\n",
    "    for i in res.json():\n",
    "        name = i[\"meta\"][\"Name\"]\n",
    "        uid = i[\"id\"]\n",
    "        if name not in entities:\n",
    "            entities[name] = uid\n",
    "            \n",
    "    query = {\n",
    "        \"entities\": list(entities.values()),\n",
    "        \"limit\": 1000,\n",
    "        \"database\": dataset\n",
    "    }\n",
    "\n",
    "    res = requests.post(drugmonizome_data_api + \"/enrich/overlap\", json=query)\n",
    "\n",
    "    scores = res.json()[\"results\"]\n",
    "    uids = {i[\"uuid\"]: i for i in scores}\n",
    "\n",
    "    payload = {\n",
    "        \"filter\":{\n",
    "            \"where\": {\n",
    "                \"id\": {\n",
    "                    \"inq\": list(uids.keys())\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    res = requests.post(drugmonizome_meta_api + \"/signatures/find\", json=payload)\n",
    "\n",
    "    sigs = res.json()\n",
    "    sigs = res.json()\n",
    "    scores = []\n",
    "    for i in sigs:\n",
    "        score = uids[i[\"id\"]]\n",
    "        scores.append({\n",
    "            \"name\": i[\"meta\"][\"Term\"][0][\"Name\"],\n",
    "            \"pval\": score[\"p-value\"]\n",
    "        })\n",
    "    \n",
    "    scores.sort(key=lambda x: x['pval'])\n",
    "    bar_chart(scores, dataset)\n",
    "    display(Markdown(\"**Figure %d** %s\"%(figure, label)))\n",
    "    figure += 1\n",
    "    return figure\n",
    "\n",
    "def get_enrichr_bar(userListId, enrichr_library, figure, label):\n",
    "    query_string = '?userListId=%s&backgroundType=%s'\n",
    "    res = requests.get(\n",
    "        enrichr_api + 'enrich' + query_string % (userListId, enrichr_library)\n",
    "     )\n",
    "    if not res.ok:\n",
    "        raise Exception('Error fetching enrichment results')\n",
    "\n",
    "    data = res.json()[enrichr_library]\n",
    "    scores = [{\"name\": i[1], \"pval\": i[2]} for i in data]\n",
    "    scores.sort(key=lambda x: x['pval'])\n",
    "    bar_chart(scores, enrichr_library)\n",
    "    display(Markdown(\"**Figure %d** %s\"%(figure, label)))\n",
    "    figure +=1\n",
    "    return figure\n",
    "\n",
    "def enrichment(consensus, label, figure):\n",
    "    gene_names = [i.upper() for i in consensus.index]\n",
    "    genes_str = '\\n'.join(gene_names)\n",
    "    description = label\n",
    "    payload = {\n",
    "        'list': (None, genes_str),\n",
    "        'description': (None, description)\n",
    "    }\n",
    "\n",
    "    res = requests.post(enrichr_api + 'addList', files=payload)\n",
    "    if not res.ok:\n",
    "        raise Exception('Error analyzing gene list')\n",
    "\n",
    "    data = res.json()\n",
    "    shortId = data[\"shortId\"]\n",
    "    userListId = data[\"userListId\"]\n",
    "    display(Markdown(\"Enrichr Link: https://maayanlab.cloud/Enrichr/enrich?dataset=%s\"%shortId))\n",
    "    for d in enrichr_libraries:\n",
    "        l = \"Enrichr %s top ranked terms for %s\"%(d.replace(\"_\", \" \"), label)\n",
    "        figure = get_enrichr_bar(userListId, d, figure, l)\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consensus Analysis\n",
    "Mimicking and reversing perturbagen counts are organized into a matrix. Depending on the consensus method chosen by the user, the consensus perturbagens are computed either by ranking the z-score calculated using the empirical mean and standard deviation derived from CREEDS [9] signatures; or by simple counts across all the gene sets. Only perturbagens that appear in at least a certain percentage defined by `perc` are kept. This is to ensure that the perturbagens are consistently present across the input gene sets.\n",
    "\n",
    "\n",
    "### Mimickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction = \"mimickers\"\n",
    "for lib in datasets:\n",
    "    library = dataset_map[lib]\n",
    "    display(Markdown(\"### %s\"%lib))\n",
    "    index = set()\n",
    "    pert_dict = enriched[direction][lib]\n",
    "    for v in pert_dict.values():\n",
    "        index = index.union(v.keys())\n",
    "    df = pd.DataFrame(0, index=index, columns=pert_dict.keys())\n",
    "    for k,v in pert_dict.items():\n",
    "        for pert, cnt in v.items():\n",
    "            df.at[pert, k] += cnt\n",
    "    df = df.loc[df.sum(1).sort_values(ascending=False).index]\n",
    "    filename = \"pert_matrix_%s_%s.tsv\"%(library.replace(\" \",\"_\"), direction)\n",
    "    df.to_csv(filename, sep=\"\\t\")\n",
    "#     display(df.head())\n",
    "#     display(Markdown(\"**Table %d** Mimicker perturbagens using %s dataset ([download](./%s))\"%\n",
    "#                      (table, lib, filename)))\n",
    "#     table += 1\n",
    "    # stat_df = pd.DataFrame(0, index=df.index, columns=[\"count\", \"z-score\", \"p-value\"])\n",
    "    empirical_stat = pd.read_csv(S3_PREFIX + \"%s_%s.tsv\" % (library, direction), sep=\"\\t\", index_col=0)\n",
    "    df = df[(df>0).sum(1) > len(df.columns) * perc]\n",
    "    index = set(df.index).intersection(empirical_stat.index)\n",
    "    filtered_df = df.loc[index]    \n",
    "    display(Markdown(\"#### Consensus mimicking %s perturbagen\"%labeller[lib]), display_id=\"mimicking\"+lib)\n",
    "    if lib in gene_page:\n",
    "        stat_df = pd.DataFrame(0, index=index, columns=[\"count\", \"z-score\", \"p-value\", \"Enrichr gene page\"])\n",
    "        stat_df['count'] = filtered_df.sum(1)\n",
    "        # Compute zstat and p value\n",
    "        stat_df[\"z-score\"] = (filtered_df.mean(1) - empirical_stat[\"mean\"]) / empirical_stat[\"std\"]\n",
    "        stat_df[\"p-value\"] = stat_df['z-score'].apply(lambda x: 1-st.norm.cdf(x))\n",
    "        if consensus_method == 'zscore':\n",
    "            #Filter by p-value\n",
    "            stat_df = stat_df[stat_df[\"p-value\"]<alpha].sort_values(by=[\"z-score\"], ascending=False)\n",
    "        else:\n",
    "            stat_df = stat_df.sort_values(by=[\"count\"], ascending=False)\n",
    "\n",
    "        stat_df['Enrichr gene page'] = [\"https://maayanlab.cloud/Enrichr/#find!gene=%s\"%i for i in stat_df.index]\n",
    "        filename = \"pert_stat_%s_%s.tsv\"%(lib.replace(\" \",\"_\"), direction)\n",
    "        stat_df.to_csv(filename, sep=\"\\t\")\n",
    "        stat_df['Enrichr gene page'] = stat_df['Enrichr gene page'].apply(make_clickable)\n",
    "        stat_html = stat_df.head(25).to_html(escape=False)\n",
    "        display(HTML(stat_html))\n",
    "    else:\n",
    "        stat_df = pd.DataFrame(0, index=index, columns=[\"count\", \"z-score\", \"p-value\"])\n",
    "        stat_df['count'] = filtered_df.sum(1)\n",
    "        # Compute zstat and p value\n",
    "        stat_df[\"z-score\"] = (filtered_df.mean(1) - empirical_stat[\"mean\"]) / empirical_stat[\"std\"]\n",
    "        stat_df[\"p-value\"] = stat_df['z-score'].apply(lambda x: 1-st.norm.cdf(x))\n",
    "\n",
    "        if consensus_method == 'zscore':\n",
    "            #Filter by p-value\n",
    "            stat_df = stat_df[stat_df[\"p-value\"]<alpha].sort_values(by=[\"z-score\"], ascending=False)\n",
    "        else:\n",
    "            stat_df = stat_df.sort_values(by=[\"count\"], ascending=False)\n",
    "\n",
    "        filename = \"pert_stat_%s_%s.tsv\"%(library.replace(\" \",\"_\"), direction)\n",
    "        stat_df.to_csv(filename, sep=\"\\t\")\n",
    "        display(stat_df.head(25))\n",
    "    display(Markdown(\"**Table %d** Top 25 consensus mimicking %s perturbagens([download](./%s))\"%\n",
    "                     (table, labeller[lib], filename)))\n",
    "\n",
    "    table+=1\n",
    "\n",
    "    consensus = df.loc[stat_df.index[0:top_perts]]\n",
    "    consensus_norm = quantile_normalize(consensus)\n",
    "#     consensus_norm = consensus.subtract(empirical_stat.loc[consensus.index, \"mean\"], axis=0).divide(empirical_stat.loc[consensus.index, \"std\"], axis=0)\n",
    "    if len(consensus.index) > top_perts:\n",
    "        consensus = consensus.loc[consensus.index[:top_perts]]\n",
    "    filename = \"consensus_matrix_%s_%s.tsv\"%(library.replace(\" \",\"_\"), direction)\n",
    "    consensus.to_csv(filename, sep=\"\\t\")\n",
    "    display(consensus.head())\n",
    "    display(Markdown(\"**Table %d** Consensus mimicking %s perturbagens ([download](./%s))\"%\n",
    "                     (table, labeller[lib], filename)))\n",
    "\n",
    "    table+=1\n",
    "#     plot_label = \"Mimicking %s perturbations\"%(labeller[lib])\n",
    "    \n",
    "#     display(Markdown(\"#### t-SNE Plots\"))\n",
    "#     figure = get_tsne(consensus_norm, plot_label, figure)\n",
    "#     display(Markdown(\"#### UMAP Plots\"))\n",
    "#     figure = get_umap(consensus_norm, plot_label, figure)\n",
    "    if len(consensus.index) > 1:\n",
    "        display(Markdown(\"#### Clustergrammer for mimicking %s perturbagens\"%labeller[lib]), display_id=\"mimicking-clustergrammer-\"+lib)\n",
    "        label = \"Clustergrammer of consensus mimicking perturbagens of L1000 %s perturbations(2021) (quantile normalized scores)\"%labeller[lib]\n",
    "        name = \"clustergrammer_%s_%s.tsv\"%(library.replace(\" \", \"_\"), direction)\n",
    "        figure = clustergrammer(consensus_norm, name, figure, label)\n",
    "\n",
    "        display(Markdown(\"#### Heatmap for mimicking %s perturbagens\"%labeller[lib]), display_id=\"mimicking-heatmap-\"+lib)\n",
    "        label = \"Heatmap of consensus mimicking perturbagens of L1000 %s perturbations(2021) (quantile normalized scores)\"%labeller[lib]\n",
    "        name = \"heatmap_%s_%s.png\"%(library.replace(\" \", \"_\"), direction)\n",
    "        figure = heatmap(consensus_norm, name, figure, label)\n",
    "        if len(consensus.index) > 5:\n",
    "            if lib in drug_page:\n",
    "                display(Markdown(\"#### Drugmonizome enrichment analysis for the consensus mimicking %s perturbagens\"% labeller[lib]))\n",
    "                for d in drugmonizome_datasets:\n",
    "                    label = \"%s top ranked enriched terms for mimicking %s perturbagens\"%(d.replace(\"_\", \" \"), labeller[lib])\n",
    "                    figure = get_drugmonizome_plot(consensus, label, figure, d)\n",
    "            elif lib in gene_page:\n",
    "                display(Markdown(\"#### Enrichr link to analyze enriched terms for the consensus mimicking %s perturbagens\"% labeller[lib]))\n",
    "                label = \"mimicking L1000 %s perturbagens\"%(labeller[lib])\n",
    "                figure = enrichment(consensus, label, figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reversers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction = \"reversers\"\n",
    "for lib in datasets:\n",
    "    library = dataset_map[lib]\n",
    "    display(Markdown(\"### %s\"%lib))\n",
    "    index = set()\n",
    "    pert_dict = enriched[direction][lib]\n",
    "    for v in pert_dict.values():\n",
    "        index = index.union(v.keys())\n",
    "    df = pd.DataFrame(0, index=index, columns=pert_dict.keys())\n",
    "    for k,v in pert_dict.items():\n",
    "        for pert, cnt in v.items():\n",
    "            df.at[pert, k] += cnt\n",
    "    df = df.loc[df.sum(1).sort_values(ascending=False).index]\n",
    "    filename = \"pert_matrix_%s_%s.tsv\"%(library.replace(\" \",\"_\"), direction)\n",
    "    df.to_csv(filename, sep=\"\\t\")\n",
    "#     display(df.head())\n",
    "#     display(Markdown(\"**Table %d** Reverser perturbagens using %s dataset ([download](./%s))\"%\n",
    "#                      (table, lib, filename)))\n",
    "#     table += 1\n",
    "    # stat_df = pd.DataFrame(0, index=df.index, columns=[\"count\", \"z-score\", \"p-value\"])\n",
    "    empirical_stat = pd.read_csv(S3_PREFIX + \"%s_%s.tsv\" % (library, direction), sep=\"\\t\", index_col=0)\n",
    "    df = df[(df>0).sum(1) > len(df.columns) * perc]\n",
    "    index = set(df.index).intersection(empirical_stat.index)\n",
    "    filtered_df = df.loc[index]    \n",
    "    display(Markdown(\"#### Consensus reversing %s perturbagen\"%labeller[lib]), display_id=\"reversing\"+lib)\n",
    "    if lib in gene_page:\n",
    "        stat_df = pd.DataFrame(0, index=index, columns=[\"count\", \"z-score\", \"p-value\", \"Enrichr gene page\"])\n",
    "        stat_df['count'] = filtered_df.sum(1)\n",
    "        # Compute zstat and p value\n",
    "        stat_df[\"z-score\"] = (filtered_df.mean(1) - empirical_stat[\"mean\"]) / empirical_stat[\"std\"]\n",
    "        stat_df[\"p-value\"] = stat_df['z-score'].apply(lambda x: 1-st.norm.cdf(x))\n",
    "        if consensus_method == 'zscore':\n",
    "            #Filter by p-value\n",
    "            stat_df = stat_df[stat_df[\"p-value\"]<alpha].sort_values(by=[\"z-score\"], ascending=False)\n",
    "        else:\n",
    "            stat_df = stat_df.sort_values(by=[\"count\"], ascending=False)\n",
    "\n",
    "        stat_df['Enrichr gene page'] = [\"https://maayanlab.cloud/Enrichr/#find!gene=%s\"%i for i in stat_df.index]\n",
    "        filename = \"pert_stat_%s_%s.tsv\"%(lib.replace(\" \",\"_\"), direction)\n",
    "        stat_df.to_csv(filename, sep=\"\\t\")\n",
    "        stat_df['Enrichr gene page'] = stat_df['Enrichr gene page'].apply(make_clickable)\n",
    "        stat_html = stat_df.head(25).to_html(escape=False)\n",
    "        display(HTML(stat_html))\n",
    "    else:\n",
    "        stat_df = pd.DataFrame(0, index=index, columns=[\"count\", \"z-score\", \"p-value\"])\n",
    "        stat_df['count'] = filtered_df.sum(1)\n",
    "        # Compute zstat and p value\n",
    "        stat_df[\"z-score\"] = (filtered_df.mean(1) - empirical_stat[\"mean\"]) / empirical_stat[\"std\"]\n",
    "        stat_df[\"p-value\"] = stat_df['z-score'].apply(lambda x: 1-st.norm.cdf(x))\n",
    "\n",
    "        if consensus_method == 'zscore':\n",
    "            #Filter by p-value\n",
    "            stat_df = stat_df[stat_df[\"p-value\"]<alpha].sort_values(by=[\"z-score\"], ascending=False)\n",
    "        else:\n",
    "            stat_df = stat_df.sort_values(by=[\"count\"], ascending=False)\n",
    "\n",
    "        filename = \"pert_stat_%s_%s.tsv\"%(library.replace(\" \",\"_\"), direction)\n",
    "        stat_df.to_csv(filename, sep=\"\\t\")\n",
    "        display(stat_df.head(25))\n",
    "    display(Markdown(\"**Table %d** Top 25 consensus reversing %s perturbagens([download](./%s))\"%\n",
    "                     (table, labeller[lib], filename)))\n",
    "\n",
    "    table+=1\n",
    "\n",
    "    consensus = df.loc[stat_df.index[0:top_perts]]\n",
    "    consensus_norm = quantile_normalize(consensus)\n",
    "#     consensus_norm = consensus.subtract(empirical_stat.loc[consensus.index, \"mean\"], axis=0).divide(empirical_stat.loc[consensus.index, \"std\"], axis=0)\n",
    "    if len(consensus.index) > top_perts:\n",
    "        consensus = consensus.loc[consensus.index[:top_perts]]\n",
    "    filename = \"consensus_matrix_%s_%s.tsv\"%(library.replace(\" \",\"_\"), direction)\n",
    "    consensus.to_csv(filename, sep=\"\\t\")\n",
    "    display(consensus.head())\n",
    "    display(Markdown(\"**Table %d** Consensus reversing %s perturbagens ([download](./%s))\"%\n",
    "                     (table, labeller[lib], filename)))\n",
    "\n",
    "    table+=1\n",
    "#     plot_label = \"Reversing %s perturbations\"%(labeller[lib])\n",
    "    \n",
    "#     display(Markdown(\"#### t-SNE Plots\"))\n",
    "#     figure = get_tsne(consensus_norm, plot_label, figure)\n",
    "#     display(Markdown(\"#### UMAP Plots\"))\n",
    "#     figure = get_umap(consensus_norm, plot_label, figure)\n",
    "    if len(consensus.index) > 1:\n",
    "        display(Markdown(\"#### Clustergrammer for reversing %s perturbagens\"%labeller[lib]), display_id=\"reversing-clustergrammer-\"+lib)\n",
    "        label = \"Clustergrammer of consensus reversing perturbagens of L1000 %s perturbations(2021) (quantile normalized scores)\"%labeller[lib]\n",
    "        name = \"clustergrammer_%s_%s.tsv\"%(library.replace(\" \", \"_\"), direction)\n",
    "        figure = clustergrammer(consensus_norm, name, figure, label)\n",
    "\n",
    "        display(Markdown(\"#### Heatmap for reversing %s perturbagens\"%labeller[lib]), display_id=\"reversing-heatmap-\"+lib)\n",
    "        label = \"Heatmap of consensus reversing perturbagens of L1000 %s perturbations(2021) (quantile normalized scores)\"%labeller[lib]\n",
    "        name = \"heatmap_%s_%s.png\"%(library.replace(\" \", \"_\"), direction)\n",
    "        figure = heatmap(consensus_norm, name, figure, label)\n",
    "\n",
    "        if len(consensus.index) > 5:\n",
    "            if lib in drug_page:\n",
    "                display(Markdown(\"#### Drugmonizome enrichment analysis for the consensus reversing %s perturbagens\"% labeller[lib]))\n",
    "                for d in drugmonizome_datasets:\n",
    "                    label = \"%s top ranked enriched terms for reversing %s perturbagens\"%(d.replace(\"_\", \" \"), labeller[lib])\n",
    "                    figure = get_drugmonizome_plot(consensus, label, figure, d)\n",
    "            elif lib in gene_page:\n",
    "                display(Markdown(\"#### Enrichr link to analyze enriched terms for the consensus reversing %s perturbagens\"% labeller[lib]))\n",
    "                label = \"reversing L1000 %s perturbagens\"%(labeller[lib])\n",
    "                figure = enrichment(consensus, label, figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "[1] Subramanian, A., Narayan, R., Corsello, S. M., Peck, D. D., Natoli, T. E., Lu, X., ... & Golub, T. R. (2017). A next generation connectivity map: L1000 platform and the first 1,000,000 profiles. Cell, 171(6), 1437-1452.\n",
    "\n",
    "[2] Fernandez, N. F., Gundersen, G. W., Rahman, A., Grimes, M. L., Rikova, K., Hornbeck, P., & Maayan, A. (2017). Clustergrammer, a web-based heatmap visualization and analysis tool for high-dimensional biological data. Scientific data, 4(1), 1-12.\n",
    "\n",
    "[3] Chen, E. Y., Tan, C. M., Kou, Y., Duan, Q., Wang, Z., Meirelles, G. V., ... & Maayan, A. (2013). Enrichr: interactive and collaborative HTML5 gene list enrichment analysis tool. BMC bioinformatics, 14(1), 1-14.\n",
    "\n",
    "[4] Kuleshov, Maxim V., et al. \"Enrichr: a comprehensive gene set enrichment analysis web server 2016 update.\" Nucleic acids research 44.W1 (2016): W90-W97.\n",
    "\n",
    "[5] Xie, Z., Bailey, A., Kuleshov, M. V., Clarke, D. J., Evangelista, J. E., Jenkins, S. L., ... & Ma'ayan, A. (2021). Gene set knowledge discovery with Enrichr. Current protocols, 1(3), e90.\n",
    "\n",
    "[6] Kropiwnicki, E., Evangelista, J. E., Stein, D. J., Clarke, D. J., Lachmann, A., Kuleshov, M. V., ... & Maayan, A. (2021). Drugmonizome and Drugmonizome-ML: integration and abstraction of small molecule attributes for drug enrichment analysis and machine learning. Database, 2021.\n",
    "\n",
    "[7] Maglott, D., Ostell, J., Pruitt, K. D., & Tatusova, T. (2005). Entrez Gene: gene-centered information at NCBI. Nucleic acids research, 33(suppl_1), D54-D58.\n",
    "\n",
    "[8] Brown, G. R., Hem, V., Katz, K. S., Ovetsky, M., Wallin, C., Ermolaeva, O., ... & Murphy, T. D. (2015). Gene: a gene-centered information resource at NCBI. Nucleic acids research, 43(D1), D36-D42.\n",
    "\n",
    "[9] Wang, Z., Monteiro, C. D., Jagodnik, K. M., Fernandez, N. F., Gundersen, G. W., Rouillard, A. D., ... & Maayan, A. (2016). Extraction and analysis of signatures from the Gene Expression Omnibus by the crowd. Nature communications, 7(1), 1-11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-default",
   "language": "python",
   "name": "jupyter-default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
