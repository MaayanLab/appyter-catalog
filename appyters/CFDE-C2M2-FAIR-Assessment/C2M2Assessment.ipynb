{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%appyter init\n",
    "from appyter import magic\n",
    "magic.init(lambda _=globals: _())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter hide_code\n",
    "\n",
    "{% do SectionField(\n",
    "    name='primary',\n",
    "    title='C2M2 FAIR Assessment',\n",
    "    subtitle='Assessing c2m2 datapackages for FAIRness',\n",
    "    img='insignia.png',\n",
    ") %}\n",
    "\n",
    "{% set file = FileField(\n",
    "    name='file',\n",
    "    label='A zipped [C2M2 Datapackage](https://docs.nih-cfde.org/en/latest/c2m2/draft-C2M2_specification/)',\n",
    "    help='Provide your zipped c2m2 datapackage',\n",
    "    examples={'example.zip': url_for('static', path='example.zip')},\n",
    "    default='example.zip',\n",
    "    section='primary',\n",
    ") %}\n",
    "\n",
    "\n",
    "{% do SectionField(\n",
    "    name='advanced',\n",
    "    title='Advanced Configuration',\n",
    "    subtitle='For tweaking the report',\n",
    ") %}\n",
    "\n",
    "{% set n_bins = IntField(\n",
    "    name='n_bins',\n",
    "    label='Number of bins for discretization of answers',\n",
    "    help='When turning the continuous valued answer into a discrete bucket, how many bins to use',\n",
    "    default=3,\n",
    "    min=2,\n",
    "    max=10,\n",
    "    section='advanced',\n",
    ") %}\n",
    "\n",
    "{% set n_comments = IntField(\n",
    "    name='n_comments',\n",
    "    label='Number of top/bottom comments',\n",
    "    help='When showing comments of unsatisfied answers, how many should be shown?',\n",
    "    default=10,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    section='advanced',\n",
    ") %}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C2M2 Assessment\n",
    "\n",
    "We perform a file-centric FAIR Assessment on all files defined in a [C2M2 datapackage](https://docs.nih-cfde.org/en/latest/c2m2/draft-C2M2_specification/) according to the [C2M2 Rubric](https://fairshake.cloud/rubric/36); descriptions of each metric and how we assess them are provided below, along with the actual code to perform the assesssment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from textwrap import dedent\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(V):\n",
    "    return sum(V) / len(V)\n",
    "\n",
    "def one_and_only(it):\n",
    "  ''' Select one and only item from an iterable, otherwise throw an exception.\n",
    "  '''\n",
    "  it = iter(it)\n",
    "  ret = next(it)\n",
    "  try:\n",
    "    next(it)\n",
    "    raise Exception('Expected one')\n",
    "  except StopIteration:\n",
    "    return ret\n",
    "\n",
    "def deep_find(root, file):\n",
    "  ''' Helper for finding a filename in a potentially deep directory\n",
    "  '''\n",
    "  return set(glob.glob(os.path.join(root, '**', file), recursive=True))\n",
    "\n",
    "def fetch_cache(url, filename, cachedir='.cached'):\n",
    "  ''' Download a {file} from a {url} if it hasn't already been downloaded, storing it in {cachedir}.\n",
    "  '''\n",
    "  import os, urllib.request\n",
    "  os.makedirs(cachedir, exist_ok=True)\n",
    "  if not os.path.exists(os.path.join(cachedir, filename)):\n",
    "    urllib.request.urlretrieve(url, filename=os.path.join(cachedir, filename))\n",
    "  return os.path.join(cachedir, filename)\n",
    "\n",
    "def url_join(*args):\n",
    "  ''' Join urls by slashes, not worrying about duplicated trailing slashes\n",
    "  '''\n",
    "  return '/'.join([arg.rstrip('/') for arg in args[:-1]]+[args[-1]])\n",
    "\n",
    "def filter_empty(val):\n",
    "  ''' Attempt to catch some actual null values that aren't really null.\n",
    "  '''\n",
    "  return [\n",
    "    v\n",
    "    for v in val\n",
    "    if v is not None and (\n",
    "      type(v) != str or v.strip().lower() not in {\n",
    "        '-',\n",
    "        '-666',\n",
    "        '',\n",
    "        'empty',\n",
    "        'n/a',\n",
    "        'na',\n",
    "        'nan',\n",
    "        'nil',\n",
    "        'none',\n",
    "        'not defined',\n",
    "        'null',\n",
    "        'undef',\n",
    "        'undefined',\n",
    "      }\n",
    "    )\n",
    "  ]\n",
    "\n",
    "_lazy = {}\n",
    "def lazy(cb):\n",
    "    import functools\n",
    "    @functools.wraps(cb)\n",
    "    def wrapper():\n",
    "        global _lazy\n",
    "        if cb not in _lazy:\n",
    "            _lazy[cb] = cb()\n",
    "        return _lazy[cb]\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Load DERIVA compatible client from URL or datapackage\n",
    "\n",
    "Given a datapackage, access it through DERIVA-compatible client. This client package <https://github.com/nih-cfde/deriva-datapackage> permits accesisng offline datapackages in the same way that the online DERIVA client operates, thus the assessment can be performed online or offline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "import zipfile\n",
    "import tempfile\n",
    "\n",
    "file = {{ file }}\n",
    "basename, ext = os.path.splitext(file)\n",
    "assert ext == '.zip', 'Expected .zip file'\n",
    "directory = tempfile.mkdtemp()\n",
    "\n",
    "with zipfile.ZipFile(file, 'r') as z:\n",
    "    z.extractall(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deriva_datapackage import create_offline_client\n",
    "\n",
    "# sometimes zip files zip the leading directory, which may be named anything,\n",
    "#  deep_find lets us locate the datapackage wherever it is.\n",
    "CFDE = create_offline_client(\n",
    "    *(\n",
    "        deep_find(directory, 'C2M2_datapackage.json')\n",
    "        | deep_find(directory, 'datapackage.json')\n",
    "    ),\n",
    "    cachedir=directory,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Load External Ontologies for Validation\n",
    "\n",
    "We download the most up to date ontologies from their public releases and load them with our `ontology_parsing.py` module which parses the ontology format and gathers the list of identifiers and synonyms so that we can validate terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ontology_parsing import OBOOntology, CellosaurusOntology\n",
    "OBI = lazy(lambda: OBOOntology.parse(fetch_cache('https://raw.githubusercontent.com/obi-ontology/obi/master/views/obi.obo', 'OBI.obo', cachedir=directory)))\n",
    "UBERON = lazy(lambda: OBOOntology.parse(fetch_cache('http://purl.obolibrary.org/obo/uberon.obo', 'uberon.owl', cachedir=directory)))\n",
    "DOID = lazy(lambda: OBOOntology.parse(fetch_cache('https://github.com/DiseaseOntology/HumanDiseaseOntology/raw/main/src/ontology/releases/doid.obo', 'doid.obo', cachedir=directory)))\n",
    "EDAM = lazy(lambda: OBOOntology.parse(fetch_cache('http://edamontology.org/EDAM.obo', 'EDAM.obo', cachedir=directory)))\n",
    "# NCBITaxon = lazy(lambda: OBOOntology.parse(fetch_cache('http://purl.obolibrary.org/obo/ncbitaxon.obo', 'ncbitaxon.obo', cachedir=directory)))\n",
    "Cellosaurus = lazy(lambda: CellosaurusOntology.parse(fetch_cache('ftp://ftp.expasy.org/databases/cellosaurus/cellosaurus.xml', 'cellosaurus.xml', cachedir=directory)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Prepare C2M2 Rubric\n",
    "\n",
    "We use a python decorator for registering each metric into the rubric. This lets us define each metric in its own cell with its description and code to assert it. All metric functions receive as parameters the file being assessed and the CFDE client for querying other information about that file and [*generate*](https://wiki.python.org/moin/Generators) compatible answers.\n",
    "\n",
    "This paradigm can be used for any rubric allowing assessment code to remain the same even with changing metrics, furthermore this is compatible with [FAIRshake](https://fairshake.cloud/) assessments, adopting FAIRshake metric identifiers allowing the results to be easily registered with FAIRshake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rubric = {\n",
    "  '@id': 36,\n",
    "  'name': 'NIH CFDE Interoperability',\n",
    "  'description': 'This rubric identifies aspects of the metadata models which promote interoperable dataset querying and filtering',\n",
    "  'metrics': {},\n",
    "}\n",
    "\n",
    "def _register_metric(schema):\n",
    "  global metrics\n",
    "  def wrapper(func):\n",
    "    rubric['metrics'][schema['@id']] = dict(schema, func=func)\n",
    "  setattr(wrapper, '__name__', schema['name'])\n",
    "  display(Markdown(dedent(f'''\n",
    "    ### Metric ([{schema['@id']}](https://fairshake.cloud/metric/{schema['@id']})): {schema['name']}\n",
    "    **{schema['description']}**\n",
    "\n",
    "    {schema['detail']}\n",
    "  ''')))\n",
    "  return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric({\n",
    "  # standardized metadata format (107), machine readable metadata (106)\n",
    "  # metadata license (117) (c2m2 ?)\n",
    "  '@id': 106,\n",
    "  'name': 'Metadata conformance',\n",
    "  'description': 'The metadata properly conforms with the CFDE perscribed metadata model specification',\n",
    "  'detail': '''Starting from a file, traverse all associated tables and calculate a ratio of missing fields vs complete of fields. 0.25 * (file_complete + biosample_complete + subject_complete + project_complete) where x_complete is n_fields_with_values / n_fields for field in all_records.''',\n",
    "  'principle': 'Findable',\n",
    "})\n",
    "def _(file, CFDE=None, **kwargs):\n",
    "  file_query = lambda: CFDE.tables['file'].filter((\n",
    "    CFDE.tables['file'].id_namespace == file['id_namespace']\n",
    "  ) & (\n",
    "    CFDE.tables['file'].local_id == file['local_id']\n",
    "  ))\n",
    "  # 25% file completeness\n",
    "  file_completeness = [len(list(filter_empty(file.values()))) / len(file.keys())]\n",
    "  # 25% biosample completeness\n",
    "  biosample_completeness = []\n",
    "  biosamples = file_query().link(\n",
    "    CFDE.tables['file_describes_biosample'], on=((\n",
    "      CFDE.tables['file'].id_namespace == CFDE.tables['file_describes_biosample'].file_id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['file'].local_id == CFDE.tables['file_describes_biosample'].file_local_id\n",
    "    ))\n",
    "  ).link(\n",
    "    CFDE.tables['biosample'], on=((\n",
    "      CFDE.tables['file_describes_biosample'].biosample_id_namespace == CFDE.tables['biosample'].id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['file_describes_biosample'].biosample_local_id == CFDE.tables['biosample'].local_id\n",
    "    ))\n",
    "  ).entities()\n",
    "  for biosample in biosamples:\n",
    "    biosample_completeness.append(\n",
    "      len(list(filter_empty(biosample.values()))) / len(biosample.keys())\n",
    "    )\n",
    "  # 25% subject completeness\n",
    "  subject_completeness = []\n",
    "  subjects = file_query().link(\n",
    "    CFDE.tables['file_describes_subject'], on=((\n",
    "       CFDE.tables['file'].id_namespace == CFDE.tables['file_describes_subject'].file_id_namespace\n",
    "    ) & (\n",
    "       CFDE.tables['file'].local_id == CFDE.tables['file_describes_subject'].file_local_id\n",
    "    ))\n",
    "  ).link(\n",
    "    CFDE.tables['subject'], on=((\n",
    "       CFDE.tables['file_describes_subject'].subject_id_namespace == CFDE.tables['subject'].id_namespace\n",
    "    ) & (\n",
    "       CFDE.tables['file_describes_subject'].subject_local_id == CFDE.tables['subject'].local_id\n",
    "    ))\n",
    "  ).entities()\n",
    "  for subject in subjects:\n",
    "    subject_completeness.append(\n",
    "      len(list(filter_empty(subject.values()))) / len(subject.keys())\n",
    "    )\n",
    "  # 25% project completeness\n",
    "  project_completeness = {}\n",
    "  #\n",
    "  projects = CFDE.tables['project'].filter((\n",
    "    CFDE.tables['project'].id_namespace == file['project_id_namespace']\n",
    "  ) & (\n",
    "    CFDE.tables['project'].local_id == file['project_local_id']\n",
    "  ))\n",
    "  project_entities = list(projects.entities())\n",
    "  #\n",
    "  while project_entities:\n",
    "    project = one_and_only(project_entities)\n",
    "    project_completeness[url_join(project['id_namespace'], project['local_id'])] = len(list(filter_empty(project.values()))) / len(project.keys())\n",
    "    #\n",
    "    p1, pip, p2 = CFDE.tables['project'].alias('p1'), CFDE.tables['project_in_project'].alias('pip'), CFDE.tables['project'].alias('p2')\n",
    "    path = p1.path.filter(((p1.id_namespace == project['id_namespace']) & (p1.local_id == project['local_id'])))\n",
    "    path = path.link(pip, on=((path.p1.id_namespace == pip.child_project_id_namespace) & (path.p1.local_id == pip.child_project_local_id)))\n",
    "    path = path.link(p2, on=((path.pip.parent_project_id_namespace == p2.id_namespace) & (path.pip.parent_project_local_id == p2.local_id)))\n",
    "    projects = path\n",
    "    project_entities = list(projects.entities())\n",
    "  #\n",
    "  file_completeness = (sum(file_completeness) / len(file_completeness)) if file_completeness else 0.\n",
    "  biosample_completeness = sum(biosample_completeness) / len(biosample_completeness) if biosample_completeness else 0.\n",
    "  subject_completeness = sum(subject_completeness) / len(subject_completeness) if subject_completeness else 0.\n",
    "  project_completeness = sum(project_completeness.values()) / len(project_completeness) if project_completeness else 0.\n",
    "  complete_completeness = mean([\n",
    "    file_completeness,\n",
    "    biosample_completeness,\n",
    "    subject_completeness,\n",
    "    project_completeness,\n",
    "  ])\n",
    "  #\n",
    "  yield {\n",
    "    'value': complete_completeness,\n",
    "    'comment': 'Computed based on completeness of file ({:.2f}) and associated biosample ({:.2f}), subject ({:.2f}), and projects ({:.2f})'.format(\n",
    "      file_completeness,\n",
    "      biosample_completeness,\n",
    "      subject_completeness,\n",
    "      project_completeness,\n",
    "    )\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric({\n",
    "  '@id': 136,\n",
    "  'name': 'Program name',\n",
    "  'description': 'Program name is available for querying',\n",
    "  'detail': '''From a given file, find the root project and ensure it corresponds to a valid DCC.''',\n",
    "  'principle': 'Findable',\n",
    "})\n",
    "def _(file, CFDE=None, **kwargs):\n",
    "  # the program name is the root project\n",
    "  #\n",
    "  project = None\n",
    "  projects = CFDE.tables['project'].filter((\n",
    "    CFDE.tables['project'].id_namespace == file['project_id_namespace']\n",
    "  ) & (\n",
    "    CFDE.tables['project'].local_id == file['project_local_id']\n",
    "  ))\n",
    "  project_entities = list(projects.entities())\n",
    "  #\n",
    "  while project_entities:\n",
    "    project = one_and_only(project_entities)\n",
    "    #\n",
    "    p1, pip, p2 = CFDE.tables['project'].alias('p1'), CFDE.tables['project_in_project'].alias('pip'), CFDE.tables['project'].alias('p2')\n",
    "    path = p1.path.filter(((p1.id_namespace == project['id_namespace']) & (p1.local_id == project['local_id'])))\n",
    "    path = path.link(pip, on=((path.p1.id_namespace == pip.child_project_id_namespace) & (path.p1.local_id == pip.child_project_local_id)))\n",
    "    path = path.link(p2, on=((path.pip.parent_project_id_namespace == p2.id_namespace) & (path.pip.parent_project_local_id == p2.local_id)))\n",
    "    projects = path\n",
    "    project_entities = list(projects.entities())\n",
    "  # at this point 'project' contains the top level project\n",
    "  if project is None:\n",
    "    yield {\n",
    "      'value': 0.0,\n",
    "      'comment': 'Could not identify top level project',\n",
    "    }\n",
    "  elif project['abbreviation'] in {'4DN', 'GTEx', 'HMP', 'KidsFirst', 'LINCS', 'Metabolomics', 'MoTrPAC'}:\n",
    "    yield {\n",
    "      'value': 1,\n",
    "      'comment': 'Identified known program {}'.format(project['name'])\n",
    "    }\n",
    "  else:\n",
    "    yield {\n",
    "      'value': 0.75,\n",
    "      'comment': 'Identified unknown top level project {}'.format(project['name'])\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric({\n",
    "  '@id': 137,\n",
    "  'name': 'Project name',\n",
    "  'description': 'Project name is available for querying',\n",
    "  'detail': '''Ensure the direct parent project for a given file is available.''',\n",
    "  'principle': 'Findable',\n",
    "})\n",
    "def _(file, CFDE=None, **kwargs):\n",
    "  # the project name is the direct parent project\n",
    "  project = one_and_only(\n",
    "    CFDE.tables['project'].filter((\n",
    "      CFDE.tables['project'].id_namespace == file['project_id_namespace']\n",
    "    ) & (\n",
    "      CFDE.tables['project'].local_id == file['project_local_id']\n",
    "    )).entities()\n",
    "  )\n",
    "  if project.get('name'):\n",
    "    yield {\n",
    "      'value': 1,\n",
    "      'comment': 'Identified project: {}'.format(project['name'])\n",
    "    }\n",
    "  else:\n",
    "    yield {\n",
    "      'value': 0.5,\n",
    "      'comment': 'Project identified, but it had no name'\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric({\n",
    "  '@id': 27,\n",
    "  'name': 'PI Contact',\n",
    "  'description': 'PI Contact is available for dataset',\n",
    "  'detail': '''Ensure primary_dcc_contact is present for the file and it's not empty.''',\n",
    "  'principle': 'Reusable',\n",
    "})\n",
    "def _(file, CFDE=None, **kwargs):\n",
    "  try:\n",
    "    contact = one_and_only(\n",
    "      CFDE.tables['primary_dcc_contact'].filter(\n",
    "        CFDE.tables['primary_dcc_contact'].project_id_namespace == file['id_namespace']\n",
    "      ).entities()\n",
    "    )\n",
    "    if contact.get('contact_email'):\n",
    "      yield {\n",
    "        'value': 0.75,\n",
    "        'comment': 'Contact email found, possibly PI'\n",
    "      }\n",
    "    elif contact.get('dcc_url'):\n",
    "      yield {\n",
    "        'value': 0.5,\n",
    "        'comment': 'DCC website available, contact information might be discoverable'\n",
    "      }\n",
    "    else:\n",
    "      yield {\n",
    "        'value': 0,\n",
    "        'comment': 'No contact information was located for this file'\n",
    "      }\n",
    "  except:\n",
    "    yield {\n",
    "      'value': 0,\n",
    "      'comment': 'No contact information was located for this file'\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric({\n",
    "  '@id': 138,\n",
    "  'name': 'Responsible institution',\n",
    "  'description': 'The institution that created this dataset is available',\n",
    "  'detail': '''This is not available in the current iteration of the C2M2.''',\n",
    "  'principle': 'Findable',\n",
    "})\n",
    "def _(file, CFDE=None, **kwargs):\n",
    "  yield {\n",
    "    'value': 0,\n",
    "    'comment': 'No information about the contributing institution is available in the C2M2 Level 1'\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric({\n",
    "  # Access protocol (110)\n",
    "  '@id': 110,\n",
    "  'name': 'Access protocol',\n",
    "  'description': 'The protocol for accessing the data is available and described with a URI',\n",
    "  'detail': '''This is not available in the current iteration of the C2M2.''',\n",
    "  'principle': 'Accessible',\n",
    "})\n",
    "def _(file, CFDE=None, **kwargs):\n",
    "  yield {\n",
    "    'value': 0,\n",
    "    'comment': 'The C2M2 Level 1 does not provide a means of capturing information about file access'\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric({\n",
    "  '@id': 139,\n",
    "  'name': 'Assay',\n",
    "  'description': 'Assay is present and a proper CFDE-specified ontological term is found in the CFDE-specified ontologies.',\n",
    "  'detail': '''Ensure the assay_type is in the latest version of OBI.''',\n",
    "  'principle': 'Interoperable',\n",
    "})\n",
    "def _(file, CFDE=None, **kwargs):\n",
    "  # TODO: check names\n",
    "  assay = file.get('assay_type')\n",
    "  if not assay:\n",
    "    yield {\n",
    "      'value': 0.0,\n",
    "      'comment': 'No assay_type found associated with the file',\n",
    "    }\n",
    "  elif OBI().get(assay) is not None:\n",
    "    yield {\n",
    "      'value': 1,\n",
    "      'comment': 'Ontological IRI for Assay found in OBI.',\n",
    "      'url_comment': assay,\n",
    "    }\n",
    "  else:\n",
    "    yield {\n",
    "      'value': 0.5,\n",
    "      'comment': 'Assay found but not verified in OBI.',\n",
    "      'url_comment': assay,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric({\n",
    "  '@id': 140,\n",
    "  'name': 'Anatomical Part',\n",
    "  'description': 'An anatomical part is present and the CFDE-specified ontological term is found in the CFDE-specified ontologies',\n",
    "  'detail': '''For each file, ensure we can find at least one anatomy term and any anatomy that is found can be associated with a file (through biosample), ensure it's present in the latest version of UBERON.''',\n",
    "  'principle': 'Interoperable',\n",
    "})\n",
    "def _(file, CFDE=None, **kwargs):\n",
    "  # TODO: check names\n",
    "  biosamples = list(CFDE.tables['file_describes_biosample'].filter((\n",
    "    CFDE.tables['file_describes_biosample'].file_id_namespace == file['id_namespace']\n",
    "  ) & (\n",
    "    CFDE.tables['file_describes_biosample'].file_local_id == file['local_id']\n",
    "  )).link(\n",
    "    CFDE.tables['biosample'], on=((\n",
    "      CFDE.tables['file_describes_biosample'].biosample_id_namespace == CFDE.tables['biosample'].id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['file_describes_biosample'].biosample_local_id == CFDE.tables['biosample'].local_id\n",
    "    ))\n",
    "  ).entities())\n",
    "  if len(biosamples) < 1:\n",
    "    yield {\n",
    "      'value': 0.0,\n",
    "      'comment': 'No biosamples found described by the file',\n",
    "    }\n",
    "  else:\n",
    "    for biosample in biosamples:\n",
    "      anatomy = biosample.get('anatomy')\n",
    "      if not anatomy:\n",
    "        yield {\n",
    "          'value': 0.0,\n",
    "          'comment': 'No anatomy found on the biosample',\n",
    "        }\n",
    "      elif UBERON().get(anatomy) is not None:\n",
    "        yield {\n",
    "          'value': 1,\n",
    "          'comment': 'Ontological IRI for Anatomy found in UBERON.',\n",
    "          'url_comment': anatomy,\n",
    "        }\n",
    "      else:\n",
    "        yield {\n",
    "          'value': 0.5,\n",
    "          'comment': 'Anatomy found but not verified in UBERON.',\n",
    "          'url_comment': anatomy,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric({\n",
    "  '@id': 141,\n",
    "  'name': 'Disease',\n",
    "  'description': 'A disease is present and the CFDE-specified ontological term is found in the CFDE-specified ontologies',\n",
    "  'detail': '''This is not available in the current iteration of the C2M2.''',\n",
    "  'principle': 'Interoperable',\n",
    "})\n",
    "def _(file, CFDE=None, **kwargs):\n",
    "  if 'subject_disease' in CFDE.tables:\n",
    "    # TODO: check names\n",
    "    path = CFDE.tables['file'].filter((CFDE.tables['file'].id_namespace == file['id_namespace']) & (CFDE.tables['file'].local_id == file['local_id']))\n",
    "    subject_path = path.link(\n",
    "      CFDE.tables['file_describes_subject'], on=((\n",
    "        CFDE.tables['file'].id_namespace == CFDE.tables['file_describes_subject'].file_id_namespace\n",
    "      ) & (\n",
    "        CFDE.tables['file'].local_id == CFDE.tables['file_describes_subject'].file_local_id\n",
    "      ))\n",
    "    )\n",
    "    subject_path = subject_path.link(\n",
    "      CFDE.tables['subject'], on=((\n",
    "        CFDE.tables['file_describes_subject'].subject_id_namespace == CFDE.tables['subject'].id_namespace\n",
    "      ) & (\n",
    "        CFDE.tables['file_describes_subject'].subject_local_id == CFDE.tables['subject'].local_id\n",
    "      ))\n",
    "    )\n",
    "    subject_path = subject_path.link(\n",
    "      CFDE.tables['subject_disease'], on=((\n",
    "        CFDE.tables['subject'].id_namespace == CFDE.tables['subject_disease'].subject_id_namespace\n",
    "      ) & (\n",
    "        CFDE.tables['subject'].local_id == CFDE.tables['subject_disease'].subject_local_id\n",
    "      ))\n",
    "    )\n",
    "    biosample_path = path.link(\n",
    "      CFDE.tables['file_describes_biosample'], on=((\n",
    "        CFDE.tables['file'].id_namespace == CFDE.tables['file_describes_biosample'].file_id_namespace\n",
    "      ) & (\n",
    "        CFDE.tables['file'].local_id == CFDE.tables['file_describes_biosample'].file_local_id\n",
    "      ))\n",
    "    )\n",
    "    biosample_path = biosample_path.link(\n",
    "      CFDE.tables['biosample'], on=((\n",
    "        CFDE.tables['file_describes_biosample'].biosample_id_namespace == CFDE.tables['biosample'].id_namespace\n",
    "      ) & (\n",
    "        CFDE.tables['file_describes_biosample'].biosample_local_id == CFDE.tables['biosample'].local_id\n",
    "      ))\n",
    "    )\n",
    "    biosample_path = biosample_path.link(\n",
    "      CFDE.tables['biosample_disease'], on=((\n",
    "        CFDE.tables['biosample'].id_namespace == CFDE.tables['biosample_disease'].biosample_id_namespace\n",
    "      ) & (\n",
    "        CFDE.tables['biosample'].local_id == CFDE.tables['biosample_disease'].biosample_local_id\n",
    "      ))\n",
    "    )\n",
    "    for label, path in [('biosample', biosample_path), ('subject', subject_path)]:\n",
    "      for entity in path.entities():\n",
    "        disease = entity.get('disease')\n",
    "        if not disease:\n",
    "          yield {\n",
    "            'value': 0.0,\n",
    "            'comment': f'No disease found attached to the {label}',\n",
    "          }\n",
    "        elif DOID().get(disease) is not None:\n",
    "          yield {\n",
    "            'value': 1,\n",
    "            'comment': f\"Ontological IRI for disease associated with {label} found in Disease Ontology.\",\n",
    "            'url_comment': disease,\n",
    "          }\n",
    "        else:\n",
    "          yield {\n",
    "            'value': 0.5,\n",
    "            'comment': f\"Disease found in {label} but not verified in Disease Ontology.\",\n",
    "            'url_comment': disease,\n",
    "          }\n",
    "  else:\n",
    "    yield {\n",
    "      'value': 0.0,\n",
    "      'comment': 'Disease information not supported by this version of C2M2',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric({\n",
    "  '@id': 142,\n",
    "  'name': 'File type',\n",
    "  'description': 'A file type is present and the CFDE-specified ontological term is found in the CFDE-specified ontologies',\n",
    "  'detail': '''Ensure the file_format & data_type is in the latest version of EDAM.''',\n",
    "  'principle': 'Interoperable',\n",
    "})\n",
    "def _(file, CFDE=None, **kwargs):\n",
    "  # TODO: check names\n",
    "  for term_type, term in [('file format', file.get('file_format')), ('data type', file.get('data_type'))]:\n",
    "    if not term:\n",
    "      yield {\n",
    "        'value': 0.0,\n",
    "        'comment': 'No {} found on the biosample'.format(term_type),\n",
    "      }\n",
    "    elif EDAM().get(\"EDAM_{term}\".format(term=term)) is not None:\n",
    "      yield {\n",
    "        'value': 1,\n",
    "        'comment': 'Ontological IRI for {} found in EDAM.'.format(term_type),\n",
    "        'url_comment': term,\n",
    "      }\n",
    "    else:\n",
    "      yield {\n",
    "        'value': 0.5,\n",
    "        'comment': '{} found but not verified in EDAM.'.format(term_type.capitalize()),\n",
    "        'url_comment': term,\n",
    "      }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric({\n",
    "  '@id': 143,\n",
    "  'name': 'Taxonomy',\n",
    "  'description': 'A taxonomy is present and the CFDE-specified ontological term is found in the CFDE-specified ontologies',\n",
    "  'detail': '''For each file, ensure we can find at least one taxonomy term and any taxonomy that is found can be associated with a file (through subject & subject_role_taxonomy), ensure it's present in the latest version of NCBI.''',\n",
    "  'principle': 'Interoperable',\n",
    "})\n",
    "def _(file, CFDE=None, ncbi_taxon_client=None, **kwargs):\n",
    "  # TODO: check names\n",
    "  path = CFDE.tables['file'].filter((CFDE.tables['file'].id_namespace == file['id_namespace']) & (CFDE.tables['file'].local_id == file['local_id']))\n",
    "  path = path.link(\n",
    "    CFDE.tables['file_describes_subject'], on=((\n",
    "      CFDE.tables['file'].id_namespace == CFDE.tables['file_describes_subject'].file_id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['file'].local_id == CFDE.tables['file_describes_subject'].file_local_id\n",
    "    ))\n",
    "  )\n",
    "  path = path.link(\n",
    "    CFDE.tables['subject'], on=((\n",
    "      CFDE.tables['file_describes_subject'].subject_id_namespace == CFDE.tables['subject'].id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['file_describes_subject'].subject_local_id == CFDE.tables['subject'].local_id\n",
    "    ))\n",
    "  )\n",
    "  path = path.link(\n",
    "    CFDE.tables['subject_role_taxonomy'], on=((\n",
    "      CFDE.tables['subject'].id_namespace == CFDE.tables['subject_role_taxonomy'].subject_id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['subject'].local_id == CFDE.tables['subject_role_taxonomy'].subject_local_id\n",
    "    ))\n",
    "  )\n",
    "  for entity in path.entities():\n",
    "    if entity.get('taxonomy_id') is None:\n",
    "      yield {\n",
    "        'value': 0,\n",
    "        'comment': 'Taxonomy is not present in subject_role_taxonomy',\n",
    "      }\n",
    "    elif entity['taxonomy_id'].startswith('NCBI:txid'):\n",
    "      taxon = ncbi_taxon_client.fetch(entity['taxonomy_id'][len('NCBI:txid'):])\n",
    "      if taxon is not None:\n",
    "        yield {\n",
    "          'value': 1,\n",
    "          'comment': 'Taxonomy is present and validated in ncbi',\n",
    "          'url_comment': entity['taxonomy_id'],\n",
    "        }\n",
    "      else:\n",
    "        yield {\n",
    "          'value': 0.5,\n",
    "          'comment': 'Taxonomy is present but not NCBI',\n",
    "          'url_comment': entity['taxonomy_id'],\n",
    "        }\n",
    "    else:\n",
    "      yield {\n",
    "        'value': 0.5,\n",
    "        'comment': 'Taxonomy is present but not NCBI',\n",
    "        'url_comment': entity['taxonomy_id'],\n",
    "      }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric({\n",
    "  '@id': 144,\n",
    "  'name': 'Cell Line',\n",
    "  'description': 'A cell line is present and the CFDE-specified ontological term is found in the CFDE-specified ontologies',\n",
    "  'detail': '''For each file, ensure we can find at least one subject corresponding to a cell line and that cell line's name is present in Cellosaurus.''',\n",
    "  'principle': 'Interoperable',\n",
    "})\n",
    "def _(file, CFDE=None, **kwargs):\n",
    "  path = CFDE.tables['file'].filter((CFDE.tables['file'].id_namespace == file['id_namespace']) & (CFDE.tables['file'].local_id == file['local_id']))\n",
    "  path = path.link(\n",
    "    CFDE.tables['file_describes_subject'], on=((\n",
    "      CFDE.tables['file'].id_namespace == CFDE.tables['file_describes_subject'].file_id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['file'].local_id == CFDE.tables['file_describes_subject'].file_local_id\n",
    "    ))\n",
    "  )\n",
    "  path = path.link(\n",
    "    CFDE.tables['subject'], on=((\n",
    "      CFDE.tables['file_describes_subject'].subject_id_namespace == CFDE.tables['subject'].id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['file_describes_subject'].subject_local_id == CFDE.tables['subject'].local_id\n",
    "    ))\n",
    "  )\n",
    "  # https://github.com/nih-cfde/specifications-and-documentation/blob/master/draft-C2M2_internal_CFDE_CV_tables/subject_granularity.tsv#L2\n",
    "  path = path.filter(CFDE.tables['subject'].granularity == 'cfde_subject_granularity:4')\n",
    "  path = path.subject\n",
    "  cell_lines = path.entities() # contain all cell line subjects\n",
    "  for cell_line in cell_lines:\n",
    "    cellosaurus_cell_line = Cellosaurus().get(cell_line['persistent_id']) if 'persistent_id' in cell_line else None\n",
    "    if cellosaurus_cell_line and cell_line.get('name') == cellosaurus_cell_line.get('name') and cell_line.get('name') is not None:\n",
    "      yield {\n",
    "        'value': 1,\n",
    "        'comment': 'Ontological IRI for cell line and term match what is found in Cellosaurus.',\n",
    "        'url_comment': cell_line['persistent_id']\n",
    "      }\n",
    "    elif cellosaurus_cell_line is not None:\n",
    "      yield {\n",
    "        'value': 0.75,\n",
    "        'comment': 'Ontological IRI for cell line was found in Cellosaurus.',\n",
    "        'url_comment': cell_line['persistent_id']\n",
    "      }\n",
    "    elif 'name' in cell_line and Cellosaurus().get(cell_line['name']):\n",
    "      yield {\n",
    "        'value': 0.75,\n",
    "        'comment': 'Ontological IRI found in Cellosaurus was in the cell_line name field.',\n",
    "        'url_comment': cell_line['name'],\n",
    "      }\n",
    "    elif 'name' in cell_line:\n",
    "      yield {\n",
    "        'value': 0.5,\n",
    "        'comment': 'Cell line found but not in Cellosaurus',\n",
    "        'url_comment': cell_line.get('name', ''),\n",
    "      }\n",
    "    else:\n",
    "      yield {\n",
    "        'value': 0,\n",
    "        'comment': 'Cell line found but missing any information',\n",
    "      }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric({\n",
    "  # License (116)\n",
    "  '@id': 116,\n",
    "  'name': 'Data Usage License',\n",
    "  'description': 'A Data usage license is described',\n",
    "  'detail': '''This is not available in the current iteration of the C2M2.''',\n",
    "  'principle': 'Reusable',\n",
    "})\n",
    "def _(file, CFDE=None, **kwargs):\n",
    "  yield {\n",
    "    'value': 0,\n",
    "    'comment': 'No information about data usage licenses are described in the C2M2 Level 1'\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric({\n",
    "  # Persistent identifier (105)\n",
    "  '@id': 104,\n",
    "  'name': 'Persistent identifier',\n",
    "  'description': 'Globally unique, persistent, and valid identifiers (preferrably DOIs) are present for the dataset',\n",
    "  'detail': '''We check that the persistent id is present and whether or not it is a DOI.''',\n",
    "  'principle': 'Findable',\n",
    "})\n",
    "def _(file, CFDE=None, **kwargs):\n",
    "  persistent_id = file.get('persistent_id')\n",
    "  if persistent_id:\n",
    "    if re.match(r'^https?://[^/]+\\.doi\\.org/.+$', persistent_id):\n",
    "      yield {\n",
    "        'value': 1,\n",
    "        'comment': 'A DOI was identified in the persistent_id',\n",
    "        'url_comment': persistent_id,\n",
    "      }\n",
    "    else:\n",
    "      yield {\n",
    "        'value': 0.5,\n",
    "        'comment': 'A persistent_id was identified but it is not a doi',\n",
    "        'url_comment': persistent_id,\n",
    "      }\n",
    "  else:\n",
    "    yield {\n",
    "      'value': 0,\n",
    "      'comment': 'No persistent_id defined'\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric({\n",
    "  # Resource identifier (108)\n",
    "  '@id': 108,\n",
    "  'name': 'Resource identifier',\n",
    "  'description': 'An identifier for the resource is present',\n",
    "  'detail': '''Likely guaranteed by the c2m2 model, checks for presence of local_id.''',\n",
    "  'principle': 'Findable',\n",
    "})\n",
    "def _(file, CFDE=None, **kwargs):\n",
    "  if file.keys() >= {'local_id', 'id_namespace'}:\n",
    "    yield {\n",
    "      'value': 1,\n",
    "      'comment': 'An id and namespace were provided for the resource',\n",
    "      'url_comment': '{} {}'.format(file['local_id'], file['id_namespace']),\n",
    "    }\n",
    "  else:\n",
    "    yield {\n",
    "      'value': 0,\n",
    "      'comment': 'An id and namespace were not present for the resource',\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric({\n",
    "  '@id': 145,\n",
    "  'name': 'Landing Page',\n",
    "  'description': 'A landing page exists and is accessible for the identifiers',\n",
    "  'detail': '''Checks to make sure the persistent_id is resolvable with a HEAD request. if it is not http/https it is assumed to be an identifiers.org-resolvable CURIE. note that this is still error prone, some identifier websites do not follow HTTP standards and may not report 404s with ids that aren't found.''',\n",
    "  'principle': 'Findable',\n",
    "})\n",
    "def _(file, CFDE=None, **kwargs):\n",
    "  persistent_id = file.get('persistent_id')\n",
    "  if persistent_id:\n",
    "    if not re.match(r'^https?://', persistent_id):\n",
    "      persistent_id = 'https://identifiers.org/{}'.format(persistent_id)\n",
    "    #\n",
    "    try:\n",
    "      status_code = requests.head(persistent_id, headers={'User-Agent': None}).status_code\n",
    "      if status_code >= 200 and status_code < 300:\n",
    "        yield {\n",
    "          'value': 1,\n",
    "          'comment': 'valid and HEAD reports {}'.format(status_code),\n",
    "          'url_comment': persistent_id,\n",
    "        }\n",
    "      elif status_code >= 300 and status_code < 399:\n",
    "        yield {\n",
    "          'value': 0.5,\n",
    "          'comment': 'valid url but HEAD reported {}, status cannot be determined'.format(status_code),\n",
    "          'url_comment': persistent_id,\n",
    "        }\n",
    "      elif status_code >= 400:\n",
    "        yield {\n",
    "          'value': 0.25,\n",
    "          'comment': 'valid url but HEAD reported {}'.format(status_code),\n",
    "          'url_comment': persistent_id,\n",
    "        }\n",
    "    except Exception as e:\n",
    "      yield {\n",
    "        'value': 0.25,\n",
    "        'comment': 'received error: {}'.format(e),\n",
    "        'url_comment': persistent_id,\n",
    "      }\n",
    "  else:\n",
    "    yield {\n",
    "      'value': 0,\n",
    "      'comment': 'A persistent_id was not provided for the resource',\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Perform assessment using rubric\n",
    "\n",
    "With the C2M2 rubric initialized in `rubric`, we can now execute an automated assessment, dispatching each file to all the metrics and collecting all the answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from ncbi_taxon import create_ncbi_taxon_client\n",
    "with create_ncbi_taxon_client(cachedir=directory) as ncbi_taxon_client:\n",
    "  ctx = dict(CFDE=CFDE, ncbi_taxon_client=ncbi_taxon_client)\n",
    "  n_files = CFDE.tables['file'].count()\n",
    "  answers = [\n",
    "    dict(\n",
    "      **answer,\n",
    "      metric=metric['@id'],\n",
    "      target=url_join(file['id_namespace'], file['local_id']),\n",
    "    )\n",
    "    for file in tqdm(\n",
    "        CFDE.tables['file'].entities(),\n",
    "        total=n_files,\n",
    "        miniters=n_files//100,\n",
    "    )\n",
    "    for metric in rubric['metrics'].values()\n",
    "    for answer in metric['func'](file, **ctx)\n",
    "  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Review results\n",
    "\n",
    "With the assessment complete, we're ready to review the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 1. A simple look at the structure of the answers dataframe (joined with metrics for readability of metrics)\n",
    "\n",
    "- `target` is the URI for the digital object being assessed, in this case it's the file global id formed by `id_namespace` + `local_id`\n",
    "- `metric` this is the id of the metric being assessed\n",
    "- `name` this is the human readable name of the metric\n",
    "- `principle` this is the F.A.I.R category of the metric\n",
    "- `value` represents the quantitative value assigned to the given answer. It ranges between 0.0 and 1.0, 0.0 representing complete lack of *compliance* with a metric, and 1.0 representing complete satisfaction of a metric. \n",
    "- `comment` is a human-description describing why the `value` is what it is.\n",
    "- `url_comment` is available when a url/uri is available as evidence for metric satisfaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame(rubric['metrics']).T\n",
    "df_answers = pd.merge(\n",
    "    left=pd.DataFrame(answers), left_on='metric',\n",
    "    right=df_metrics[['name', 'principle']], right_index=True,\n",
    ")\n",
    "df_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "### Figure 1. Heatmap of answers\n",
    "\n",
    "We discretize the values into {{ n_bins }} bins to get a sense of how many metrics are being satisfied and by how well.\n",
    "We show the percentage of answers for that metric which fall into that bucket alongside the number of answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "d = df_answers.groupby([\n",
    "    pd.cut(\n",
    "        df_answers['value'],\n",
    "        bins={{ n_bins }},\n",
    "{% if n_bins.raw_value == 2 %}\n",
    "        labels=('poor', 'good'),\n",
    "{% elif n_bins.raw_value == 3 %}\n",
    "        labels=('poor', 'okay', 'good'),\n",
    "{% elif n_bins.raw_value == 4 %}\n",
    "        labels=('poor', 'okay', 'good', 'great'),\n",
    "{% else %}\n",
    "        labels=np.arange({{ n_bins }})+1,\n",
    "{% endif %}\n",
    "    ),\n",
    "    'name',\n",
    "])['value'].count().unstack().T\n",
    "\n",
    "d_pct = d.divide(d.sum(axis=1), axis=0)*100\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 12))\n",
    "#\n",
    "sns.heatmap(\n",
    "    d_pct,\n",
    "    annot=True, fmt='.1f',\n",
    "    square=True,\n",
    "    ax=ax1,\n",
    ")\n",
    "for t in ax1.get_yticklabels():\n",
    "  t.set_rotation(0)\n",
    "ax1.set_xlabel('')\n",
    "ax1.set_ylabel('')\n",
    "#\n",
    "sns.barplot(\n",
    "    data=d.sum(axis=1).to_frame('Number of Answers').reset_index(),\n",
    "    x='Number of Answers', y='name',\n",
    "    order=d.index,\n",
    "    orient='h',\n",
    "    ax=ax2,\n",
    ")\n",
    "ax2.set_ylabel('')\n",
    "ax2.set_yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "{% if n_comments.raw_value > 0 %}\n",
    "### Figure 2. The top and bottom {{ n_comments }} most frequent comments occuring on unsatisfied metrics.\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "{% if n_comments.raw_value > 0 %}\n",
    "comment_vc = df_answers[df_answers['value'] < 1.0]['comment'].value_counts()\n",
    "comment_vc = comment_vc[comment_vc > 1]\n",
    "display(comment_vc.head({{ n_comments }}))\n",
    "display(comment_vc.tail({{ n_comments }}))\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "No need to run this locally, but useful for appyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(directory)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
