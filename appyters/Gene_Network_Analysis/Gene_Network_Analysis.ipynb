{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%appyter init\n",
    "from appyter import magic\n",
    "magic.init(lambda _=globals: _())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "\n",
    "<center> <h1> Gene Network Analysis</h1>\n",
    "<h3>An appyter for the visualization and analysis of gene networks and sub-clusters within gene sets.</h3></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objects as go\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from networkx.algorithms import community\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "from pyvis import network as net\n",
    "import random\n",
    "import unidecode\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter hide\n",
    "\n",
    "{% do SectionField(\n",
    "    name=\"GENES\",\n",
    "    title=\"Submit a gene list\",\n",
    ") %}\n",
    "\n",
    "\n",
    "{% set user_gene_lists = TextField(\n",
    "    name=\"user_gene_lists\",\n",
    "    label=\"Gene list(s)\",\n",
    "    description=\"Paste with a single gene on each line. Separate gene lists with two line breaks.\",\n",
    "    section=\"GENES\",\n",
    "    default=\"\",\n",
    ") %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "n_genes = {{ IntField(\n",
    "    name=\"n_genes\",\n",
    "    label=\"Minimum number of genes per cluster\",\n",
    "    section=\"GENES\",\n",
    "    default=20,\n",
    "    minimum=2,\n",
    "    maximum=1000000\n",
    ")}}\n",
    "\n",
    "gene_list_selection = '''{{ ChoiceField(\n",
    "    name = \"gene_list_selection\",\n",
    "    label=\"Sample gene lists to load\",\n",
    "    description=\"If not using your own gene lists, you can load examples.\",\n",
    "    section=\"GENES\",\n",
    "    default=\"SARS-CoV-2_down\",\n",
    "    choices=[\"SARS-CoV-2_down\"]\n",
    ")}}'''\n",
    "\n",
    "edge_types = {{ MultiCheckboxField(\n",
    "    name = \"edge_types\",\n",
    "    label=\"Types of edges to use to construct the network\",\n",
    "    section=\"GENES\",\n",
    "    default=[\"Gene-gene co-expression\",\"Protein-protein interactions\"],\n",
    "    choices=[\"Gene-gene co-expression\",\"Protein-protein interactions\"]\n",
    ")}}\n",
    "\n",
    "user_gene_lists = {{user_gene_lists}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "cloud_url = 'https://appyters.maayanlab.cloud/storage/Gene_Network_Analysis/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(edge_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "# Load gene lists\n",
    "{% if not user_gene_lists.value == \"\" %}\n",
    "gene_lists = {}\n",
    "\n",
    "for i, genes in enumerate(user_gene_lists.split(\"\\n\\n\")):\n",
    "    gene_lists[i] = genes.split(\"\\n\")\n",
    "    \n",
    "{% else %}\n",
    "if gene_list_selection == \"ULK4_293_coIP_hits\":\n",
    "    with open(\"ULK4_293_coIP_hits.txt\",\"r\") as f_in:\n",
    "        writer = csv.reader(f_in, lineterminator='\\n')\n",
    "        sample_genes = [item for sublist in writer for item in sublist if len(sublist) > 0]\n",
    "        gene_lists = [[ x.upper() for x in sample_genes ]]\n",
    "elif gene_list_selection == \"SARS-CoV-2_down\":\n",
    "    df_genes = pd.read_csv(cloud_url + \"gene_lists/SARS-CoV-2_down.csv\",header=None).drop(columns=[0,1])\n",
    "    df_genes = df_genes.transpose()\n",
    "    gene_lists = df_genes.to_dict(\"list\")\n",
    "    for k,v in gene_lists.items():\n",
    "        gene_lists[k] = [unidecode.unidecode(x) for x in v if isinstance(x, str)] # filter out NaNs  \n",
    "\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loaded {len(gene_lists)} gene lists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ppi_edges = pd.read_csv(cloud_url + 'ppi_edges_list.csv',header=None)\n",
    "df_gene_edges = pd.read_csv(cloud_url + 'top_500_correlation.csv')\n",
    "\n",
    "display(df_ppi_edges.head())\n",
    "print(\"PPI dataframe shape:\", df_ppi_edges.shape)\n",
    "display(df_gene_edges.head())\n",
    "print(\"Gene-gene coexpression dataframe shape:\",df_gene_edges.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppi_edges_dict = {}\n",
    "\n",
    "for index, row in df_ppi_edges.iterrows():\n",
    "    if row[0] in ppi_edges_dict:\n",
    "        ppi_edges_dict[row[0]].append(row[1])\n",
    "    else:\n",
    "        ppi_edges_dict[row[0]] = [row[1]]\n",
    "        \n",
    "gene_edges_dict = df_gene_edges.to_dict('list')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "def get_relevant_ppi_edges(gene_list):\n",
    "    edges = []\n",
    "    for gene in gene_list:\n",
    "        if gene in ppi_edges_dict:  \n",
    "            edges = [*edges,  *[(gene, x) for x in ppi_edges_dict[gene]]]\n",
    "    return edges\n",
    "\n",
    "def get_relevant_gene_edges(gene_list):\n",
    "    edges = []\n",
    "    for gene in gene_list:\n",
    "        if gene in gene_edges_dict:  \n",
    "            edges = [*edges,  *[(gene, x) for x in gene_edges_dict[gene]]]\n",
    "    return edges\n",
    "'''\n",
    "\n",
    "def get_relevant_ppi_edges(gene_list):\n",
    "    edges = []\n",
    "    missing = []\n",
    "    for gene_a in gene_list:\n",
    "        if gene_a in ppi_edges_dict:\n",
    "            for gene_b in ppi_edges_dict[gene_a]:\n",
    "                if gene_b == gene_a: continue\n",
    "                if gene_b in gene_list: edges.append((gene_a, gene_b))      \n",
    "        else: missing.append(gene_a)\n",
    "    return edges,missing\n",
    "\n",
    "def get_relevant_gene_edges(gene_list):\n",
    "    # use at most the top 3 edges for each gene.\n",
    "    edges = []\n",
    "    missing = []\n",
    "    for gene_a in gene_list:\n",
    "        gene_count = 0\n",
    "        if gene_a in gene_edges_dict:\n",
    "            for gene_b in gene_edges_dict[gene_a]:\n",
    "                if gene_count >= 3: break \n",
    "                if gene_b == gene_a: continue\n",
    "                if gene_b in gene_list: \n",
    "                    gene_count += 1\n",
    "                    edges.append((gene_a, gene_b))\n",
    "        else: missing.append(gene_a)\n",
    "    return edges,missing\n",
    "\n",
    "def pretty_heading(content):\n",
    "    num_dashes = len(content) + 2\n",
    "    num_dashes = max(30,num_dashes)\n",
    "    print(\"-\"*num_dashes)\n",
    "    print(content)\n",
    "    print(\"-\"*num_dashes)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "networks = {}\n",
    "clustering_coeffs = {}\n",
    "\n",
    "nums_missing_nodes = []\n",
    "\n",
    "for list_num, gene_list in gene_lists.items():\n",
    "\n",
    "    # create the Network object\n",
    "    pretty_heading(f\"Constructing network for gene list {list_num}\")\n",
    " \n",
    "    ppi_edges,ppi_missing = get_relevant_ppi_edges(gene_list)\n",
    "    gene_edges,gene_missing = get_relevant_gene_edges(gene_list)\n",
    "    \n",
    "    print(\"Missing PPI nodes:\\n\\n\", ppi_missing, \"\\n\")\n",
    "    print(\"Missing gene-gene co-expression nodes:\\n\\n\", gene_missing, \"\\n\")\n",
    "    \n",
    "    both_missing = set(ppi_missing).intersection(set(gene_missing))\n",
    "    print(\"Missing nodes for both types of edges:\\n\\n\", both_missing, \"\\n\")\n",
    "        \n",
    "    G = nx.Graph(name=list_num)\n",
    "    G.add_nodes_from(gene_list)\n",
    "    \n",
    "    if \"Protein-protein interactions\" in edge_types:\n",
    "        G.add_edges_from(ppi_edges,edge_type=\"PPI\")\n",
    "\n",
    "    if \"Gene-gene co-expression\" in edge_types:\n",
    "        G.add_edges_from(gene_edges,edge_type=\"Coexpression\")\n",
    "        \n",
    "    hits = []\n",
    "    \n",
    "    for edge in G.edges:\n",
    "        hits.append(edge[0])\n",
    "        hits.append(edge[1])\n",
    "        \n",
    "    num_missing = len(gene_list) - len(list(set(hits)))\n",
    "    print(num_missing, \" disconnected or missing nodes\\n\")\n",
    "    nums_missing_nodes.append(num_missing)\n",
    "  \n",
    "    print(nx.info(G), \"\\n\")\n",
    "    \n",
    "    networks[list_num] = G\n",
    "    clustering_coeffs[list_num] = nx.average_clustering(G)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute clusters\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering\n",
    "all_clusters = {}\n",
    "num_clusters_by_method = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-clique communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clusters[\"k_clique_communities\"] = {}\n",
    "\n",
    "for num, G in networks.items():\n",
    "\n",
    "    pretty_heading(f\"Computing k_clique_communities for gene list {num}\")\n",
    "    \n",
    "    c = list(community.k_clique_communities(G, 3)) \n",
    "    clusters = [ list(x) for x in c if len(x) > n_genes]\n",
    "    print(f\"Computed {len(clusters)} cluster(s)\\n\")\n",
    "    \n",
    "    print(\"Cluster sizes:\", [len(x) for x in clusters],\"\\n\")\n",
    "\n",
    "    all_clusters[\"k_clique_communities\"][num] = clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Girvan-Newman communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clusters[\"girvan_newman\"] = {}\n",
    "\n",
    "for num, G in networks.items():\n",
    "    pretty_heading(f\"Computing girvan_newman communities for gene list {num}\")\n",
    "\n",
    "    communities_generator = community.girvan_newman(G)\n",
    "    top_level_communities = next(communities_generator)\n",
    "    next_level_communities = next(communities_generator)\n",
    "    clusters = [ list(x) for x in next_level_communities if len(x) > n_genes ]\n",
    "    clusters = [ list(x) for x in clusters if len(x) > n_genes]\n",
    "    print(f\"Computed {len(clusters)} cluster(s)\\n\") \n",
    "    print(\"Cluster sizes:\", [len(x) for x in clusters],\"\\n\")\n",
    "    \n",
    "    all_clusters[\"girvan_newman\"][num] = clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy modularity communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clusters[\"greedy_modularity_communities\"] = {}\n",
    "\n",
    "for num, G in networks.items():\n",
    "    pretty_heading(f\"Computing greedy_modularity_communities for gene list {num}\")\n",
    "\n",
    "    clusters = list(community.greedy_modularity_communities(G))\n",
    "    clusters = [ list(x) for x in clusters if len(x) > n_genes]\n",
    "    \n",
    "    print(f\"Computed {len(clusters)} cluster(s)\\n\") \n",
    "    print(\"Cluster sizes:\", [len(x) for x in clusters],\"\\n\")\n",
    "    \n",
    "    all_clusters[\"greedy_modularity_communities\"][num] = clusters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clusters[\"connected_components\"] = {}\n",
    "# connected_components\n",
    "\n",
    "for num, G in networks.items():\n",
    "    pretty_heading(f\"Computing connected_components for gene list {num}\")\n",
    "    \n",
    "    components = sorted(nx.connected_components(G), key = len, reverse=True)\n",
    "    clusters = [ list(x) for x in components if len(x) > n_genes ]\n",
    "\n",
    "    print(f\"Computed {len(clusters)} cluster(s)\\n\") \n",
    "    print(\"Cluster sizes:\", [len(x) for x in clusters],\"\\n\")\n",
    "    \n",
    "    all_clusters[\"connected_components\"][num] = clusters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile all clustering results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cluster_dfs = {}\n",
    "\n",
    "clustering_results = []\n",
    "\n",
    "for clustering_method, gene_lists in all_clusters.items():\n",
    "    for num, clusters in gene_lists.items():\n",
    "        for index,cluster in enumerate(clusters):\n",
    "            for gene in cluster:\n",
    "                data = {\"gene\": gene, \"gene_list\": num, \"clustering_method\": clustering_method, \"cluster\": index}     \n",
    "                clustering_results.append(data)\n",
    "df_clusters = pd.DataFrame(clustering_results)\n",
    "\n",
    "display(df_clusters)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network visualizations\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nodes are color-coded by their `greedy_modularity_communities` cluster membership."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate colors to color code clusters\n",
    "def random_color():\n",
    "    hex_number = \"#000000\"\n",
    "    while hex_number == \"#000000\":\n",
    "        hex_number = \"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)])\n",
    "    return hex_number\n",
    "\n",
    "cluster_color_dict = {}\n",
    "edge_color_dict = {\"PPI\": \"#bd34eb\", \"Coexpression\": \"#2dc2b0\"}\n",
    "\n",
    "def color_by_cluster(cluster):\n",
    "    if not cluster in cluster_colors:\n",
    "        cluster_color_dict[cluster] = random_color()\n",
    "    return cluster_color_dict[cluster]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# networkx and plotly code\n",
    "def network_graph(num, G, df):\n",
    " \n",
    "    pos = nx.spring_layout(G,k=1,iterations=800)\n",
    "    for n, p in pos.items():\n",
    "        G.nodes[n]['pos'] = p\n",
    "\n",
    "    edge_x = {\"PPI\": [], \"Coexpression\": []}\n",
    "    edge_y = {\"PPI\": [], \"Coexpression\": []}\n",
    "\n",
    "    for edge in G.edges.data():\n",
    "        x0, y0 = G.nodes[edge[0]]['pos']\n",
    "        x1, y1 = G.nodes[edge[1]]['pos']\n",
    "\n",
    "        edge_type = edge[2]['edge_type']\n",
    "        edge_x[edge_type].append(x0)\n",
    "        edge_x[edge_type].append(x1)\n",
    "        edge_x[edge_type].append(None)\n",
    "        edge_y[edge_type].append(y0)\n",
    "        edge_y[edge_type].append(y1)\n",
    "        edge_y[edge_type].append(None)\n",
    "\n",
    "    ppi_edge_trace = go.Scatter(\n",
    "        x=edge_x[\"PPI\"], y=edge_y[\"PPI\"],\n",
    "        line=dict(width=1, color=edge_color_dict[\"PPI\"]),\n",
    "        hoverinfo='none',\n",
    "        mode='lines',\n",
    "        name=\"Protein-protein interaction\")\n",
    "\n",
    "    coexp_edge_trace = go.Scatter(\n",
    "        x=edge_x[\"Coexpression\"], y=edge_y[\"Coexpression\"],\n",
    "        line=dict(width=1, color=edge_color_dict[\"Coexpression\"]),\n",
    "        hoverinfo='none',\n",
    "        mode='lines',\n",
    "        name=\"Gene-gene coexpression\")\n",
    "\n",
    "    # dicts mapping clusters to relevant node info\n",
    "    node_x = {}\n",
    "    node_y = {}\n",
    "    gene_names = {}\n",
    "    \n",
    "    cluster_node_data = {}\n",
    "    cluster_node_data[\"not assigned\"] = {\"x\": [], \"y\": [], 'color': \"#c5d0d1\", 'genes': []}\n",
    "\n",
    "    for node in G.nodes():\n",
    "        cluster = df[df[\"gene\"] == node][\"cluster\"].values\n",
    "        if len(cluster) > 0:\n",
    "            cluster = cluster[0]\n",
    "            if cluster not in cluster_node_data:\n",
    "                cluster_node_data[cluster] = {\n",
    "                    'x': [], \n",
    "                    'y': [], \n",
    "                    'color': \"\", #color_by_cluster(cluster), \n",
    "                    'genes': []\n",
    "                }\n",
    "        else:\n",
    "            cluster = \"not assigned\"\n",
    "\n",
    "        x, y = G.nodes[node]['pos']\n",
    "        cluster_node_data[cluster]['x'].append(x)\n",
    "        cluster_node_data[cluster]['y'].append(y)\n",
    "        cluster_node_data[cluster]['genes'].append(node)\n",
    "        \n",
    "    \n",
    "    cluster_node_data_sorted = {k: v for k, v in sorted(cluster_node_data.items(),\n",
    "                                                       key= lambda x: str(x)) if k != 'not assigned'}\n",
    "    cluster_node_data_sorted['not assigned'] = cluster_node_data['not assigned']\n",
    "    \n",
    "    node_traces = []\n",
    "    for cluster, data in cluster_node_data_sorted.items():\n",
    "        trace = go.Scatter(\n",
    "                    x=data['x'], \n",
    "                    y=data['y'],\n",
    "                    mode='markers',\n",
    "                    hoverinfo='text',\n",
    "                    text=data['genes'],\n",
    "                    name=str(cluster),\n",
    "                    textposition='middle center',\n",
    "                    marker=dict(\n",
    "                        showscale=False,\n",
    "                        reversescale=True,\n",
    "                        size=10,\n",
    "                        line_width=2))\n",
    "        if cluster == 'not assigned':\n",
    "            trace.marker.color = data['color']\n",
    "        \n",
    "        node_traces.append(trace)\n",
    "\n",
    "    fig = go.Figure(\n",
    "        data=[ppi_edge_trace, coexp_edge_trace, *node_traces],\n",
    "        layout=go.Layout(\n",
    "            title=f\"Gene list {num + 1}<br>\",\n",
    "            titlefont_size=16,\n",
    "            showlegend=True,\n",
    "            hovermode='closest',\n",
    "            margin=dict(b=10,l=5,r=5,t=40),\n",
    "            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)))\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num, G in networks.items():\n",
    "    clustering_coeff = nx.average_clustering(G)\n",
    "    print(\"Average clustering: \",clustering_coeff)\n",
    "    for clustering_method in df_clusters['clustering_method'].unique():\n",
    "        if not clustering_method == 'greedy_modularity_communities': continue\n",
    "        df_method = df_clusters[df_clusters[\"clustering_method\"] == clustering_method]\n",
    "        df_method = df_method[df_method[\"gene_list\"] == num] \n",
    "        #display(df_method)\n",
    "\n",
    "        network_graph(num,G,df_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of clustering coefficients to numbers of clusters computed\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compule the numbers of clusters computed by each method for each gene list\n",
    "\n",
    "cluster_counts = {}\n",
    "\n",
    "for method, network_clusters in all_clusters.items():\n",
    "    cluster_counts[method] = []\n",
    "    for i, clusters in network_clusters.items():\n",
    "        cluster_counts[method].append(len(clusters))\n",
    "\n",
    "print(cluster_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [(gene_list + 1, method, count) for method, counts in cluster_counts.items() for gene_list, count in enumerate(counts) ]\n",
    "\n",
    "df_cluster_counts = pd.DataFrame(x, columns = [\"Gene list\",\"Method\", \"Number of clusters\"])\n",
    "display(df_cluster_counts)\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.barplot(x=\"Gene list\", hue=\"Method\", y=\"Number of clusters\", data=df_cluster_counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation of cluster quality with Enrichr scores\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation with Enrichr\n",
    "enrichr_libraries = OrderedDict([\n",
    "    ('Ontologies', ['GO_Biological_Process_2018']),\n",
    "])\n",
    "\n",
    "# Util functions\n",
    "def enrichr_link_from_genes(genes, description='', enrichr_link='https://amp.pharm.mssm.edu/Enrichr'):\n",
    "    ''' Functional access to Enrichr API\n",
    "    '''\n",
    "    time.sleep(1)\n",
    "    resp = requests.post(enrichr_link + '/addList', files={\n",
    "    'list': (None, '\\n'.join(genes)),\n",
    "    'description': (None, description),\n",
    "    })\n",
    "    if resp.status_code != 200:\n",
    "        raise Exception('Enrichr failed with status {}: {}'.format(\n",
    "          resp.status_code,\n",
    "          resp.text,\n",
    "        ))\n",
    "    # wait a tinybit before returning link (backoff)\n",
    "    time.sleep(1)\n",
    "    result = resp.json()\n",
    "    return dict(result, link=enrichr_link + '/enrich?dataset=' + resp.json()['shortId'])\n",
    "\n",
    "def enrichr_get_top_results(userListId, bg, enrichr_link='https://amp.pharm.mssm.edu/Enrichr'):\n",
    "    time.sleep(1)\n",
    "    resp = requests.get(enrichr_link + '/enrich?userListId={}&backgroundType={}'.format(userListId, bg))\n",
    "    if resp.status_code != 200:\n",
    "        raise Exception('Enrichr failed with status {}: {}'.format(\n",
    "          resp.status_code,\n",
    "          resp.text,\n",
    "        ))\n",
    "    time.sleep(1)\n",
    "    return pd.DataFrame(resp.json()[bg], columns=['rank', 'term', 'pvalue', 'zscore', 'combinedscore', 'overlapping_genes', 'adjusted_pvalue', '', ''])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Enrichr links for each method, for each gene list, for each cluster\n",
    "enrichr_links = {}\n",
    "\n",
    "for clustering_method, cluster_groups in all_clusters.items():\n",
    "    enrichr_links[clustering_method] = {}\n",
    "    for num, clusters in cluster_groups.items():\n",
    "        enrichr_links[clustering_method][num]  = {}\n",
    "        for index, genes in enumerate(clusters):\n",
    "            try:\n",
    "                link = enrichr_link_from_genes(genes, f'gene list {num}, {clustering_method} cluster {index}')\n",
    "            except:\n",
    "                link = None\n",
    "                print(f'Enrichr failed for {clustering_method}, cluster {index} genes')\n",
    "\n",
    "            enrichr_links[clustering_method][num][index] = link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis parameters\n",
    "top_n_results = 5\n",
    "num_overall_results = 100\n",
    "sort_by = 'combinedscore'\n",
    "\n",
    "# Grab top results for each cluster\n",
    "all_enrichr_results = []\n",
    "\n",
    "for clustering_method, cluster_groups in enrichr_links.items():\n",
    "    if clustering_method == 'overall': continue\n",
    "    for num, links in cluster_groups.items():\n",
    "        num_clusters = len(all_clusters[clustering_method][num])\n",
    "        if num_clusters == 0: continue\n",
    "        top_n_results = int(num_overall_results / num_clusters)\n",
    "        for cluster, link in links.items():\n",
    "            if link is None:\n",
    "                continue\n",
    "            for category, libraries in enrichr_libraries.items():\n",
    "                for library in libraries:\n",
    "                    try:\n",
    "                        results = enrichr_get_top_results(link['userListId'], library).sort_values(sort_by).iloc[:top_n_results]\n",
    "                        results['clustering_method'] = clustering_method\n",
    "                        results['gene_list'] = num\n",
    "                        results['link'] = link['link']\n",
    "                        results['library'] = library\n",
    "                        results['category'] = category\n",
    "                        results['cluster'] = cluster\n",
    "                        all_enrichr_results.append(results)\n",
    "                    except:\n",
    "                        print('{}: {} {} {} gene list {} cluster {} failed, continuing'.format(link, library, category, clustering_method, num, cluster))\n",
    "\n",
    "df_clustering_enrichr = pd.concat(all_enrichr_results).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_clustering_enrichr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_terms = {}\n",
    "num_unique_terms = []\n",
    "\n",
    "num_unique_hits = []\n",
    "\n",
    "for clustering_method in [ x for x in df_clustering_enrichr[\"clustering_method\"].unique() if x != \"overall\"]:\n",
    "    df_method = df_clustering_enrichr.loc[df_clustering_enrichr[\"clustering_method\"] == clustering_method]\n",
    "    \n",
    "    terms = df_method[\"term\"].values    \n",
    "    unique = list(set(terms))\n",
    "    num_unique_terms.append(len(unique))\n",
    "    unique_terms[clustering_method] = unique\n",
    "    \n",
    "    hits = df_method.shape[0]\n",
    "    num_unique_hits.append(hits)\n",
    "\n",
    "\n",
    "\n",
    "# avg number of unique terms per method\n",
    "avg_unique_terms = int(np.mean(np.array(num_unique_terms)))\n",
    "print(\"Average unique terms per clustering method: \", avg_unique_terms)\n",
    "\n",
    "# avg number of enrichr entries per method\n",
    "avg_hits = int(np.mean(np.array(num_unique_hits)))\n",
    "print(\"Average hits per clustering method: \", avg_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data on the overall gene sets\n",
    "\n",
    "overall_results = []\n",
    "num_results = int(avg_hits / len(gene_lists))\n",
    "\n",
    "for num, genes in gene_lists.items():\n",
    "    print(genes)\n",
    "    for category, libraries in enrichr_libraries.items():\n",
    "        for library in libraries:\n",
    "             try:\n",
    "                link = enrichr_link_from_genes(genes, 'overall')\n",
    "                results = enrichr_get_top_results(link['userListId'], library).sort_values(sort_by).iloc[:top_n_results]\n",
    "                results['gene_list'] = num\n",
    "                results['clustering_method'] = 'overall'\n",
    "                results['link'] = link['link']\n",
    "                results['library'] = library\n",
    "                results['category'] = category\n",
    "                results['cluster'] = \"\"\n",
    "                overall_results.append(results)\n",
    "            except:\n",
    "                print('Failed to get Enrichr results for overall gene set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clustering_enrichr = pd.concat(all_enrichr_results).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overall_results = pd.concat(overall_results)\n",
    "\n",
    "df_overall_results = df_overall_results.loc[:,[ x for x in df_overall_results.columns if x != \"\"]]\n",
    "\n",
    "df_clustering_enrichr = df_clustering_enrichr.loc[:,[ x for x in df_clustering_enrichr.columns if x != \"\"]]\n",
    "\n",
    "df_enrichr_results = pd.concat([df_overall_results,df_clustering_enrichr]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accumulate results for each method\n",
    "neg_log_pvalues = {}\n",
    "combined_scores = {}\n",
    "\n",
    "for clustering_method in df_enrichr_results[\"clustering_method\"].unique():\n",
    "    df_method = df_enrichr_results.loc[df_enrichr_results[\"clustering_method\"] == clustering_method]\n",
    "    vals = df_method[\"pvalue\"].values\n",
    "    neg_log_pvalues[clustering_method] = [ -math.log(p) for p in vals]\n",
    "    combined_scores[clustering_method] = df_method[\"combinedscore\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accumulate results for each cluster\n",
    "neg_log_pvalues_cluster = {}\n",
    "combined_scores_cluster = {}\n",
    "\n",
    "for gene_list in df_enrichr_results[\"gene_list\"].unique():\n",
    "    neg_log_pvalues_cluster[gene_list] = {}\n",
    "    combined_scores_cluster[gene_list] = {}\n",
    "                    \n",
    "    df_gene_list = df_enrichr_results.loc[df_enrichr_results[\"gene_list\"] == gene_list]\n",
    "    \n",
    "    for clustering_method in df_gene_list[\"clustering_method\"].unique():\n",
    "        \n",
    "        df_method = df_gene_list.loc[df_gene_list[\"clustering_method\"] == clustering_method]        \n",
    "        if clustering_method == \"overall\":\n",
    "            title = \"Overall\"\n",
    "            \n",
    "            vals = df_method[\"pvalue\"].values\n",
    "\n",
    "            neg_log_pvalues_cluster[gene_list][title] = [ -math.log(p) for p in vals]\n",
    "            combined_scores_cluster[gene_list][title] = df_cluster[\"combinedscore\"].values\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            for cluster in df_method[\"cluster\"].unique():\n",
    "                \n",
    "                title = f'{clustering_method}, cluster {cluster}'\n",
    "                \n",
    "                df_cluster = df_method[df_method[\"cluster\"] == cluster]\n",
    "                vals = df_cluster[\"pvalue\"].values\n",
    "\n",
    "                neg_log_pvalues_cluster[gene_list][title] = [ -math.log(p) for p in vals]\n",
    "                combined_scores_cluster[gene_list][title] = df_cluster[\"combinedscore\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot one distribution per method and cluster\n",
    "\n",
    "for gene_list, methods in neg_log_pvalues_cluster.items():\n",
    "    print(f\"Gene list {gene_list}\")\n",
    "    num_plots = len(methods) \n",
    "    num_rows = int(math.ceil(num_plots / 2))\n",
    "    count = 1\n",
    "    fig = plt.figure(figsize=(15,5*num_rows))    \n",
    "    for method, data in methods.items():\n",
    "        \n",
    "    \n",
    "        ax = fig.add_subplot(num_rows,2,count)\n",
    "        sns.distplot(data, ax=ax)\n",
    "        ax.set_title(method)\n",
    "        ax.set_xlabel(\"-log (p-value)\")\n",
    "        ax.set_ylabel(\"Frequency\")\n",
    "        plt.xlim([-1,10]) \n",
    "        \n",
    "        count += 1\n",
    "    fig.tight_layout(pad=3, w_pad=2, h_pad=6)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlay the kernel density estimates of combined scores on a single plot\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "for clustering_method, y in combined_scores.items():\n",
    "    fig, ax = plt.subplots(figsize=(7,5))\n",
    "    sns.kdeplot(y, neg_log_pvalues[clustering_method], label=clustering_method,shade=True)\n",
    "    ax.set_title(clustering_method)\n",
    "    ax.set_xlabel(\"Combined score\")\n",
    "    ax.set_ylabel(\"-log(p-value)\")\n",
    "    ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlay the kernel density estimates of combined scores on a single plot\n",
    "# for each cluster\n",
    "for gene_list, methods in combined_scores_cluster.items():\n",
    "    print(f\"Gene list {gene_list}\")\n",
    "    num_plots = len(methods) \n",
    "    num_rows = int(math.ceil(num_plots / 2))\n",
    "    count = 1\n",
    "    fig = plt.figure(figsize=(15,5*num_rows))    \n",
    "    for method, data in methods.items():\n",
    "        ax = fig.add_subplot(num_rows,2,count)\n",
    "        sns.kdeplot(data, neg_log_pvalues_cluster[gene_list][method], label=method,shade=True)\n",
    "        ax.set_title(method)\n",
    "        ax.set_xlabel(\"Combined score\")\n",
    "        ax.set_ylabel(\"-log(p-value)\")\n",
    "        ax.legend()\n",
    "        count += 1\n",
    "    fig.tight_layout(pad=3, w_pad=2, h_pad=6)\n",
    "    plt.show()\n",
    "'''\n",
    "\n",
    "for cluster, y in combined_scores_cluster.items():\n",
    "    print(len(y))\n",
    "    fig, ax = plt.subplots(figsize=(7,5))\n",
    "    sns.kdeplot(y, neg_log_pvalues_cluster[cluster], label=cluster,shade=True)\n",
    "    ax.set_title(cluster)\n",
    "    ax.set_xlabel(\"Combined score\")\n",
    "    ax.set_ylabel(\"-log(p-value)\")\n",
    "    ax.legend()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter hide_code\n",
    "\n",
    "'''\n",
    "cluster_colors = {}\n",
    "edge_colors = {\"PPI\": \"#bd34eb\", \"Coexpression\": \"#2dc2b0\"}\n",
    "\n",
    "os.makedirs(\"network_visualizations/PPI_and_coexpression_graphs\",exist_ok=True)\n",
    "os.makedirs(\"network_visualizations/PPI\",exist_ok=True)\n",
    "os.makedirs(\"network_visualizations/coexpression\",exist_ok=True)\n",
    "\n",
    "folder = \"./network_visualizations/\"\n",
    "\n",
    "if len(edge_types) == 2:\n",
    "    folder += \"PPI_and_coexpression_graphs\"\n",
    "elif \"Protein-protein interactions\" in edge_types:\n",
    "    folder += \"PPI\"\n",
    "elif \"Gene-gene co-expression\" in edge_types:\n",
    "    folder += \"coexpression\"\n",
    "\n",
    "# make the clustering method graphs\n",
    "for num, G in networks.items():\n",
    "    for clustering_method in df_clusters.clustering_method.unique():\n",
    "        \n",
    "        df_method = df_clusters[df_clusters[\"clustering_method\"] == clustering_method]\n",
    "        df_method = df_method[df_method[\"gene_list\"] == num]\n",
    "    \n",
    "        nt = net.Network(width=\"100%\", height = 800, notebook=True)\n",
    "        nt.from_nx(G)\n",
    "        # nt.show_buttons()\n",
    "        for node in nt.nodes:\n",
    "            cluster = df_method[df_method[\"gene\"] == node[\"id\"]]\n",
    "            if cluster.shape[0] == 0: node[\"color\"] = \"#000\"\n",
    "            else: \n",
    "                #print(cluster)\n",
    "                cluster_num = cluster[\"cluster\"].values[0]\n",
    "                if not cluster_num in cluster_colors:\n",
    "                    cluster_colors[cluster_num] = random_color()\n",
    "                \n",
    "                node[\"color\"] = cluster_colors[cluster_num]\n",
    "                \n",
    "        for edge in nt.edges:\n",
    "            edge[\"color\"] = edge_colors[edge[\"edge_type\"]]\n",
    "            edge[\"title\"] = edge[\"edge_type\"]\n",
    "        nt.prep_notebook()\n",
    "        display(f\"Gene list {num}, {clustering_method}\")\n",
    "        display(nt.show(f\"{folder}/graph_{num}_{clustering_method}.html\"))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison to [STRING](https://string-db.org) results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison to STRING results\n",
    "\n",
    "print(\"Calculating number of missed genes in each STRING network:\\n\\n\")\n",
    "string_api_url = \"https://string-db.org/api\"\n",
    "output_format = \"json\"\n",
    "method = \"interaction_partners\"\n",
    "\n",
    "request_url = \"https://string-db.org/api/json/network\"\n",
    "nums_misses_string = []\n",
    "\n",
    "for num, genes in gene_lists.items():\n",
    "    print(\"List \", num + 1)\n",
    "    params = {\n",
    "        \"identifiers\" : \"%0d\".join(genes), # your protein\n",
    "        \"species\": 9606\n",
    "    }\n",
    "    \n",
    "    hits = set()\n",
    "    \n",
    "    response = requests.post(request_url, data=params)\n",
    "    data = response.json()\n",
    "    for interaction in data:\n",
    "        hits.add(interaction[\"preferredName_A\"])\n",
    "        hits.add(interaction[\"preferredName_B\"])\n",
    "    \n",
    "    misses = set()\n",
    "    \n",
    "    for gene in genes:\n",
    "        if gene not in hits:\n",
    "            misses.add(gene)\n",
    "    \n",
    "    print(f\"{len(genes) - len(hits)} gene misses out of {len(genes)}\\n\")\n",
    "    nums_misses_string.append(len(genes) - len(hits))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare missing/disconnected nodes in our network to those in STRING\n",
    "\n",
    "%matplotlib inline\n",
    "gene_list_sizes = [len(v) for k,v in gene_lists.items()]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "\n",
    "ind = np.arange(1,len(gene_lists)+1) \n",
    "width = 0.35   \n",
    "\n",
    "bar1 = plt.bar(ind,nums_misses_string,width, label=\"STRING misses\",color=\"#bd34eb\")\n",
    "bar2 = plt.bar(ind + width,nums_missing_nodes,width, label=\"Our misses\",color=\"#2dc2b0\")\n",
    "plt.xticks(ind + width / 2, ind)\n",
    "plt.legend(loc='best')\n",
    "ax.set_ylabel(\"Number of disconnected nodes\")\n",
    "ax.set_xlabel(\"Gene list\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
