{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%appyter init\n",
    "from appyter import magic\n",
    "magic.init(lambda _=globals: _())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter hide_code\n",
    "{% do SectionField(\n",
    "  name='primary',\n",
    "  title='C2M2 FAIR Assessment',\n",
    "  subtitle='Assessing c2m2 datapackages for FAIRness',\n",
    "  img='insignia.png',\n",
    ") %}\n",
    "\n",
    "{% set file = FileField(\n",
    "  name='file',\n",
    "  label='A zipped [C2M2 Datapackage](https://docs.nih-cfde.org/en/latest/c2m2/draft-C2M2_specification/)',\n",
    "  help='Provide your zipped c2m2 datapackage',\n",
    "  examples={'example.zip': url_for('static', path='example.zip')},\n",
    "  default='example.zip',\n",
    "  section='primary',\n",
    ") %}\n",
    "\n",
    "{% set skip_landing = BoolField(\n",
    "  name='skip_landing',\n",
    "  label='Skip the landing page check',\n",
    "  default=True,\n",
    "  section='primary',\n",
    ") %}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C2M2 Assessment\n",
    "\n",
    "We perform a file-centric FAIR Assessment on all files defined in a [C2M2 datapackage](https://docs.nih-cfde.org/en/latest/c2m2/draft-C2M2_specification/) according to the [C2M2 Rubric](https://fairshake.cloud/rubric/36); descriptions of each metric and how we assess them are provided below, along with the actual code to perform the assesssment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from textwrap import dedent\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_and_only(it):\n",
    "  ''' Select one and only item from an iterable, otherwise throw an exception.\n",
    "  '''\n",
    "  it = iter(it)\n",
    "  ret = next(it)\n",
    "  try:\n",
    "    next(it)\n",
    "    raise Exception('Expected one')\n",
    "  except StopIteration:\n",
    "    return ret\n",
    "\n",
    "def deep_find(root, file):\n",
    "  ''' Helper for finding a filename in a potentially deep directory\n",
    "  '''\n",
    "  return set(glob.glob(os.path.join(root, '**', file), recursive=True))\n",
    "\n",
    "def fetch_cache(url, filename, cachedir='.cached'):\n",
    "  ''' Download a {file} from a {url} if it hasn't already been downloaded, storing it in {cachedir}.\n",
    "  '''\n",
    "  import os, urllib.request\n",
    "  os.makedirs(cachedir, exist_ok=True)\n",
    "  if not os.path.exists(os.path.join(cachedir, filename)):\n",
    "    urllib.request.urlretrieve(url, filename=os.path.join(cachedir, filename))\n",
    "  return os.path.join(cachedir, filename)\n",
    "\n",
    "def url_join(*args):\n",
    "  ''' Join urls by slashes, not worrying about duplicated trailing slashes\n",
    "  '''\n",
    "  return '/'.join([arg.rstrip('/') for arg in args[:-1]]+[args[-1]])\n",
    "\n",
    "def filter_empty(val):\n",
    "  ''' Attempt to catch some actual null values that aren't really null.\n",
    "  '''\n",
    "  return [\n",
    "    v\n",
    "    for v in val\n",
    "    if v is not None and (\n",
    "      type(v) != str or v.strip().lower() not in {\n",
    "        '-',\n",
    "        '-666',\n",
    "        '',\n",
    "        'empty',\n",
    "        'n/a',\n",
    "        'na',\n",
    "        'nan',\n",
    "        'nil',\n",
    "        'none',\n",
    "        'not defined',\n",
    "        'null',\n",
    "        'undef',\n",
    "        'undefined',\n",
    "      }\n",
    "    )\n",
    "  ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Load DERIVA compatible client from URL or datapackage\n",
    "\n",
    "Given a datapackage, access it through DERIVA-compatible client. This client package <https://github.com/nih-cfde/deriva-datapackage> permits accessing offline datapackages in the same way that the online DERIVA client operates, thus the assessment can be performed online or offline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "import zipfile\n",
    "import tempfile\n",
    "\n",
    "file = {{ file }}\n",
    "basename, ext = os.path.splitext(file)\n",
    "assert ext == '.zip', 'Expected .zip file'\n",
    "directory = tempfile.mkdtemp()\n",
    "\n",
    "with zipfile.ZipFile(file, 'r') as z:\n",
    "  z.extractall(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deriva_datapackage import create_offline_client\n",
    "\n",
    "# sometimes zip files zip the leading directory, which may be named anything,\n",
    "#  deep_find lets us locate the datapackage wherever it is.\n",
    "CFDE = create_offline_client(\n",
    "    *(\n",
    "      deep_find(directory, 'C2M2_datapackage.json')\n",
    "      | deep_find(directory, 'datapackage.json')\n",
    "    ),\n",
    "    cachedir=directory,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Compute and report global metrics about the datapackage\n",
    "\n",
    "### Table 1: Entity Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_files = CFDE.tables['file'].count()\n",
    "total_collections = CFDE.tables['collection'].count()\n",
    "total_biosamples = CFDE.tables['biosample'].count()\n",
    "total_subjects = CFDE.tables['subject'].count()\n",
    "total_projects = CFDE.tables['project'].count()\n",
    "entity_counts = pd.Series({\n",
    "  name: table.count()\n",
    "  for name, table in CFDE.tables.items()\n",
    "}).to_frame('Entity Counts')\n",
    "entity_counts.to_csv('entity-counts.tsv', sep='\\t')\n",
    "entity_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Compute and report metric compliance for the datapackage\n",
    "\n",
    "We use a python decorator for registering each metric into the rubric. This lets us define each metric in its own cell with its description and code to assert it. Because of the nature of these assertions, assessments are performed as metrics are registered. This assessment is datapackage-centric rather than file centric.\n",
    "\n",
    "This paradigm can be used for any rubric allowing assessment code to remain the same even with changing metrics, furthermore this is compatible with [FAIRshake](https://fairshake.cloud/) assessments, adopting FAIRshake metric identifiers allowing the results to be easily registered with FAIRshake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rubric = {\n",
    "  '@id': 36,\n",
    "  'name': 'NIH CFDE Interoperability',\n",
    "  'description': 'This rubric identifies aspects of the metadata models which promote interoperable dataset querying and filtering',\n",
    "  'metrics': {},\n",
    "}\n",
    "answers = []\n",
    "\n",
    "def _rbInterpolate(value):\n",
    "  if pd.isna(value): return f\"#666666\"\n",
    "  r, g, b = int(255. * (1-value)), 0, int(255. * value)\n",
    "  return f\"{r:02x}{g:02x}{b:02x}\"\n",
    "\n",
    "def _asPct(value):\n",
    "  if pd.isna(value):\n",
    "    return \"NaN\"\n",
    "  else:\n",
    "    return f\"{value*100:.2f}%\"\n",
    "\n",
    "def _register_metric_answer(schema):\n",
    "  global metrics\n",
    "  global answers\n",
    "  def wrapper(func):\n",
    "    rubric['metrics'][schema['@id']] = dict(schema, func=func)\n",
    "    link = '' if schema['@id'] < 0 else f\" ([{schema['@id']}](https://fairshake.cloud/metric/{schema['@id']}))\"\n",
    "    display(Markdown(dedent(f'''\n",
    "      ### Metric{link}: {schema['name']}\n",
    "      **{schema['description']}**\n",
    "\n",
    "      {schema['detail']}\n",
    "    ''')))\n",
    "    answer = dict(func(), metric=schema['@id'])\n",
    "    answers.append(answer)\n",
    "    display(Markdown(dedent(f'''\n",
    "      #### Results: <span style=\"font-weight: bold; color: #{_rbInterpolate(answer['value'])}\">{_asPct(answer['value'])}</span> '''\n",
    "    ) + dedent(answer['comment'])))\n",
    "  setattr(wrapper, '__name__', schema['name'])\n",
    "  return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric_answer({\n",
    "  # standardized metadata format (107), machine readable metadata (106)\n",
    "  # metadata license (117) (c2m2 ?)\n",
    "  '@id': 106,\n",
    "  'name': 'Metadata conformance',\n",
    "  'description': 'The metadata properly conforms with the CFDE perscribed metadata model specification',\n",
    "  'detail': '''The average metadata coverage of all tables''',\n",
    "  'principle': 'Findable',\n",
    "})\n",
    "def _():\n",
    "  display(Markdown('### Table 2. Metadata Coverage'))\n",
    "  coverage = pd.DataFrame(\n",
    "    dict(\n",
    "      table=table_name,\n",
    "      coverage=len(list(filter_empty(entity.values()))) / len(table.column_definitions.keys()),\n",
    "    )\n",
    "    for table_name, table in CFDE.tables.items()\n",
    "    for entity in table.entities()\n",
    "  ).groupby('table')['coverage'].describe().fillna(0).sort_values('mean')\n",
    "  coverage.to_csv('coverage.tsv', sep='\\t')\n",
    "  display(coverage)\n",
    "  value = coverage['mean'].mean()\n",
    "  return {\n",
    "    'value': value,\n",
    "    'comment': f'(See metadata coverage for more info)',\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Help us identify other acceptible globally unique persistent and valid identifiers\n",
    "@_register_metric_answer({\n",
    "  # Persistent identifier (105)\n",
    "  '@id': 104,\n",
    "  'name': 'Persistent identifier',\n",
    "  'description': 'Globally unique, persistent, and valid identifiers (preferrably DOIs) are present for the dataset',\n",
    "  'detail': '''We check that the persistent id that are present are DOIs.''',\n",
    "  'principle': 'Findable',\n",
    "})\n",
    "def _():\n",
    "  qualified_persistent_ids = pd.Series({\n",
    "    (file['id_namespace'], file['local_id'], file.get('persistent_id')): 1 if file.get('persistent_id') and re.match(r'^https?://[^/]+\\.doi\\.org/.+$', file['persistent_id']) else 0\n",
    "    for file in CFDE.tables['file'].entities()\n",
    "  }).sort_values()\n",
    "  display(qualified_persistent_ids)\n",
    "  total_qualified_persistent_ids = qualified_persistent_ids.sum()\n",
    "  value = (total_qualified_persistent_ids / total_files) if total_files else float('nan')\n",
    "  return {\n",
    "    'value': value,\n",
    "    'comment': f'({total_qualified_persistent_ids} / {total_files})',\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric_answer({\n",
    "  '@id': -1,\n",
    "  'name': 'ratio files are associated with data type term',\n",
    "  'description': '',\n",
    "  'detail': '',\n",
    "  'principle': '',\n",
    "})\n",
    "def _():\n",
    "  total_files_associated_with_data_type = CFDE.tables['data_type'] \\\n",
    "    .link(CFDE.tables['file'], on=(\n",
    "      CFDE.tables['file'].data_type == CFDE.tables['data_type'].id\n",
    "    )) \\\n",
    "    .groupby(CFDE.tables['file'].id_namespace, CFDE.tables['file'].local_id) \\\n",
    "    .count()\n",
    "  value = (total_files_associated_with_data_type / total_files) if total_files else float('nan')\n",
    "  return {\n",
    "    'value': value,\n",
    "    'comment': f\"({total_files_associated_with_data_type} / {total_files})\",\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric_answer({\n",
    "  '@id': -2,\n",
    "  'name': 'ratio files are associated with file format term',\n",
    "  'description': '',\n",
    "  'detail': '',\n",
    "  'principle': '',\n",
    "})\n",
    "def _():\n",
    "  total_files_associated_with_file_format = CFDE.tables['file_format'] \\\n",
    "    .link(CFDE.tables['file'], on=(\n",
    "      CFDE.tables['file'].file_format == CFDE.tables['file_format'].id\n",
    "    )) \\\n",
    "    .groupby(CFDE.tables['file'].id_namespace, CFDE.tables['file'].local_id) \\\n",
    "    .count()\n",
    "  value = (total_files_associated_with_file_format / total_files) if total_files else float('nan')\n",
    "  return {\n",
    "    'value': value,\n",
    "    'comment': f\"({total_files_associated_with_file_format} / {total_files})\",\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric_answer({\n",
    "  '@id': -3,\n",
    "  'name': 'ratio files are associated with assaytype term',\n",
    "  'description': '',\n",
    "  'detail': '',\n",
    "  'principle': '',\n",
    "})\n",
    "def _():\n",
    "  total_files_associated_with_assay_type = CFDE.tables['assay_type'] \\\n",
    "    .link(CFDE.tables['file'], on=(\n",
    "      CFDE.tables['file'].assay_type == CFDE.tables['assay_type'].id\n",
    "    )) \\\n",
    "    .groupby(CFDE.tables['file'].id_namespace, CFDE.tables['file'].local_id) \\\n",
    "    .count()\n",
    "  value = (total_files_associated_with_assay_type / total_files) if total_files else float('nan')\n",
    "  return {\n",
    "    'value': value,\n",
    "    'comment': f\"({total_files_associated_with_assay_type} / {total_files})\",\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric_answer({\n",
    "  '@id': -4,\n",
    "  'name': 'ratio files are associate with anatomy term',\n",
    "  'description': '',\n",
    "  'detail': '',\n",
    "  'principle': '',\n",
    "})\n",
    "def _():\n",
    "  total_files_associated_with_anatomy = CFDE.tables['anatomy'] \\\n",
    "    .link(CFDE.tables['biosample'], on=(\n",
    "      CFDE.tables['biosample'].anatomy == CFDE.tables['anatomy'].id\n",
    "    )) \\\n",
    "    .link(CFDE.tables['file_describes_biosample'], on=((\n",
    "      CFDE.tables['file_describes_biosample'].biosample_id_namespace == CFDE.tables['biosample'].id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['file_describes_biosample'].biosample_local_id == CFDE.tables['biosample'].local_id\n",
    "    ))) \\\n",
    "    .link(CFDE.tables['file'], on=((\n",
    "      CFDE.tables['file'].id_namespace == CFDE.tables['file_describes_biosample'].file_id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['file'].local_id == CFDE.tables['file_describes_biosample'].file_local_id\n",
    "    ))) \\\n",
    "    .groupby(CFDE.tables['file'].id_namespace, CFDE.tables['file'].local_id) \\\n",
    "    .count()\n",
    "  value = (total_files_associated_with_anatomy / total_files) if total_files else float('nan')\n",
    "  return {\n",
    "    'value': value,\n",
    "    'comment': f\"({total_files_associated_with_anatomy} / {total_files})\",\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric_answer({\n",
    "  '@id': -5,\n",
    "  'name': 'ratio files are associated with a biosample',\n",
    "  'description': '',\n",
    "  'detail': '',\n",
    "  'principle': '',\n",
    "})\n",
    "def _():\n",
    "  total_files_associated_with_biosample = CFDE.tables['biosample'] \\\n",
    "    .link(CFDE.tables['file_describes_biosample'], on=((\n",
    "      CFDE.tables['file_describes_biosample'].biosample_id_namespace == CFDE.tables['biosample'].id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['file_describes_biosample'].biosample_local_id == CFDE.tables['biosample'].local_id\n",
    "    ))) \\\n",
    "    .link(CFDE.tables['file'], on=((\n",
    "      CFDE.tables['file'].id_namespace == CFDE.tables['file_describes_biosample'].file_id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['file'].local_id == CFDE.tables['file_describes_biosample'].file_local_id\n",
    "    ))) \\\n",
    "    .groupby(CFDE.tables['file'].id_namespace, CFDE.tables['file'].local_id) \\\n",
    "    .count()\n",
    "  value = (total_files_associated_with_biosample / total_files) if total_files else float('nan')\n",
    "  return {\n",
    "    'value': value,\n",
    "    'comment': f\"({total_files_associated_with_biosample} / {total_files})\",\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric_answer({\n",
    "  '@id': -6,\n",
    "  'name': 'ratio files are associated with a subject',\n",
    "  'description': '',\n",
    "  'detail': '',\n",
    "  'principle': '',\n",
    "})\n",
    "def _():\n",
    "  total_files_associated_with_subject = CFDE.tables['subject'] \\\n",
    "    .link(CFDE.tables['file_describes_subject'], on=((\n",
    "      CFDE.tables['file_describes_subject'].subject_id_namespace == CFDE.tables['subject'].id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['file_describes_subject'].subject_local_id == CFDE.tables['subject'].local_id\n",
    "    ))) \\\n",
    "    .link(CFDE.tables['file'], on=((\n",
    "      CFDE.tables['file'].id_namespace == CFDE.tables['file_describes_subject'].file_id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['file'].local_id == CFDE.tables['file_describes_subject'].file_local_id\n",
    "    ))) \\\n",
    "    .groupby(CFDE.tables['file'].id_namespace, CFDE.tables['file'].local_id) \\\n",
    "    .count()\n",
    "  value = (total_files_associated_with_subject / total_files) if total_files else float('nan')\n",
    "  return {\n",
    "    'value': value,\n",
    "    'comment': f\"({total_files_associated_with_subject} / {total_files})\",\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric_answer({\n",
    "  '@id': -7,\n",
    "  'name': 'ratio files are associated with a subject_role_taxonomy',\n",
    "  'description': '',\n",
    "  'detail': '',\n",
    "  'principle': '',\n",
    "})\n",
    "def _():\n",
    "  total_files_associated_with_subject_role = CFDE.tables['subject_role_taxonomy'] \\\n",
    "    .link(CFDE.tables['subject'], on=((\n",
    "      CFDE.tables['subject'].id_namespace == CFDE.tables['subject_role_taxonomy'].subject_id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['subject'].local_id == CFDE.tables['subject_role_taxonomy'].subject_local_id\n",
    "    ))) \\\n",
    "    .link(CFDE.tables['file_describes_subject'], on=((\n",
    "      CFDE.tables['file_describes_subject'].subject_id_namespace == CFDE.tables['subject'].id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['file_describes_subject'].subject_local_id == CFDE.tables['subject'].local_id\n",
    "    ))) \\\n",
    "    .link(CFDE.tables['file'], on=((\n",
    "      CFDE.tables['file'].id_namespace == CFDE.tables['file_describes_subject'].file_id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['file'].local_id == CFDE.tables['file_describes_subject'].file_local_id\n",
    "    ))) \\\n",
    "    .groupby(CFDE.tables['file'].id_namespace, CFDE.tables['file'].local_id) \\\n",
    "    .count()\n",
    "  value = (total_files_associated_with_subject_role / total_files) if total_files else float('nan')\n",
    "  return {\n",
    "    'value': value,\n",
    "    'comment': f\"({total_files_associated_with_subject_role} / {total_files})\",\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric_answer({\n",
    "  '@id': -8,\n",
    "  'name': 'ratio biosamples are associated with a species term (NCBI Taxon)',\n",
    "  'description': '',\n",
    "  'detail': '',\n",
    "  'principle': '',\n",
    "})\n",
    "def _():\n",
    "  total_biosamples_associated_with_ncbi_taxon = CFDE.tables['ncbi_taxonomy'] \\\n",
    "    .link(CFDE.tables['subject_role_taxonomy'], on=(\n",
    "      CFDE.tables['subject_role_taxonomy'].taxonomy_id == CFDE.tables['ncbi_taxonomy'].id\n",
    "    )) \\\n",
    "    .link(CFDE.tables['subject'], on=((\n",
    "      CFDE.tables['subject'].id_namespace == CFDE.tables['subject_role_taxonomy'].subject_id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['subject'].local_id == CFDE.tables['subject_role_taxonomy'].subject_local_id\n",
    "    ))) \\\n",
    "    .link(CFDE.tables['biosample_from_subject'], on=((\n",
    "      CFDE.tables['biosample_from_subject'].subject_id_namespace == CFDE.tables['subject'].id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['biosample_from_subject'].subject_local_id == CFDE.tables['subject'].local_id\n",
    "    ))) \\\n",
    "    .link(CFDE.tables['biosample'], on=((\n",
    "      CFDE.tables['biosample'].id_namespace == CFDE.tables['biosample_from_subject'].biosample_id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['biosample'].local_id == CFDE.tables['biosample_from_subject'].biosample_local_id\n",
    "    ))) \\\n",
    "    .groupby(CFDE.tables['biosample'].id_namespace, CFDE.tables['biosample'].local_id) \\\n",
    "    .count()\n",
    "  value = (total_biosamples_associated_with_ncbi_taxon / total_biosamples) if total_biosamples else float('nan')\n",
    "  return {\n",
    "    'value': value,\n",
    "    'comment': f\"({total_biosamples_associated_with_ncbi_taxon} / {total_biosamples})\",\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric_answer({\n",
    "  '@id': -9,\n",
    "  'name': 'ratio biosamples are associated with a subject',\n",
    "  'description': '',\n",
    "  'detail': '',\n",
    "  'principle': '',\n",
    "})\n",
    "def _():\n",
    "  total_biosamples_associated_with_subject = CFDE.tables['subject'] \\\n",
    "    .link(CFDE.tables['biosample_from_subject'], on=((\n",
    "      CFDE.tables['biosample_from_subject'].subject_id_namespace == CFDE.tables['subject'].id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['biosample_from_subject'].subject_local_id == CFDE.tables['subject'].local_id\n",
    "    ))) \\\n",
    "    .link(CFDE.tables['biosample'], on=((\n",
    "      CFDE.tables['biosample'].id_namespace == CFDE.tables['biosample_from_subject'].biosample_id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['biosample'].local_id == CFDE.tables['biosample_from_subject'].biosample_local_id\n",
    "    ))) \\\n",
    "    .groupby(CFDE.tables['biosample'].id_namespace, CFDE.tables['biosample'].local_id) \\\n",
    "    .count()\n",
    "  value = (total_biosamples_associated_with_subject / total_biosamples) if total_biosamples else float('nan')\n",
    "  return {\n",
    "    'value': value,\n",
    "    'comment': f\"({total_biosamples_associated_with_subject} / {total_biosamples})\",\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric_answer({\n",
    "  '@id': -10,\n",
    "  'name': 'ratio biosamples are associated with a file',\n",
    "  'description': '',\n",
    "  'detail': '',\n",
    "  'principle': '',\n",
    "})\n",
    "def _():\n",
    "  total_biosamples_associated_with_file = CFDE.tables['file'] \\\n",
    "    .link(CFDE.tables['file_describes_biosample'], on=((\n",
    "      CFDE.tables['file_describes_biosample'].file_id_namespace == CFDE.tables['file'].id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['file_describes_biosample'].file_local_id == CFDE.tables['file'].local_id\n",
    "    ))) \\\n",
    "    .link(CFDE.tables['biosample'], on=((\n",
    "      CFDE.tables['biosample'].id_namespace == CFDE.tables['file_describes_biosample'].biosample_id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['biosample'].local_id == CFDE.tables['file_describes_biosample'].biosample_local_id\n",
    "    ))) \\\n",
    "    .groupby(CFDE.tables['biosample'].id_namespace, CFDE.tables['biosample'].local_id) \\\n",
    "    .count()\n",
    "  value = (total_biosamples_associated_with_file / total_biosamples) if total_biosamples else float('nan')\n",
    "  return {\n",
    "    'value': value,\n",
    "    'comment': f\"({total_biosamples_associated_with_file} / {total_biosamples})\",\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric_answer({\n",
    "  '@id': -11,\n",
    "  'name': 'ratio biosamples are associated with an anatomy term',\n",
    "  'description': '',\n",
    "  'detail': '',\n",
    "  'principle': '',\n",
    "})\n",
    "def _():\n",
    "  total_biosamples_associated_with_anatomy = CFDE.tables['anatomy'] \\\n",
    "    .link(CFDE.tables['biosample'], on=(\n",
    "      CFDE.tables['biosample'].anatomy == CFDE.tables['anatomy'].id\n",
    "    )) \\\n",
    "    .groupby(CFDE.tables['biosample'].id_namespace, CFDE.tables['biosample'].local_id) \\\n",
    "    .count()\n",
    "  value = (total_biosamples_associated_with_anatomy / total_biosamples) if total_biosamples else float('nan')\n",
    "  return {\n",
    "    'value': value,\n",
    "    'comment': f\"({total_biosamples_associated_with_anatomy} / {total_biosamples})\",\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric_answer({\n",
    "  '@id': -12,\n",
    "  'name': 'ratio biosamples are associated with an assay term',\n",
    "  'description': '',\n",
    "  'detail': '',\n",
    "  'principle': '',\n",
    "})\n",
    "def _():\n",
    "  total_biosamples_associated_with_assay = CFDE.tables['file'].filter(CFDE.tables['file'].assay_type != None)   .link(CFDE.tables['file_describes_biosample'], on=((\n",
    "      CFDE.tables['file_describes_biosample'].file_id_namespace == CFDE.tables['file'].id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['file_describes_biosample'].file_local_id == CFDE.tables['file'].local_id\n",
    "    ))) \\\n",
    "    .link(CFDE.tables['biosample'], on=((\n",
    "      CFDE.tables['biosample'].id_namespace == CFDE.tables['file_describes_biosample'].biosample_id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['biosample'].local_id == CFDE.tables['file_describes_biosample'].biosample_local_id\n",
    "    ))) \\\n",
    "    .groupby(CFDE.tables['biosample'].id_namespace, CFDE.tables['biosample'].local_id) \\\n",
    "    .count()\n",
    "  value = (total_biosamples_associated_with_assay / total_biosamples) if total_biosamples else float('nan')\n",
    "  return {\n",
    "    'value': value,\n",
    "    'comment': f\"({total_biosamples_associated_with_assay} / {total_biosamples})\",\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric_answer({\n",
    "  '@id': -13,\n",
    "  'name': 'ratio subjects are associated with a taxonomy',\n",
    "  'description': '',\n",
    "  'detail': '',\n",
    "  'principle': '',\n",
    "})\n",
    "def _():\n",
    "  total_subjects_associated_with_taxonomy = CFDE.tables['ncbi_taxonomy'] \\\n",
    "    .link(CFDE.tables['subject_role_taxonomy'], on=(\n",
    "      CFDE.tables['subject_role_taxonomy'].taxonomy_id == CFDE.tables['ncbi_taxonomy'].id\n",
    "    )) \\\n",
    "    .link(CFDE.tables['subject'], on=((\n",
    "      CFDE.tables['subject'].id_namespace == CFDE.tables['subject_role_taxonomy'].subject_id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['subject'].local_id == CFDE.tables['subject_role_taxonomy'].subject_local_id\n",
    "    ))) \\\n",
    "    .groupby(CFDE.tables['subject'].id_namespace, CFDE.tables['subject'].local_id) \\\n",
    "    .count()\n",
    "  value = (total_subjects_associated_with_taxonomy / total_subjects) if total_subjects else float('nan')\n",
    "  return {\n",
    "    'value': value,\n",
    "    'comment': f\"({total_subjects_associated_with_taxonomy} / {total_subjects})\",\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric_answer({\n",
    "  '@id': -14,\n",
    "  'name': 'ratio subjects have subject granularity',\n",
    "  'description': '',\n",
    "  'detail': '',\n",
    "  'principle': '',\n",
    "})\n",
    "def _():\n",
    "  total_subjects_associated_with_granularity = CFDE.tables['subject'].filter(\n",
    "    (CFDE.tables['subject'].granularity != None) & (CFDE.tables['subject'].granularity != '')\n",
    "  ).count()\n",
    "  value = (total_subjects_associated_with_granularity / total_subjects) if total_subjects else float('nan')\n",
    "  return {\n",
    "    'value': value,\n",
    "    'comment': f\"({total_subjects_associated_with_granularity} / {total_subjects})\",\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric_answer({\n",
    "  '@id': -15,\n",
    "  'name': 'ratio subjects have taxonomic role',\n",
    "  'description': '',\n",
    "  'detail': '',\n",
    "  'principle': '',\n",
    "})\n",
    "def _():\n",
    "  total_subjects_associated_with_role_taxonomy = CFDE.tables['subject_role_taxonomy'] \\\n",
    "    .link(CFDE.tables['subject'], on=((\n",
    "      CFDE.tables['subject'].id_namespace == CFDE.tables['subject_role_taxonomy'].subject_id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['subject'].local_id == CFDE.tables['subject_role_taxonomy'].subject_local_id\n",
    "    ))) \\\n",
    "    .groupby(CFDE.tables['subject'].id_namespace, CFDE.tables['subject'].local_id) \\\n",
    "    .count()\n",
    "  value = (total_subjects_associated_with_role_taxonomy / total_subjects) if total_subjects else float('nan')\n",
    "  return {\n",
    "    'value': value,\n",
    "    'comment': f\"({total_subjects_associated_with_role_taxonomy} / {total_subjects})\",\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric_answer({\n",
    "  '@id': -16,\n",
    "  'name': 'ratio subjects associated with a biosample',\n",
    "  'description': '',\n",
    "  'detail': '',\n",
    "  'principle': '',\n",
    "})\n",
    "def _():\n",
    "  total_subjects_associated_with_biosample = CFDE.tables['biosample'] \\\n",
    "    .link(CFDE.tables['biosample_from_subject'], on=((\n",
    "      CFDE.tables['biosample_from_subject'].biosample_id_namespace == CFDE.tables['biosample'].id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['biosample_from_subject'].biosample_local_id == CFDE.tables['biosample'].local_id\n",
    "    ))) \\\n",
    "    .link(CFDE.tables['subject'], on=((\n",
    "      CFDE.tables['subject'].id_namespace == CFDE.tables['biosample_from_subject'].subject_id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['subject'].local_id == CFDE.tables['biosample_from_subject'].subject_local_id\n",
    "    ))) \\\n",
    "    .groupby(CFDE.tables['subject'].id_namespace, CFDE.tables['subject'].local_id) \\\n",
    "    .count()\n",
    "  value = (total_subjects_associated_with_biosample / total_subjects) if total_subjects else float('nan')\n",
    "  return {\n",
    "    'value': value,\n",
    "    'comment': f\"({total_subjects_associated_with_biosample} / {total_subjects})\",\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric_answer({\n",
    "  '@id': -17,\n",
    "  'name': 'ratio subjects associated with a file',\n",
    "  'description': '',\n",
    "  'detail': '',\n",
    "  'principle': '',\n",
    "})\n",
    "def _():\n",
    "  total_subjects_associated_with_file = CFDE.tables['file'] \\\n",
    "    .link(CFDE.tables['file_describes_subject'], on=((\n",
    "      CFDE.tables['file_describes_subject'].file_id_namespace == CFDE.tables['file'].id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['file_describes_subject'].file_local_id == CFDE.tables['file'].local_id\n",
    "    ))) \\\n",
    "    .link(CFDE.tables['subject'], on=((\n",
    "      CFDE.tables['subject'].id_namespace == CFDE.tables['file_describes_subject'].subject_id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['subject'].local_id == CFDE.tables['file_describes_subject'].subject_local_id\n",
    "    ))) \\\n",
    "    .groupby(CFDE.tables['subject'].id_namespace, CFDE.tables['subject'].local_id) \\\n",
    "    .count()\n",
    "  value = (total_subjects_associated_with_file / total_subjects) if total_subjects else float('nan')\n",
    "  return {\n",
    "    'value': value,\n",
    "    'comment': f\"({total_subjects_associated_with_file} / {total_subjects})\",\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric_answer({\n",
    "  '@id': -18,\n",
    "  'name': 'IF there are collections: # of files that are part of a collection',\n",
    "  'description': '',\n",
    "  'detail': '',\n",
    "  'principle': '',\n",
    "})\n",
    "def _():\n",
    "  total_files_not_in_collection = CFDE.tables['collection'] \\\n",
    "    .link(CFDE.tables['file_in_collection'], on=((\n",
    "      CFDE.tables['file_in_collection'].collection_id_namespace == CFDE.tables['collection'].id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['file_in_collection'].collection_local_id == CFDE.tables['collection'].local_id\n",
    "    ))) \\\n",
    "    .link(CFDE.tables['file'], on=((\n",
    "      CFDE.tables['file'].id_namespace == CFDE.tables['file_in_collection'].file_id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['file'].local_id == CFDE.tables['file_in_collection'].file_local_id\n",
    "    ))) \\\n",
    "    .groupby(CFDE.tables['file'].id_namespace, CFDE.tables['file'].local_id) \\\n",
    "    .count()\n",
    "  value = (total_files_not_in_collection / total_files) if total_files else float('nan')\n",
    "  return {\n",
    "    'value': value,\n",
    "    'comment': f\"({total_files_not_in_collection} / {total_files})\",\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric_answer({\n",
    "  '@id': -19,\n",
    "  'name': 'IF there are collections: # of subjects that are part of a collection',\n",
    "  'description': '',\n",
    "  'detail': '',\n",
    "  'principle': '',\n",
    "})\n",
    "def _():\n",
    "  total_subjects_not_in_collection = CFDE.tables['collection'] \\\n",
    "    .link(CFDE.tables['subject_in_collection'], on=((\n",
    "      CFDE.tables['subject_in_collection'].collection_id_namespace == CFDE.tables['collection'].id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['subject_in_collection'].collection_local_id == CFDE.tables['collection'].local_id\n",
    "    ))) \\\n",
    "    .link(CFDE.tables['subject'], on=((\n",
    "      CFDE.tables['subject'].id_namespace == CFDE.tables['subject_in_collection'].subject_id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['subject'].local_id == CFDE.tables['subject_in_collection'].subject_local_id\n",
    "    ))) \\\n",
    "    .groupby(CFDE.tables['subject'].id_namespace, CFDE.tables['subject'].local_id) \\\n",
    "    .count()\n",
    "  value = (total_subjects_not_in_collection / total_subjects) if total_subjects else float('nan')\n",
    "  return {\n",
    "    'value': value,\n",
    "    'comment': f\"({total_subjects_not_in_collection} / {total_subjects})\",\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric_answer({\n",
    "  '@id': -20,\n",
    "  'name': 'IF there are collections: # of biosamples that are part of a collection',\n",
    "  'description': '',\n",
    "  'detail': '',\n",
    "  'principle': '',\n",
    "})\n",
    "def _():\n",
    "  total_biosamples_not_in_collection = CFDE.tables['collection'] \\\n",
    "    .link(CFDE.tables['biosample_in_collection'], on=((\n",
    "      CFDE.tables['biosample_in_collection'].collection_id_namespace == CFDE.tables['collection'].id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['biosample_in_collection'].collection_local_id == CFDE.tables['collection'].local_id\n",
    "    ))) \\\n",
    "    .link(CFDE.tables['biosample'], on=((\n",
    "      CFDE.tables['biosample'].id_namespace == CFDE.tables['biosample_in_collection'].biosample_id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['biosample'].local_id == CFDE.tables['biosample_in_collection'].biosample_local_id\n",
    "    ))) \\\n",
    "    .groupby(CFDE.tables['biosample'].id_namespace, CFDE.tables['biosample'].local_id) \\\n",
    "    .count()\n",
    "  value = (total_biosamples_not_in_collection / total_biosamples) if total_biosamples else float('nan')\n",
    "  return {\n",
    "    'value': value,\n",
    "    'comment': f\"({total_biosamples_not_in_collection} / {total_biosamples})\",\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric_answer({\n",
    "  '@id': -21,\n",
    "  'name': 'Project associated with anatomy',\n",
    "  'description': '',\n",
    "  'detail': '',\n",
    "  'principle': '',\n",
    "})\n",
    "def _():\n",
    "  # NOTE: does not include recursive projects\n",
    "  total_projects_associated_with_anatomy = CFDE.tables['anatomy'] \\\n",
    "    .link(CFDE.tables['biosample'], on=(\n",
    "      CFDE.tables['biosample'].anatomy == CFDE.tables['anatomy'].id\n",
    "    )) \\\n",
    "    .link(CFDE.tables['project'], on=((\n",
    "      CFDE.tables['project'].id_namespace == CFDE.tables['biosample'].project_id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['project'].local_id == CFDE.tables['biosample'].project_local_id\n",
    "    ))) \\\n",
    "    .groupby(CFDE.tables['project'].id_namespace, CFDE.tables['project'].local_id) \\\n",
    "    .count()\n",
    "  value = (total_projects_associated_with_anatomy / total_projects) if total_projects else float('nan')\n",
    "  return {\n",
    "    'value': value,\n",
    "    'comment': f\"({total_projects_associated_with_anatomy} / {total_projects})\",\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric_answer({\n",
    "  '@id': -22,\n",
    "  'name': 'Project associated with files',\n",
    "  'description': '',\n",
    "  'detail': '',\n",
    "  'principle': '',\n",
    "})\n",
    "def _():\n",
    "  # NOTE: does not include recursive projects\n",
    "  total_projects_associated_with_file = CFDE.tables['file'] \\\n",
    "    .link(CFDE.tables['project'], on=((\n",
    "      CFDE.tables['project'].id_namespace == CFDE.tables['file'].project_id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['project'].local_id == CFDE.tables['file'].project_local_id\n",
    "    ))) \\\n",
    "    .groupby(CFDE.tables['project'].id_namespace, CFDE.tables['project'].local_id) \\\n",
    "    .count()\n",
    "  value = (total_projects_associated_with_file / total_projects) if total_projects else float('nan')\n",
    "  return {\n",
    "    'value': value,\n",
    "    'comment': f\"({total_projects_associated_with_file} / {total_projects})\",\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric_answer({\n",
    "  '@id': -23,\n",
    "  'name': 'Project associated with data types',\n",
    "  'description': '',\n",
    "  'detail': '',\n",
    "  'principle': '',\n",
    "})\n",
    "def _():\n",
    "  # NOTE: does not include recursive projects\n",
    "  total_projects_associated_with_data_type = CFDE.tables['data_type'] \\\n",
    "    .link(CFDE.tables['file'], on=(\n",
    "      CFDE.tables['file'].data_type == CFDE.tables['data_type'].id\n",
    "    )) \\\n",
    "    .link(CFDE.tables['project'], on=((\n",
    "      CFDE.tables['project'].id_namespace == CFDE.tables['file'].project_id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['project'].local_id == CFDE.tables['file'].project_local_id\n",
    "    ))) \\\n",
    "    .groupby(CFDE.tables['project'].id_namespace, CFDE.tables['project'].local_id) \\\n",
    "    .count()\n",
    "  value = (total_projects_associated_with_data_type / total_projects) if total_projects else float('nan')\n",
    "  return {\n",
    "    'value': value,\n",
    "    'comment': f\"({total_projects_associated_with_data_type} / {total_projects})\",\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric_answer({\n",
    "  '@id': -24,\n",
    "  'name': 'Project associated with subjects',\n",
    "  'description': '',\n",
    "  'detail': '',\n",
    "  'principle': '',\n",
    "})\n",
    "def _():\n",
    "  # NOTE: does not include recursive projects\n",
    "  total_projects_associated_with_subject = CFDE.tables['subject'] \\\n",
    "    .link(CFDE.tables['project'], on=((\n",
    "      CFDE.tables['project'].id_namespace == CFDE.tables['subject'].project_id_namespace\n",
    "    ) & (\n",
    "      CFDE.tables['project'].local_id == CFDE.tables['subject'].project_local_id\n",
    "    ))) \\\n",
    "    .groupby(CFDE.tables['project'].id_namespace, CFDE.tables['project'].local_id) \\\n",
    "    .count()\n",
    "  value = (total_projects_associated_with_subject / total_projects) if total_projects else float('nan')\n",
    "  return {\n",
    "    'value': value,\n",
    "    'comment': f\"({total_projects_associated_with_subject} / {total_projects})\",\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric_answer({\n",
    "  '@id': -25,\n",
    "  'name': 'list of any anatomy terms in anatomy.tsv NOT associated with biosamples',\n",
    "  'description': '',\n",
    "  'detail': '',\n",
    "  'principle': '',\n",
    "})\n",
    "def _():\n",
    "  # TODO: we can probably use an outer join for this..\n",
    "  used_anatomy_terms = CFDE.tables['biosample'] \\\n",
    "      .link(CFDE.tables['anatomy'], on=(\n",
    "          CFDE.tables['anatomy'].id == CFDE.tables['biosample'].anatomy\n",
    "      )) \\\n",
    "      .groupby(CFDE.tables['anatomy'].id)\n",
    "  used_anatomy_ids = {\n",
    "      anatomy['id']\n",
    "      for anatomy in used_anatomy_terms.entities()\n",
    "  }\n",
    "  unused_anatomy_terms = pd.DataFrame({\n",
    "      anatomy['id']: anatomy\n",
    "      for anatomy in CFDE.tables['anatomy'].entities()\n",
    "      if anatomy['id'] not in used_anatomy_ids\n",
    "  }).T\n",
    "  unused_anatomy_terms.to_csv('unused-anatomy-terms.tsv', sep='\\t')\n",
    "  display(Markdown('\\n'.join(f'''- {v['id']}''' for _, v in unused_anatomy_terms.iterrows())))\n",
    "  total = len(used_anatomy_ids) + unused_anatomy_terms.shape[0]\n",
    "  value = (1 - (unused_anatomy_terms.shape[0] / total)) if total else float('nan')\n",
    "  return {\n",
    "    'value': value,\n",
    "    'comment': f\"({len(used_anatomy_ids)} / {total})\",\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric_answer({\n",
    "  '@id': -26,\n",
    "  'name': 'list of any species terms in ncbi_taxonomy.tsv NOT associated with a subject',\n",
    "  'description': '',\n",
    "  'detail': '',\n",
    "  'principle': '',\n",
    "})\n",
    "def _():\n",
    "  # TODO: we can probably use an outer join for this..\n",
    "  used_taxonomy_terms = CFDE.tables['subject'] \\\n",
    "      .link(CFDE.tables['subject_role_taxonomy'], on=((\n",
    "          CFDE.tables['subject_role_taxonomy'].subject_id_namespace == CFDE.tables['subject'].id_namespace\n",
    "      ) & (\n",
    "          CFDE.tables['subject_role_taxonomy'].subject_local_id == CFDE.tables['subject'].local_id\n",
    "      ))) \\\n",
    "      .link(CFDE.tables['ncbi_taxonomy'], on=(\n",
    "          CFDE.tables['ncbi_taxonomy'].id == CFDE.tables['subject_role_taxonomy'].taxonomy_id\n",
    "      )) \\\n",
    "      .groupby(CFDE.tables['ncbi_taxonomy'].id)\n",
    "  used_taxonomy_ids = {\n",
    "      taxonomy['id']\n",
    "      for taxonomy in used_taxonomy_terms.entities()\n",
    "  }\n",
    "  unused_taxonomy_terms = pd.DataFrame({\n",
    "      taxonomy['id']: taxonomy\n",
    "      for taxonomy in CFDE.tables['ncbi_taxonomy'].entities()\n",
    "      if taxonomy['id'] not in used_taxonomy_ids\n",
    "  }).T\n",
    "  unused_taxonomy_terms.to_csv('unused-taxonomy-terms.tsv', sep='\\t')\n",
    "  display(Markdown('\\n'.join(f'''- {v['id']}''' for _, v in unused_taxonomy_terms.iterrows())))\n",
    "  total = len(used_taxonomy_ids) + unused_taxonomy_terms.shape[0]\n",
    "  value = (1 - (unused_taxonomy_terms.shape[0] / total)) if total else float('nan')\n",
    "  return {\n",
    "    'value': value,\n",
    "    'comment': f\"({len(used_taxonomy_ids)} / {total})\",\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric_answer({\n",
    "  '@id': -27,\n",
    "  'name': 'list of any assay terms in assay_type.tsv NOT associated with files',\n",
    "  'description': '',\n",
    "  'detail': '',\n",
    "  'principle': '',\n",
    "})\n",
    "def _():\n",
    "  used_assay_type_terms = CFDE.tables['file'] \\\n",
    "      .link(CFDE.tables['assay_type'], on=(\n",
    "          CFDE.tables['assay_type'].id == CFDE.tables['file'].assay_type\n",
    "      )) \\\n",
    "      .groupby(CFDE.tables['assay_type'].id)\n",
    "  used_assay_type_ids = {\n",
    "      assay_type['id']\n",
    "      for assay_type in used_assay_type_terms.entities()\n",
    "  }\n",
    "  unused_assay_type_terms = pd.DataFrame({\n",
    "      assay_type['id']: assay_type\n",
    "      for assay_type in CFDE.tables['assay_type'].entities()\n",
    "      if assay_type['id'] not in used_assay_type_ids\n",
    "  }).T\n",
    "  unused_assay_type_terms.to_csv('unused-assay-type-terms.tsv', sep='\\t')\n",
    "  display(Markdown('\\n'.join(f'''- {v['id']}''' for _, v in unused_assay_type_terms.iterrows())))\n",
    "  total = len(used_assay_type_ids) + unused_assay_type_terms.shape[0]\n",
    "  value = (1 - (unused_assay_type_terms.shape[0] / total)) if total else float('nan')\n",
    "  return {\n",
    "    'value': value,\n",
    "    'comment': f\"({len(used_assay_type_ids)} / {total})\",\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric_answer({\n",
    "  '@id': -28,\n",
    "  'name': 'list of any format terms in file_format.tsv NOT associated with files',\n",
    "  'description': '',\n",
    "  'detail': '',\n",
    "  'principle': '',\n",
    "})\n",
    "def _():\n",
    "  used_file_format_terms = CFDE.tables['file'] \\\n",
    "      .link(CFDE.tables['file_format'], on=(\n",
    "          CFDE.tables['file_format'].id == CFDE.tables['file'].file_format\n",
    "      )) \\\n",
    "      .groupby(CFDE.tables['file_format'].id)\n",
    "  used_file_format_ids = {\n",
    "      file_format['id']\n",
    "      for file_format in used_file_format_terms.entities()\n",
    "  }\n",
    "  unused_file_format_terms = pd.DataFrame({\n",
    "      file_format['id']: file_format\n",
    "      for file_format in CFDE.tables['file_format'].entities()\n",
    "      if file_format['id'] not in used_file_format_ids\n",
    "  }).T\n",
    "  unused_file_format_terms.to_csv('unused-file-format-terms.tsv', sep='\\t')\n",
    "  display(Markdown('\\n'.join(f'''- {v['id']}''' for _, v in unused_file_format_terms.iterrows())))\n",
    "  total = len(used_file_format_ids) + unused_file_format_terms.shape[0]\n",
    "  value = (1 - (unused_file_format_terms.shape[0] / total)) if total else float('nan')\n",
    "  return {\n",
    "    'value': value,\n",
    "    'comment': f\"({len(used_file_format_ids)} / {total})\",\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_register_metric_answer({\n",
    "  '@id': -29,\n",
    "  'name': 'list of any data type terms in data_type.tsv NOT associated with files',\n",
    "  'description': '',\n",
    "  'detail': '',\n",
    "  'principle': '',\n",
    "})\n",
    "def _():\n",
    "  used_data_type_terms = CFDE.tables['file'] \\\n",
    "      .link(CFDE.tables['data_type'], on=(\n",
    "          CFDE.tables['data_type'].id == CFDE.tables['file'].data_type\n",
    "      )) \\\n",
    "      .groupby(CFDE.tables['data_type'].id)\n",
    "  used_data_type_ids = {\n",
    "      data_type['id']\n",
    "      for data_type in used_data_type_terms.entities()\n",
    "  }\n",
    "  unused_data_type_terms = pd.DataFrame({\n",
    "      data_type['id']: data_type\n",
    "      for data_type in CFDE.tables['data_type'].entities()\n",
    "      if data_type['id'] not in used_data_type_ids\n",
    "  }).T\n",
    "  unused_data_type_terms.to_csv('unused-data-type-terms.tsv', sep='\\t')\n",
    "  display(Markdown('\\n'.join(f'''- {v['id']}''' for _, v in unused_data_type_terms.iterrows())))\n",
    "  total = len(used_data_type_ids) + unused_data_type_terms.shape[0]\n",
    "  value = (1 - (unused_data_type_terms.shape[0] / total)) if total else float('nan')\n",
    "  return {\n",
    "    'value': value,\n",
    "    'comment': f\"({len(used_data_type_ids)} / {total})\",\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter code_exec\n",
    "@_register_metric_answer({\n",
    "  '@id': 145,\n",
    "  'name': 'Landing Page',\n",
    "  'description': 'A landing page exists and is accessible for the identifiers',\n",
    "  'detail': '''Checks to make sure the persistent_id is resolvable with a HEAD request. if it is not http/https it is assumed to be an identifiers.org-resolvable CURIE. note that this is still error prone, some identifier websites do not follow HTTP standards and may not report 404s with ids that aren't found.''',\n",
    "  'principle': 'Findable',\n",
    "})\n",
    "def _():\n",
    "  results = {}\n",
    "  for file in CFDE.tables['file'].entities():\n",
    "    file_id = (file['id_namespace'], file['local_id'])\n",
    "    results[file_id] = {}\n",
    "    persistent_id = file.get('persistent_id')\n",
    "    if not persistent_id:\n",
    "      results[file_id]['value'] = 0\n",
    "      results[file_id]['comment'] = \"No persistent id present\"\n",
    "      continue\n",
    "    if not re.match(r'^https?://', persistent_id):\n",
    "      persistent_id = 'https://identifiers.org/{}'.format(persistent_id)\n",
    "    {% if skip_landing.value %}\n",
    "    results[file_id]['value'] = float('nan')\n",
    "    results[file_id]['comment'] = \"Skipped\"\n",
    "    {% else %}\n",
    "    try:\n",
    "      status_code = requests.head(persistent_id, headers={'User-Agent': None}).status_code\n",
    "      results[file_id]['comment'] = f\"Status Code: {status_code}\"\n",
    "      if status_code >= 200 and status_code < 300:\n",
    "        results[file_id]['value'] = 1.0\n",
    "      elif status_code >= 300 and status_code < 399:\n",
    "        results[file_id]['value'] = 0.5\n",
    "      elif status_code >= 400:\n",
    "        results[file_id]['value'] = 0.25\n",
    "    except Exception as e:\n",
    "      results[file_id]['value'] = 0.0\n",
    "      results[file_id]['comment'] = f\"Error: {e}\"\n",
    "    {% endif %}\n",
    "  results = pd.DataFrame(results).T\n",
    "  results.to_csv('landing-pages.tsv', sep='\\t')\n",
    "  display(results)\n",
    "  display(results.describe())\n",
    "  display(results['comment'].value_counts().to_frame('comment'))\n",
    "  return {\n",
    "    'value': results['value'].mean(),\n",
    "    'comment': f'(based on status_code reports via HEAD)',\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Review results\n",
    "\n",
    "With the assessment complete, we're ready to review the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 3. A simple look at the structure of the answers dataframe (joined with metrics for readability of metrics)\n",
    "\n",
    " - `name` this is the human readable name of the metric\n",
    " - `principle` this is the F.A.I.R category of the metric\n",
    " - `value` represents the quantitative value assigned to the given answer. It ranges between 0.0 and 1.0, 0.0 representing complete lack of *compliance* with a metric, and 1.0 representing complete satisfaction of a metric.\n",
    " - `comment` is a human-description describing why the `value` is what it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame(rubric['metrics']).T\n",
    "df_answers = pd.merge(\n",
    "    left=pd.DataFrame(answers), left_on='metric',\n",
    "    right=df_metrics[['name', 'principle']], right_index=True,\n",
    ")[['name', 'principle', 'value', 'comment']].sort_values('value')\n",
    "df_answers.to_csv('summary.tsv', sep='\\t')\n",
    "df_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. FAIRshake\n",
    "\n",
    "Our assessment is now ready to be registered with FAIRshake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_insignia(scores, metrics):\n",
    "    from IPython.display import display, HTML\n",
    "    import uuid, json\n",
    "    id = str(uuid.uuid4())\n",
    "    display(HTML(f'''\n",
    "        <div id={repr(id)} style=\"width: 100px; height: 100px;\"></div>\n",
    "        <script>\n",
    "        require(['https://fairshake.cloud/v2/static/scripts/insignia.js'], function(insignia) {{\n",
    "            var metrics = {json.dumps(metrics)}\n",
    "            var el = document.getElementById({repr(id)})\n",
    "            for (var i = 0; i < el.children.length; i++) el.removeChild(el.children[i])\n",
    "            insignia.build_svg(el,\n",
    "                {json.dumps(scores)},\n",
    "                {{ tooltips: function (rubric, metric, score) {{ return `${{(score*100).toFixed(0)}}%<br />${{metrics[metric]}}` }} }}\n",
    "            )\n",
    "        }})\n",
    "        </script>\n",
    "    '''), display_id=id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 1. FAIRshake Insignia\n",
    "\n",
    "The insignia compactly shows the results of the assessments; hovering over each square shows what metric was being evaluated. Blue means high satisfaction while red means low satisfaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_insignia(\n",
    "    { 0: df_answers['value'].to_dict() },\n",
    "    df_answers['name'].to_dict()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "No need to run this locally, but useful for appyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(directory)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
